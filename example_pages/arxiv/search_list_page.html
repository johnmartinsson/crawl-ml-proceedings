<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1" name="viewport"/>
  <!-- new favicon config and versions by realfavicongenerator.net -->
  <link href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/>
  <link href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/>
  <link href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/>
  <link href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest" rel="manifest"/>
  <link color="#b31b1b" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" rel="mask-icon"/>
  <link href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico" rel="shortcut icon"/>
  <meta content="#b31b1b" name="msapplication-TileColor"/>
  <meta content="images/icons/browserconfig.xml" name="msapplication-config"/>
  <meta content="#b31b1b" name="theme-color"/>
  <!-- end favicon config -->
  <title>
   Search | arXiv e-print repository
  </title>
  <script defer="" src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js">
  </script>
  <link href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" rel="stylesheet">
   <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
   </script>
   <script src="//static.arxiv.org/MathJax-2.7.3/MathJax.js">
   </script>
   <script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js">
   </script>
   <link href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" rel="stylesheet">
    <link href="https://static.arxiv.org/static/search/0.5.6/css/search.css" rel="stylesheet">
     <script crossorigin="anonymous" integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g=" src="https://code.jquery.com/jquery-3.2.1.slim.min.js">
     </script>
     <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js">
     </script>
     <style>
      radio#cf-customfield_11400 {
    display: none;
  }
     </style>
    </link>
   </link>
  </link>
 </head>
 <body>
  <header>
   <a class="is-sr-only" href="#main-container">
    Skip to main content
   </a>
   <!-- contains Cornell logo and sponsor statement -->
   <div class="attribution level is-marginless" role="banner">
    <div class="level-left">
     <a class="level-item" href="https://cornell.edu/">
      <img alt="Cornell University" aria-label="logo" src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" width="200"/>
     </a>
    </div>
    <div class="level-right is-marginless">
     <p class="sponsors level-item is-marginless">
      <a href="https://arxiv.org/about/ourmembers">
       We gratefully acknowledge support from
       <br/>
       the Simons Foundation and member institutions.
      </a>
     </p>
    </div>
   </div>
   <!-- contains arXiv identity and search bar -->
   <div class="identity level is-marginless">
    <div class="level-left">
     <div class="level-item">
      <a aria-label="arxiv-logo" class="arxiv" href="https://arxiv.org/">
       <img alt="arxiv logo" aria-label="logo" src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" style="width:85px;" width="85"/>
      </a>
     </div>
    </div>
    <div class="search-block level-right">
     <form action="https://arxiv.org/search" class="level-item mini-search" method="GET">
      <div class="field has-addons">
       <div class="control">
        <input aria-label="Search term or terms" class="input is-small" name="query" placeholder="Search..." type="text"/>
        <p class="help">
         <a href="https://arxiv.org/help">
          Help
         </a>
         |
         <a href="https://arxiv.org/search/advanced">
          Advanced Search
         </a>
        </p>
       </div>
       <div class="control">
        <div class="select is-small">
         <select aria-label="Field to search" name="searchtype">
          <option selected="selected" value="all">
           All fields
          </option>
          <option value="title">
           Title
          </option>
          <option value="author">
           Author
          </option>
          <option value="abstract">
           Abstract
          </option>
          <option value="comments">
           Comments
          </option>
          <option value="journal_ref">
           Journal reference
          </option>
          <option value="acm_class">
           ACM classification
          </option>
          <option value="msc_class">
           MSC classification
          </option>
          <option value="report_num">
           Report number
          </option>
          <option value="paper_id">
           arXiv identifier
          </option>
          <option value="doi">
           DOI
          </option>
          <option value="orcid">
           ORCID
          </option>
          <option value="author_id">
           arXiv author ID
          </option>
          <option value="help">
           Help pages
          </option>
          <option value="full_text">
           Full text
          </option>
         </select>
        </div>
       </div>
       <input name="source" type="hidden" value="header"/>
       <button class="button is-small is-cul-darker">
        Search
       </button>
      </div>
     </form>
    </div>
   </div>
   <!-- closes identity -->
   <div class="container">
    <div aria-label="User menu" class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation">
     <a href="https://arxiv.org/login">
      Login
     </a>
    </div>
   </div>
  </header>
  <main class="container" id="main-container">
   <div class="level is-marginless">
    <div class="level-left">
     <h1 class="title is-clearfix">
      Showing 401–600 of 2,783 results for all:
      <span class="mathjax">
       "active learning"
      </span>
     </h1>
    </div>
    <div class="level-right is-hidden-mobile">
     <!-- feedback for mobile is moved to footer -->
     <span class="help" style="display: inline-block;">
      <a href="https://github.com/arXiv/arxiv-search/releases">
       Search v0.5.6 released 2020-02-24
      </a>
     </span>
     <button class="button is-small" id="feedback-button">
      Feedback?
     </button>
    </div>
   </div>
   <div class="content">
    <form action="/search/" aria-role="search" method="GET">
     <div class="field has-addons-tablet">
      <div class="control is-expanded">
       <label class="hidden-label" for="query">
        Search term or terms
       </label>
       <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value='"active learning"'/>
      </div>
      <div class="select control is-medium">
       <label class="is-hidden" for="searchtype">
        Field
       </label>
       <select class="is-medium" id="searchtype" name="searchtype">
        <option selected="" value="all">
         All fields
        </option>
        <option value="title">
         Title
        </option>
        <option value="author">
         Author(s)
        </option>
        <option value="abstract">
         Abstract
        </option>
        <option value="comments">
         Comments
        </option>
        <option value="journal_ref">
         Journal reference
        </option>
        <option value="acm_class">
         ACM classification
        </option>
        <option value="msc_class">
         MSC classification
        </option>
        <option value="report_num">
         Report number
        </option>
        <option value="paper_id">
         arXiv identifier
        </option>
        <option value="doi">
         DOI
        </option>
        <option value="orcid">
         ORCID
        </option>
        <option value="license">
         License (URI)
        </option>
        <option value="author_id">
         arXiv author ID
        </option>
        <option value="help">
         Help pages
        </option>
        <option value="full_text">
         Full text
        </option>
       </select>
      </div>
      <div class="control">
       <button class="button is-link is-medium">
        Search
       </button>
      </div>
     </div>
     <div class="field">
      <div class="control is-size-7">
       <label class="radio">
        <input checked="" id="abstracts-0" name="abstracts" type="radio" value="show"/>
        Show abstracts
       </label>
       <label class="radio">
        <input id="abstracts-1" name="abstracts" type="radio" value="hide"/>
        Hide abstracts
       </label>
      </div>
     </div>
     <div class="is-clearfix" style="height: 2.5em">
      <div class="is-pulled-right">
       <a href="/search/advanced?terms-0-term=%22active+learning%22&amp;terms-0-field=all&amp;size=200&amp;order=-announced_date_first">
        Advanced Search
       </a>
      </div>
     </div>
     <input name="order" type="hidden" value="-announced_date_first"/>
     <input name="size" type="hidden" value="200"/>
    </form>
    <div class="level breathe-horizontal">
     <div class="level-left">
      <form action="/search/" method="GET">
       <div style="display: none;">
        <select id="searchtype" name="searchtype">
         <option selected="" value="all">
          All fields
         </option>
         <option value="title">
          Title
         </option>
         <option value="author">
          Author(s)
         </option>
         <option value="abstract">
          Abstract
         </option>
         <option value="comments">
          Comments
         </option>
         <option value="journal_ref">
          Journal reference
         </option>
         <option value="acm_class">
          ACM classification
         </option>
         <option value="msc_class">
          MSC classification
         </option>
         <option value="report_num">
          Report number
         </option>
         <option value="paper_id">
          arXiv identifier
         </option>
         <option value="doi">
          DOI
         </option>
         <option value="orcid">
          ORCID
         </option>
         <option value="license">
          License (URI)
         </option>
         <option value="author_id">
          arXiv author ID
         </option>
         <option value="help">
          Help pages
         </option>
         <option value="full_text">
          Full text
         </option>
        </select>
        <input id="query" name="query" type="text" value='"active learning"'/>
        <ul id="abstracts">
         <li>
          <input checked="" id="abstracts-0" name="abstracts" type="radio" value="show"/>
          <label for="abstracts-0">
           Show abstracts
          </label>
         </li>
         <li>
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"/>
          <label for="abstracts-1">
           Hide abstracts
          </label>
         </li>
        </ul>
       </div>
       <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
         <span class="select is-small">
          <select id="size" name="size">
           <option value="25">
            25
           </option>
           <option value="50">
            50
           </option>
           <option value="100">
            100
           </option>
           <option selected="" value="200">
            200
           </option>
          </select>
         </span>
         <label for="size">
          results per page
         </label>
         .
        </div>
        <div class="control">
         <label for="order">
          Sort results by
         </label>
         <span class="select is-small">
          <select id="order" name="order">
           <option selected="" value="-announced_date_first">
            Announcement date (newest first)
           </option>
           <option value="announced_date_first">
            Announcement date (oldest first)
           </option>
           <option value="-submitted_date">
            Submission date (newest first)
           </option>
           <option value="submitted_date">
            Submission date (oldest first)
           </option>
           <option value="">
            Relevance
           </option>
          </select>
         </span>
        </div>
        <div class="control">
         <button class="button is-small is-link">
          Go
         </button>
        </div>
       </div>
      </form>
     </div>
    </div>
    <nav aria-label="pagination" class="pagination is-small is-centered breathe-horizontal" role="navigation">
     <a class="pagination-previous" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=200">
      Previous
     </a>
     <a class="pagination-next" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=600">
      Next
     </a>
     <ul class="pagination-list">
      <li>
       <a aria-label="Goto page 1" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=0">
        1
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 2" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=200">
        2
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 3" class="pagination-link is-current" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=400">
        3
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 4" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=600">
        4
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 5" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=800">
        5
       </a>
      </li>
      <li>
       <span class="pagination-ellipsis">
        …
       </span>
      </li>
     </ul>
    </nav>
    <ol class="breathe-horizontal" start="401">
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.01578">
         arXiv:2307.01578
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.01578">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.01578">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">
         cs.IT
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Optimal and Efficient Binary Questioning for Human-in-the-Loop Annotation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Marchesoni-Acland%2C+F">
        Franco Marchesoni-Acland
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Morel%2C+J">
        Jean-Michel Morel
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kherroubi%2C+J">
        Josselin Kherroubi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Facciolo%2C+G">
        Gabriele Facciolo
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.01578v1-abstract-short" style="display: inline;">
        Even though data annotation is extremely important for interpretability, research and development of artificial intelligence solutions, most research efforts such as
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        or few-shot learning focus on the sample efficiency problem. This paper studies the neglected complementary problem of getting annotated d…
        <a class="is-size-7" onclick="document.getElementById('2307.01578v1-abstract-full').style.display = 'inline'; document.getElementById('2307.01578v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.01578v1-abstract-full" style="display: none;">
        Even though data annotation is extremely important for interpretability, research and development of artificial intelligence solutions, most research efforts such as
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        or few-shot learning focus on the sample efficiency problem. This paper studies the neglected complementary problem of getting annotated data given a predictor. For the simple binary classification setting, we present the spectrum ranging from optimal general solutions to practical efficient methods. The problem is framed as the full annotation of a binary classification dataset with the minimal number of yes/no questions when a predictor is available. For the case of general binary questions the solution is found in coding theory, where the optimal questioning strategy is given by the Huffman encoding of the possible labelings. However, this approach is computationally intractable even for small dataset sizes. We propose an alternative practical solution based on several heuristics and lookahead minimization of proxy cost functions. The proposed solution is analysed, compared with optimal solutions and evaluated on several synthetic and real-world datasets. On these datasets, the method allows a significant improvement ($23-86\%$) in annotation efficiency.
        <a class="is-size-7" onclick="document.getElementById('2307.01578v1-abstract-full').style.display = 'none'; document.getElementById('2307.01578v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        8 pages + references + appendix
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.01232">
         arXiv:2307.01232
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.01232">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.01232">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Robust Surgical Tools Detection in Endoscopic Videos with Noisy Data
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Qayyum%2C+A">
        Adnan Qayyum
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ali%2C+H">
        Hassan Ali
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Caputo%2C+M">
        Massimo Caputo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Vohra%2C+H">
        Hunaid Vohra
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Akinosho%2C+T">
        Taofeek Akinosho
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Abioye%2C+S">
        Sofiat Abioye
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Berrou%2C+I">
        Ilhem Berrou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Capik%2C+P">
        Paweł Capik
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Qadir%2C+J">
        Junaid Qadir
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bilal%2C+M">
        Muhammad Bilal
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.01232v1-abstract-short" style="display: inline;">
        …propose a systematic methodology for developing robust models for surgical tool detection using noisy data. Our methodology introduces two key innovations: (1) an intelligent
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy for minimal dataset identification and label correction by human experts; and (2) an assembling strategy for a student-t…
        <a class="is-size-7" onclick="document.getElementById('2307.01232v1-abstract-full').style.display = 'inline'; document.getElementById('2307.01232v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.01232v1-abstract-full" style="display: none;">
        Over the past few years, surgical data science has attracted substantial interest from the machine learning (ML) community. Various studies have demonstrated the efficacy of emerging ML techniques in analysing surgical data, particularly recordings of procedures, for digitizing clinical and non-clinical functions like preoperative planning, context-aware decision-making, and operating skill assessment. However, this field is still in its infancy and lacks representative, well-annotated datasets for training robust models in intermediate ML tasks. Also, existing datasets suffer from inaccurate labels, hindering the development of reliable models. In this paper, we propose a systematic methodology for developing robust models for surgical tool detection using noisy data. Our methodology introduces two key innovations: (1) an intelligent
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy for minimal dataset identification and label correction by human experts; and (2) an assembling strategy for a student-teacher model-based self-training framework to achieve the robust classification of 14 surgical tools in a semi-supervised fashion. Furthermore, we employ weighted data loaders to handle difficult class labels and address class imbalance issues. The proposed methodology achieves an average F1-score of 85.88\% for the ensemble model-based self-training with class weights, and 80.88\% without class weights for noisy labels. Also, our proposed method significantly outperforms existing approaches, which effectively demonstrates its effectiveness.
        <a class="is-size-7" onclick="document.getElementById('2307.01232v1-abstract-full').style.display = 'none'; document.getElementById('2307.01232v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       3 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.01138">
         arXiv:2307.01138
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.01138">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.01138">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Cosmology and Nongalactic Astrophysics">
         astro-ph.CO
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Instrumentation and Methods for Astrophysics">
         astro-ph.IM
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Uncertainty-aware and Data-efficient Cosmological Emulation using Gaussian Processes and PCA
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=G%C3%BCnther%2C+S">
        Sven Günther
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.01138v1-abstract-short" style="display: inline;">
        …the uncertainty-awareness of the emulator, which allows to state the emulation accuracy and ensures reliable performance. With a focus on data efficiency, we implement an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm based on a combination of Gaussian Processes and Principal Component Analysis. We find that for an MCMC analysis of Planck…
        <a class="is-size-7" onclick="document.getElementById('2307.01138v1-abstract-full').style.display = 'inline'; document.getElementById('2307.01138v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.01138v1-abstract-full" style="display: none;">
        Bayesian parameter inference is one of the key elements for model selection in cosmological research. However, the available inference tools require a large number of calls to simulation codes which can lead to high and sometimes even infeasible computational costs. In this work we propose a new way of emulating simulation codes for Bayesian parameter inference. In particular, this novel approach emphasizes the uncertainty-awareness of the emulator, which allows to state the emulation accuracy and ensures reliable performance. With a focus on data efficiency, we implement an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm based on a combination of Gaussian Processes and Principal Component Analysis. We find that for an MCMC analysis of Planck and BAO data on the $Λ$CDM model (6 model and 21 nuisance parameters) we can reduce the number of simulation calls by a factor of $\sim$500 and save about $96\%$ of the computational costs.
        <a class="is-size-7" onclick="document.getElementById('2307.01138v1-abstract-full').style.display = 'none'; document.getElementById('2307.01138v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       3 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        5 pages, 2 figures
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Report number:
       </span>
       TTK-23-16
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.00968">
         arXiv:2307.00968
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.00968">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.00968">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       REAL: A Representative Error-Driven Approach for
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chen%2C+C">
        Cheng Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">
        Yong Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liao%2C+L">
        Lizi Liao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">
        Yueguo Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Du%2C+X">
        Xiaoyong Du
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.00968v2-abstract-short" style="display: inline;">
        Given a limited labeling budget,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) aims to sample the most informative instances from an unlabeled pool to acquire labels for subsequent model training. To achieve this, AL typically measures the informativeness of unlabeled instances based on uncertainty and diversity. However, it does not consider…
        <a class="is-size-7" onclick="document.getElementById('2307.00968v2-abstract-full').style.display = 'inline'; document.getElementById('2307.00968v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.00968v2-abstract-full" style="display: none;">
        Given a limited labeling budget,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) aims to sample the most informative instances from an unlabeled pool to acquire labels for subsequent model training. To achieve this, AL typically measures the informativeness of unlabeled instances based on uncertainty and diversity. However, it does not consider erroneous instances with their neighborhood error density, which have great potential to improve the model performance. To address this limitation, we propose $REAL$, a novel approach to select data instances with $\underline{R}$epresentative $\underline{E}$rrors for $\underline{A}$ctive $\underline{L}$earning. It identifies minority predictions as \emph{pseudo errors} within a cluster and allocates an adaptive sampling budget for the cluster based on estimated error density. Extensive experiments on five text classification datasets demonstrate that $REAL$ consistently outperforms all best-performing baselines regarding accuracy and F1-macro scores across a wide range of hyperparameter settings. Our analysis also shows that $REAL$ selects the most representative pseudo errors that match the distribution of ground-truth errors along the decision boundary. Our code is publicly available at https://github.com/withchencheng/ECML_PKDD_23_Real.
        <a class="is-size-7" onclick="document.getElementById('2307.00968v2-abstract-full').style.display = 'none'; document.getElementById('2307.00968v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 3 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted by ECML/PKDD 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.00398">
         arXiv:2307.00398
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.00398">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.00398">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ProbVLM: Probabilistic Adapter for Frozen Vision-Language Models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Upadhyay%2C+U">
        Uddeshya Upadhyay
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Karthik%2C+S">
        Shyamgopal Karthik
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mancini%2C+M">
        Massimiliano Mancini
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Akata%2C+Z">
        Zeynep Akata
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.00398v3-abstract-short" style="display: inline;">
        …two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and model selection as two real-world downstream tasks for VLMs and show that the estimated uncertainty aids both tasks. Lastly,…
        <a class="is-size-7" onclick="document.getElementById('2307.00398v3-abstract-full').style.display = 'inline'; document.getElementById('2307.00398v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.00398v3-abstract-full" style="display: none;">
        Large-scale vision-language models (VLMs) like CLIP successfully find correspondences between images and text. Through the standard deterministic mapping process, an image or a text sample is mapped to a single vector in the embedding space. This is problematic: as multiple samples (images or text) can abstract the same concept in the physical world, deterministic embeddings do not reflect the inherent ambiguity in the embedding space. We propose ProbVLM, a probabilistic adapter that estimates probability distributions for the embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc manner without needing large-scale datasets or computing. On four challenging datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and model selection as two real-world downstream tasks for VLMs and show that the estimated uncertainty aids both tasks. Lastly, we present a novel technique for visualizing the embedding distributions using a large-scale pre-trained latent diffusion model. Code is available at https://github.com/ExplainableML/ProbVLM.
        <a class="is-size-7" onclick="document.getElementById('2307.00398v3-abstract-full').style.display = 'none'; document.getElementById('2307.00398v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 1 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        ICCV 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.00374">
         arXiv:2307.00374
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.00374">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.00374">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Revisiting Sample Size Determination in Natural Language Understanding
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chang%2C+E">
        Ernie Chang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rashid%2C+M+H">
        Muhammad Hassan Rashid
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lin%2C+P">
        Pin-Jie Lin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhao%2C+C">
        Changsheng Zhao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Demberg%2C+V">
        Vera Demberg
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shi%2C+Y">
        Yangyang Shi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chandra%2C+V">
        Vikas Chandra
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.00374v1-abstract-short" style="display: inline;">
        …many data points need to be labeled to achieve a certain model performance is a hugely beneficial step towards reducing the overall budgets for annotation. It pertains to both
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and traditional data annotation, and is particularly beneficial for low resource scenarios. Nevertheless, it remains a largely u…
        <a class="is-size-7" onclick="document.getElementById('2307.00374v1-abstract-full').style.display = 'inline'; document.getElementById('2307.00374v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.00374v1-abstract-full" style="display: none;">
        Knowing exactly how many data points need to be labeled to achieve a certain model performance is a hugely beneficial step towards reducing the overall budgets for annotation. It pertains to both
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and traditional data annotation, and is particularly beneficial for low resource scenarios. Nevertheless, it remains a largely under-explored area of research in NLP. We therefore explored various techniques for estimating the training sample size necessary to achieve a targeted performance value. We derived a simple yet effective approach to predict the maximum achievable model performance based on small amount of training samples - which serves as an early indicator during data annotation for data quality and sample size determination. We performed ablation studies on four language understanding tasks, and showed that the proposed approach allows us to forecast model performance within a small margin of mean absolute error (~ 0.9%) with only 10% data.
        <a class="is-size-7" onclick="document.getElementById('2307.00374v1-abstract-full').style.display = 'none'; document.getElementById('2307.00374v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       1 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to ACL 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2307.00108">
         arXiv:2307.00108
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2307.00108">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2307.00108">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Ticket-BERT: Labeling Incident Management Tickets with Language Models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">
        Zhexiong Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Benge%2C+C">
        Cris Benge
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jiang%2C+S">
        Siduo Jiang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2307.00108v1-abstract-short" style="display: inline;">
        …demonstrate the superiority of Ticket-BERT over baselines and state-of-the-art text classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT with an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        cycle and deploy it on the Microsoft IcM system, which enables the model to quickly finetune on newly-collected tickets with a few annot…
        <a class="is-size-7" onclick="document.getElementById('2307.00108v1-abstract-full').style.display = 'inline'; document.getElementById('2307.00108v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2307.00108v1-abstract-full" style="display: none;">
        An essential aspect of prioritizing incident tickets for resolution is efficiently labeling tickets with fine-grained categories. However, ticket data is often complex and poses several unique challenges for modern machine learning methods: (1) tickets are created and updated either by machines with pre-defined algorithms or by engineers with domain expertise that share different protocols, (2) tickets receive frequent revisions that update ticket status by modifying all or parts of ticket descriptions, and (3) ticket labeling is time-sensitive and requires knowledge updates and new labels per the rapid software and hardware improvement lifecycle. To handle these issues, we introduce Ticket- BERT which trains a simple yet robust language model for labeling tickets using our proposed ticket datasets. Experiments demonstrate the superiority of Ticket-BERT over baselines and state-of-the-art text classifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT with an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        cycle and deploy it on the Microsoft IcM system, which enables the model to quickly finetune on newly-collected tickets with a few annotations.
        <a class="is-size-7" onclick="document.getElementById('2307.00108v1-abstract-full').style.display = 'none'; document.getElementById('2307.00108v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       July 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        In the Microsoft Journal of Applied Research (MSJAR), Volume 18, January 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.17693">
         arXiv:2306.17693
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.17693">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.17693">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Thompson sampling for improved exploration in GFlowNets
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rector-Brooks%2C+J">
        Jarrid Rector-Brooks
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Madan%2C+K">
        Kanika Madan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jain%2C+M">
        Moksh Jain
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Korablyov%2C+M">
        Maksym Korablyov
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+C">
        Cheng-Hao Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chandar%2C+S">
        Sarath Chandar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Malkin%2C+N">
        Nikolay Malkin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bengio%2C+Y">
        Yoshua Bengio
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.17693v1-abstract-short" style="display: inline;">
        …optimal way of efficiently selecting trajectories for training has not yet been systematically explored. In this paper, we view the choice of trajectories for training as an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        problem and approach it using Bayesian techniques inspired by methods for multi-armed bandits. The proposed algorithm, Thompson sa…
        <a class="is-size-7" onclick="document.getElementById('2306.17693v1-abstract-full').style.display = 'inline'; document.getElementById('2306.17693v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.17693v1-abstract-full" style="display: none;">
        Generative flow networks (GFlowNets) are amortized variational inference algorithms that treat sampling from a distribution over compositional objects as a sequential decision-making problem with a learnable action policy. Unlike other algorithms for hierarchical sampling that optimize a variational bound, GFlowNet algorithms can stably run off-policy, which can be advantageous for discovering modes of the target distribution. Despite this flexibility in the choice of behaviour policy, the optimal way of efficiently selecting trajectories for training has not yet been systematically explored. In this paper, we view the choice of trajectories for training as an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        problem and approach it using Bayesian techniques inspired by methods for multi-armed bandits. The proposed algorithm, Thompson sampling GFlowNets (TS-GFN), maintains an approximate posterior distribution over policies and samples trajectories from this posterior for training. We show in two domains that TS-GFN yields improved exploration and thus faster convergence to the target distribution than the off-policy exploration strategies used in past work.
        <a class="is-size-7" onclick="document.getElementById('2306.17693v1-abstract-full').style.display = 'none'; document.getElementById('2306.17693v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Structured Probabilistic Inference and Generative Modeling (SPIGM) workshop @ ICML 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.17277">
         arXiv:2306.17277
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.17277">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Speeding up high-throughput characterization of materials libraries by
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       : autonomous electrical resistance measurements
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Thelen%2C+F">
        Felix Thelen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Banko%2C+L">
        Lars Banko
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zehl%2C+R">
        Rico Zehl
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Baha%2C+S">
        Sabrina Baha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ludwig%2C+A">
        Alfred Ludwig
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.17277v1-abstract-short" style="display: inline;">
        …of, e.g., compositionally complex materials, require decreasing characterization times significantly. Here, an autonomous measurement algorithm was developed, which leverages
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        based on a Gaussian process model capable of iteratively scanning a materials library based on the highest uncertainty. The algor…
        <a class="is-size-7" onclick="document.getElementById('2306.17277v1-abstract-full').style.display = 'inline'; document.getElementById('2306.17277v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.17277v1-abstract-full" style="display: none;">
        High-throughput experimentation enables efficient search space exploration for the discovery and optimization of new materials. However, large search spaces of, e.g., compositionally complex materials, require decreasing characterization times significantly. Here, an autonomous measurement algorithm was developed, which leverages
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        based on a Gaussian process model capable of iteratively scanning a materials library based on the highest uncertainty. The algorithm is applied to a four-point probe electrical resistance measurement device, frequently used to obtain indications for regions of interest in materials libraries. Ten materials libraries with different complexities of composition and property trends are analyzed to validate the model. By stopping the process before the entire library is characterized and predicting the remaining measurement areas, the measurement efficiency can be improved drastically. As robustness is essential for autonomous measurements, intrinsic outlier handling is built into the model and a dynamic stopping criterion based on the mean predicted covariance is proposed. A measurement time reduction of about 70-90% was observed while still ensuring an accuracy of above 90%.
        <a class="is-size-7" onclick="document.getElementById('2306.17277v1-abstract-full').style.display = 'none'; document.getElementById('2306.17277v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.16918">
         arXiv:2306.16918
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.16918">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.16918">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       PCDAL: A Perturbation Consistency-Driven
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Approach for Medical Image Segmentation and Classification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Wang%2C+T">
        Tao Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">
        Xinlin Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">
        Yuanbo Zhou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lan%2C+J">
        Junlin Lan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tan%2C+T">
        Tao Tan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Du%2C+M">
        Min Du
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gao%2C+Q">
        Qinquan Gao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tong%2C+T">
        Tong Tong
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.16918v1-abstract-short" style="display: inline;">
        …However, supervised learning deeply relies on large-scale annotated data, which is expensive, time-consuming, and even impractical to acquire in medical imaging applications.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.16918v1-abstract-full').style.display = 'inline'; document.getElementById('2306.16918v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.16918v1-abstract-full" style="display: none;">
        In recent years, deep learning has become a breakthrough technique in assisting medical image diagnosis. Supervised learning using convolutional neural networks (CNN) provides state-of-the-art performance and has served as a benchmark for various medical image segmentation and classification. However, supervised learning deeply relies on large-scale annotated data, which is expensive, time-consuming, and even impractical to acquire in medical imaging applications.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) methods have been widely applied in natural image classification tasks to reduce annotation costs by selecting more valuable examples from the unlabeled data pool. However, their application in medical image segmentation tasks is limited, and there is currently no effective and universal AL-based method specifically designed for 3D medical image segmentation. To address this limitation, we propose an AL-based method that can be simultaneously applied to 2D medical image classification, segmentation, and 3D medical image segmentation tasks. We extensively validated our proposed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method on three publicly available and challenging medical image datasets, Kvasir Dataset, COVID-19 Infection Segmentation Dataset, and BraTS2019 Dataset. The experimental results demonstrate that our PCDAL can achieve significantly improved performance with fewer annotations in 2D classification and segmentation and 3D segmentation tasks. The codes of this study are available at https://github.com/ortonwang/PCDAL.
        <a class="is-size-7" onclick="document.getElementById('2306.16918v1-abstract-full').style.display = 'none'; document.getElementById('2306.16918v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.16431">
         arXiv:2306.16431
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.16431">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.16431">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Increasing Performance And Sample Efficiency With Model-agnostic Interactive Feature Attributions
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Michiels%2C+J">
        Joran Michiels
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=De+Vos%2C+M">
        Maarten De Vos
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Suykens%2C+J">
        Johan Suykens
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.16431v1-abstract-short" style="display: inline;">
        …approach can significantly improve the model's performance only by augmenting its training dataset based on corrected explanations. Adding our interactive explanations to
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        settings increases the sample efficiency significantly and outperforms existing explanatory interactive strategies. Additionally…
        <a class="is-size-7" onclick="document.getElementById('2306.16431v1-abstract-full').style.display = 'inline'; document.getElementById('2306.16431v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.16431v1-abstract-full" style="display: none;">
        Model-agnostic feature attributions can provide local insights in complex ML models. If the explanation is correct, a domain expert can validate and trust the model's decision. However, if it contradicts the expert's knowledge, related work only corrects irrelevant features to improve the model. To allow for unlimited interaction, in this paper we provide model-agnostic implementations for two popular explanation methods (Occlusion and Shapley values) to enforce entirely different attributions in the complex model. For a particular set of samples, we use the corrected feature attributions to generate extra local data, which is used to retrain the model to have the right explanation for the samples. Through simulated and real data experiments on a variety of models we show how our proposed approach can significantly improve the model's performance only by augmenting its training dataset based on corrected explanations. Adding our interactive explanations to
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        settings increases the sample efficiency significantly and outperforms existing explanatory interactive strategies. Additionally we explore how a domain expert can provide feature attributions which are sufficiently correct to improve the model.
        <a class="is-size-7" onclick="document.getElementById('2306.16431v1-abstract-full').style.display = 'none'; document.getElementById('2306.16431v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.15766">
         arXiv:2306.15766
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.15766">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.15766">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Large Language Models as Annotators: Enhancing Generalization of NLP Models at Minimal Cost
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Bansal%2C+P">
        Parikshit Bansal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sharma%2C+A">
        Amit Sharma
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.15766v1-abstract-short" style="display: inline;">
        …Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference…
        <a class="is-size-7" onclick="document.getElementById('2306.15766v1-abstract-full').style.display = 'inline'; document.getElementById('2306.15766v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.15766v1-abstract-full" style="display: none;">
        State-of-the-art supervised NLP models achieve high accuracy but are also susceptible to failures on inputs from low-data regimes, such as domains that are not represented in training data. As an approximation to collecting ground-truth labels for the specific domain, we study the use of large language models (LLMs) for annotating inputs and improving the generalization of NLP models. Specifically, given a budget for LLM annotations, we present an algorithm for sampling the most informative inputs to annotate and retrain the NLP model. We find that popular
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies such as uncertainty-based sampling do not work well. Instead, we propose a sampling strategy based on the difference in prediction scores between the base model and the finetuned NLP model, utilizing the fact that most NLP models are finetuned from a base model. Experiments with classification (semantic similarity) and ranking (semantic search) tasks show that our sampling strategy leads to significant gains in accuracy for both the training and target domains.
        <a class="is-size-7" onclick="document.getElementById('2306.15766v1-abstract-full').style.display = 'none'; document.getElementById('2306.15766v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.15058">
         arXiv:2306.15058
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.15058">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.15058">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       BatchGFN: Generative Flow Networks for Batch
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Malik%2C+S+A">
        Shreshth A. Malik
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lahlou%2C+S">
        Salem Lahlou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jesson%2C+A">
        Andrew Jesson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jain%2C+M">
        Moksh Jain
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Malkin%2C+N">
        Nikolay Malkin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Deleu%2C+T">
        Tristan Deleu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bengio%2C+Y">
        Yoshua Bengio
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gal%2C+Y">
        Yarin Gal
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.15058v1-abstract-short" style="display: inline;">
        We introduce BatchGFN -- a novel approach for pool-based
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.15058v1-abstract-full').style.display = 'inline'; document.getElementById('2306.15058v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.15058v1-abstract-full" style="display: none;">
        We introduce BatchGFN -- a novel approach for pool-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        that uses generative flow networks to sample sets of data points proportional to a batch reward. With an appropriate reward function to quantify the utility of acquiring a batch, such as the joint mutual information between the batch and the model parameters, BatchGFN is able to construct highly informative batches for
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in a principled way. We show our approach enables sampling near-optimal utility batches at inference time with a single forward pass per point in the batch in toy regression problems. This alleviates the computational complexity of batch-aware algorithms and removes the need for greedy approximations to find maximizers for the batch reward. We also present early results for amortizing training across acquisition steps, which will enable scaling to real-world tasks.
        <a class="is-size-7" onclick="document.getElementById('2306.15058v1-abstract-full').style.display = 'none'; document.getElementById('2306.15058v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       26 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at the Structured Probabilistic Inference &amp; Generative Modeling workshop, ICML 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.14113">
         arXiv:2306.14113
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.14113">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.14113">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Exploring Data Redundancy in Real-world Image Classification through Data Selection
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tang%2C+Z">
        Zhenyu Tang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">
        Shaoting Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+X">
        Xiaosong Wang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.14113v1-abstract-short" style="display: inline;">
        …and meanwhile, obtaining quality labels remains a tedious job. Many methods have been proposed to address this issue in various training paradigms, e.g., continual learning,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , and federated learning, which indeed demonstrate certain forms of the data valuation process. However, existing methods are eith…
        <a class="is-size-7" onclick="document.getElementById('2306.14113v1-abstract-full').style.display = 'inline'; document.getElementById('2306.14113v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.14113v1-abstract-full" style="display: none;">
        Deep learning models often require large amounts of data for training, leading to increased costs. It is particularly challenging in medical imaging, i.e., gathering distributed data for centralized training, and meanwhile, obtaining quality labels remains a tedious job. Many methods have been proposed to address this issue in various training paradigms, e.g., continual learning,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , and federated learning, which indeed demonstrate certain forms of the data valuation process. However, existing methods are either overly intuitive or limited to common clean/toy datasets in the experiments. In this work, we present two data valuation metrics based on Synaptic Intelligence and gradient norms, respectively, to study the redundancy in real-world image data. Novel online and offline data selection algorithms are then proposed via clustering and grouping based on the examined data values. Our online approach effectively evaluates data utilizing layerwise model parameter updates and gradients in each epoch and can accelerate model training with fewer epochs and a subset (e.g., 19%-59%) of data while maintaining equivalent levels of accuracy in a variety of datasets. It also extends to the offline coreset construction, producing subsets of only 18%-30% of the original. The codes for the proposed adaptive data selection and coreset computation are available (https://github.com/ZhenyuTANG2023/data_selection).
        <a class="is-size-7" onclick="document.getElementById('2306.14113v1-abstract-full').style.display = 'none'; document.getElementById('2306.14113v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       24 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        18 pages, 8 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.13935">
         arXiv:2306.13935
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.13935">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.13935">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Are Good Explainers Secretly Human-in-the-Loop Active Learners?
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Nguyen%2C+E">
        Emma Nguyen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ghose%2C+A">
        Abhishek Ghose
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.13935v2-abstract-short" style="display: inline;">
        …for multiple use-cases in the past few years. Here we consider its use in studying model predictions to gather additional training data. We argue that this is equivalent to
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.13935v2-abstract-full').style.display = 'inline'; document.getElementById('2306.13935v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.13935v2-abstract-full" style="display: none;">
        Explainable AI (XAI) techniques have become popular for multiple use-cases in the past few years. Here we consider its use in studying model predictions to gather additional training data. We argue that this is equivalent to
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        , where the query strategy involves a human-in-the-loop. We provide a mathematical approximation for the role of the human, and present a general formalization of the end-to-end workflow. This enables us to rigorously compare this use with standard
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        algorithms, while allowing for extensions to the workflow. An added benefit is that their utility can be assessed via simulation instead of conducting expensive user-studies. We also present some initial promising results.
        <a class="is-size-7" onclick="document.getElementById('2306.13935v2-abstract-full').style.display = 'none'; document.getElementById('2306.13935v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 24 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.12928">
         arXiv:2306.12928
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.12928">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.12928">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Disordered Systems and Neural Networks">
         cond-mat.dis-nn
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Soft Condensed Matter">
         cond-mat.soft
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Statistical Mechanics">
         cond-mat.stat-mech
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1103/PhysRevE.109.024311">
           10.1103/PhysRevE.109.024311
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       The Physical Effects of Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Stern%2C+M">
        Menachem Stern
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+A+J">
        Andrea J. Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Balasubramanian%2C+V">
        Vijay Balasubramanian
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.12928v2-abstract-short" style="display: inline;">
        …can learn to perform diverse tasks. This learning, both in nature and in engineered systems, can occur through evolutionary selection or through dynamical rules that drive
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        from experience. Here, we show that \added{learning in linear physical networks with weak input signals} leaves architectural imprin…
        <a class="is-size-7" onclick="document.getElementById('2306.12928v2-abstract-full').style.display = 'inline'; document.getElementById('2306.12928v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.12928v2-abstract-full" style="display: none;">
        Interacting many-body physical systems ranging from neural networks in the brain to folding proteins to self-modifying electrical circuits can learn to perform diverse tasks. This learning, both in nature and in engineered systems, can occur through evolutionary selection or through dynamical rules that drive
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        from experience. Here, we show that \added{learning in linear physical networks with weak input signals} leaves architectural imprints on the Hessian of a physical system. Compared to a generic organization of the system components, (a) the effective physical dimension of the response to inputs decreases, (b) the response of physical degrees of freedom to random perturbations (or system ``susceptibility'') increases, and (c) the low-eigenvalue eigenvectors of the Hessian align with the task. Overall, these effects embody the typical scenario for learning processes in physical systems in the weak input regime, suggesting ways of discovering whether a physical network may have been trained.
        <a class="is-size-7" onclick="document.getElementById('2306.12928v2-abstract-full').style.display = 'none'; document.getElementById('2306.12928v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 January, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 22 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        24 pages, 10 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.12398">
         arXiv:2306.12398
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.12398">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.12398">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Multi-Task Consistency for
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hekimoglu%2C+A">
        Aral Hekimoglu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Friedrich%2C+P">
        Philipp Friedrich
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zimmer%2C+W">
        Walter Zimmer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schmidt%2C+M">
        Michael Schmidt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Marcos-Ramiro%2C+A">
        Alvaro Marcos-Ramiro
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Knoll%2C+A+C">
        Alois C. Knoll
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.12398v1-abstract-short" style="display: inline;">
        …for vision tasks require a large amount of labeled training data to ensure their performance and reliability. In single-task vision-based settings, inconsistency-based
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.12398v1-abstract-full').style.display = 'inline'; document.getElementById('2306.12398v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.12398v1-abstract-full" style="display: none;">
        Learning-based solutions for vision tasks require a large amount of labeled training data to ensure their performance and reliability. In single-task vision-based settings, inconsistency-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        has proven to be effective in selecting informative samples for annotation. However, there is a lack of research exploiting the inconsistency between multiple tasks in multi-task networks. To address this gap, we propose a novel multi-task
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy for two coupled vision tasks: object detection and semantic segmentation. Our approach leverages the inconsistency between them to identify informative samples across both tasks. We propose three constraints that specify how the tasks are coupled and introduce a method for determining the pixels belonging to the object detected by a bounding box, to later quantify the constraints as inconsistency scores. To evaluate the effectiveness of our approach, we establish multiple baselines for multi-task
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and introduce a new metric, mean Detection Segmentation Quality (mDSQ), tailored for the multi-task
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        comparison that addresses the performance of both tasks. We conduct extensive experiments on the nuImages and A9 datasets, demonstrating that our approach outperforms existing state-of-the-art methods by up to 3.4% mDSQ on nuImages. Our approach achieves 95% of the fully-trained performance using only 67% of the available data, corresponding to 20% fewer labels compared to random selection and 5% fewer labels compared to state-of-the-art selection strategy. Our code will be made publicly available after the review process.
        <a class="is-size-7" onclick="document.getElementById('2306.12398v1-abstract-full').style.display = 'none'; document.getElementById('2306.12398v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.12376">
         arXiv:2306.12376
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.12376">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.12376">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       M-VAAL: Multimodal Variational Adversarial
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Downstream Medical Image Analysis Tasks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Khanal%2C+B">
        Bidur Khanal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bhattarai%2C+B">
        Binod Bhattarai
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Khanal%2C+B">
        Bishesh Khanal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Stoyanov%2C+D">
        Danail Stoyanov
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Linte%2C+C+A">
        Cristian A. Linte
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.12376v1-abstract-short" style="display: inline;">
        Acquiring properly annotated data is expensive in the medical field as it requires experts, time-consuming protocols, and rigorous validation.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.12376v1-abstract-full').style.display = 'inline'; document.getElementById('2306.12376v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.12376v1-abstract-full" style="display: none;">
        Acquiring properly annotated data is expensive in the medical field as it requires experts, time-consuming protocols, and rigorous validation.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        attempts to minimize the need for large annotated samples by actively sampling the most informative examples for annotation. These examples contribute significantly to improving the performance of supervised machine learning models, and thus,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can play an essential role in selecting the most appropriate information in deep learning-based diagnosis, clinical assessments, and treatment planning. Although some existing works have proposed methods for sampling the best examples for annotation in medical image analysis, they are not task-agnostic and do not use multimodal auxiliary information in the sampler, which has the potential to increase robustness. Therefore, in this work, we propose a Multimodal Variational Adversarial
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (M-VAAL) method that uses auxiliary information from additional modalities to enhance the active sampling. We applied our method to two datasets: i) brain tumor segmentation and multi-label classification using the BraTS2018 dataset, and ii) chest X-ray image classification using the COVID-QU-Ex dataset. Our results show a promising direction toward data-efficient learning under limited annotations.
        <a class="is-size-7" onclick="document.getElementById('2306.12376v1-abstract-full').style.display = 'none'; document.getElementById('2306.12376v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.11715">
         arXiv:2306.11715
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.11715">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.11715">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Biomolecules">
         q-bio.BM
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Multi-Fidelity
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with GFlowNets
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hernandez-Garcia%2C+A">
        Alex Hernandez-Garcia
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Saxena%2C+N">
        Nikita Saxena
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jain%2C+M">
        Moksh Jain
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+C">
        Cheng-Hao Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bengio%2C+Y">
        Yoshua Bengio
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.11715v1-abstract-short" style="display: inline;">
        …tackle such problems would help accelerate currently crucial areas such as drug and materials discovery. In this paper, we propose the use of GFlowNets for multi-fidelity
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.11715v1-abstract-full').style.display = 'inline'; document.getElementById('2306.11715v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.11715v1-abstract-full" style="display: none;">
        In the last decades, the capacity to generate large amounts of data in science and engineering applications has been growing steadily. Meanwhile, the progress in machine learning has turned it into a suitable tool to process and utilise the available data. Nonetheless, many relevant scientific and engineering problems present challenges where current machine learning methods cannot yet efficiently leverage the available data and resources. For example, in scientific discovery, we are often faced with the problem of exploring very large, high-dimensional spaces, where querying a high fidelity, black-box objective function is very expensive. Progress in machine learning methods that can efficiently tackle such problems would help accelerate currently crucial areas such as drug and materials discovery. In this paper, we propose the use of GFlowNets for multi-fidelity
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , where multiple approximations of the black-box function are available at lower fidelity and cost. GFlowNets are recently proposed methods for amortised probabilistic inference that have proven efficient for exploring large, high-dimensional spaces and can hence be practical in the multi-fidelity setting too. Here, we describe our algorithm for multi-fidelity
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        with GFlowNets and evaluate its performance in both well-studied synthetic tasks and practically relevant applications of molecular discovery. Our results show that multi-fidelity
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        with GFlowNets can efficiently leverage the availability of multiple oracles with different costs and fidelities to accelerate scientific discovery and engineering design.
        <a class="is-size-7" onclick="document.getElementById('2306.11715v1-abstract-full').style.display = 'none'; document.getElementById('2306.11715v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       20 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Code: https://github.com/nikita-0209/mf-al-gfn
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.11605">
         arXiv:2306.11605
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.11605">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.11605">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Annotation Cost Efficient
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Content Based Image Retrieval
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Henkel%2C+J">
        Julia Henkel
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hoxha%2C+G">
        Genc Hoxha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sumbul%2C+G">
        Gencer Sumbul
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=M%C3%B6llenbrok%2C+L">
        Lars Möllenbrok
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Demir%2C+B">
        Begüm Demir
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.11605v2-abstract-short" style="display: inline;">
        …DML methods require a high number of annotated training images, which can be costly to gather. To address this problem, in this paper we present an annotation cost efficient
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) method (denoted as ANNEAL). The proposed method aims to iteratively enrich the training set by annotating the most informativ…
        <a class="is-size-7" onclick="document.getElementById('2306.11605v2-abstract-full').style.display = 'inline'; document.getElementById('2306.11605v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.11605v2-abstract-full" style="display: none;">
        Deep metric learning (DML) based methods have been found very effective for content-based image retrieval (CBIR) in remote sensing (RS). For accurately learning the model parameters of deep neural networks, most of the DML methods require a high number of annotated training images, which can be costly to gather. To address this problem, in this paper we present an annotation cost efficient
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) method (denoted as ANNEAL). The proposed method aims to iteratively enrich the training set by annotating the most informative image pairs as similar or dissimilar, while accurately modelling a deep metric space. This is achieved by two consecutive steps. In the first step the pairwise image similarity is modelled based on the available training set. Then, in the second step the most uncertain and diverse (i.e., informative) image pairs are selected to be annotated. Unlike the existing AL methods for CBIR, at each AL iteration of ANNEAL a human expert is asked to annotate the most informative image pairs as similar/dissimilar. This significantly reduces the annotation cost compared to annotating images with land-use/land cover class labels. Experimental results show the effectiveness of our method. The code of ANNEAL is publicly available at https://git.tu-berlin.de/rsim/ANNEAL.
        <a class="is-size-7" onclick="document.getElementById('2306.11605v2-abstract-full').style.display = 'none'; document.getElementById('2306.11605v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       26 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 20 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2023. Our code is available at https://git.tu-berlin.de/rsim/ANNEAL
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.11180">
         arXiv:2306.11180
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.11180">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.11180">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Hyperbolic
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Semantic Segmentation under Domain Shift
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Franco%2C+L">
        Luca Franco
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mandica%2C+P">
        Paolo Mandica
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kallidromitis%2C+K">
        Konstantinos Kallidromitis
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Guillory%2C+D">
        Devin Guillory
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Y">
        Yu-Teng Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Darrell%2C+T">
        Trevor Darrell
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Galasso%2C+F">
        Fabio Galasso
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.11180v4-abstract-short" style="display: inline;">
        We introduce a hyperbolic neural network approach to pixel-level
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.11180v4-abstract-full').style.display = 'inline'; document.getElementById('2306.11180v4-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.11180v4-abstract-full" style="display: none;">
        We introduce a hyperbolic neural network approach to pixel-level
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for semantic segmentation. Analysis of the data statistics leads to a novel interpretation of the hyperbolic radius as an indicator of data scarcity. In HALO (Hyperbolic
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        Optimization), for the first time, we propose the use of epistemic uncertainty as a data acquisition strategy, following the intuition of selecting data points that are the least known. The hyperbolic radius, complemented by the widely-adopted prediction entropy, effectively approximates epistemic uncertainty. We perform extensive experimental analysis based on two established synthetic-to-real benchmarks, i.e. GTAV $\rightarrow$ Cityscapes and SYNTHIA $\rightarrow$ Cityscapes. Additionally, we test HALO on Cityscape $\rightarrow$ ACDC for domain adaptation under adverse weather conditions, and we benchmark both convolutional and attention-based backbones. HALO sets a new state-of-the-art in
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for semantic segmentation under domain shift and it is the first
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach that surpasses the performance of supervised domain adaptation while using only a small portion of labels (i.e., 1\%).
        <a class="is-size-7" onclick="document.getElementById('2306.11180v4-abstract-full').style.display = 'none'; document.getElementById('2306.11180v4-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 February, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 19 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.11056">
         arXiv:2306.11056
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.11056">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.11056">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Taming Small-sample Bias in Low-budget
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Song%2C+L">
        Linxin Song
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">
        Jieyu Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lu%2C+X">
        Xiaotian Lu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhou%2C+T">
        Tianyi Zhou
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.11056v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.11056v1-abstract-full').style.display = 'inline'; document.getElementById('2306.11056v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.11056v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) aims to minimize the annotation cost by only querying a few informative examples for each model training stage. However, training a model on a few queried examples suffers from the small-sample bias. In this paper, we address this small-sample bias issue in low-budget AL by exploring a regularizer called Firth bias reduction, which can provably reduce the bias during the model training process but might hinder learning if its coefficient is not adaptive to the learning progress. Instead of tuning the coefficient for each query round, which is sensitive and time-consuming, we propose the curriculum Firth bias reduction (CHAIN) that can automatically adjust the coefficient to be adaptive to the training process. Under both deep learning and linear model settings, experiments on three benchmark datasets with several widely used query strategies and hyperparameter searching methods show that CHAIN can be used to build more efficient AL and can substantially improve the progress made by each
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        query.
        <a class="is-size-7" onclick="document.getElementById('2306.11056v1-abstract-full').style.display = 'none'; document.getElementById('2306.11056v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.10700">
         arXiv:2306.10700
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.10700">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.10700">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Perturbation-Based Two-Stage Multi-Domain
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=He%2C+R">
        Rui He
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dai%2C+Z">
        Zeyu Dai
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=He%2C+S">
        Shan He
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tang%2C+K">
        Ke Tang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.10700v1-abstract-short" style="display: inline;">
        In multi-domain learning (MDL) scenarios, high labeling effort is required due to the complexity of collecting data from various domains.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.10700v1-abstract-full').style.display = 'inline'; document.getElementById('2306.10700v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.10700v1-abstract-full" style="display: none;">
        In multi-domain learning (MDL) scenarios, high labeling effort is required due to the complexity of collecting data from various domains.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) presents an encouraging solution to this issue by annotating a smaller number of highly informative instances, thereby reducing the labeling effort. Previous research has relied on conventional AL strategies for MDL scenarios, which underutilize the domain-shared information of each instance during the selection procedure. To mitigate this issue, we propose a novel perturbation-based two-stage multi-domain
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (P2S-MDAL) method incorporated into the well-regarded ASP-MTL model. Specifically, P2S-MDAL involves allocating budgets for domains and establishing regions for diversity selection, which are further used to select the most cross-domain influential samples in each region. A perturbation metric has been introduced to evaluate the robustness of the shared feature extractor of the model, facilitating the identification of potentially cross-domain influential samples. Experiments are conducted on three real-world datasets, encompassing both texts and images. The superior performance over conventional AL strategies shows the effectiveness of the proposed strategy. Additionally, an ablation study has been carried out to demonstrate the validity of each component. Finally, we outline several intriguing potential directions for future MDAL research, thus catalyzing the field's advancement.
        <a class="is-size-7" onclick="document.getElementById('2306.10700v1-abstract-full').style.display = 'none'; document.getElementById('2306.10700v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.10440">
         arXiv:2306.10440
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.10440">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.10440">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Graph-based
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Surface Water and Sediment Detection in Multispectral Images
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chen%2C+B">
        Bohan Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Miller%2C+K">
        Kevin Miller
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bertozzi%2C+A+L">
        Andrea L. Bertozzi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schwenk%2C+J">
        Jon Schwenk
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.10440v1-abstract-short" style="display: inline;">
        We develop a graph
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        pipeline (GAP) to detect surface water and in-river sediment pixels in satellite images. The
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach is applied within the training process to optimally select specific pixels to generate…
        <a class="is-size-7" onclick="document.getElementById('2306.10440v1-abstract-full').style.display = 'inline'; document.getElementById('2306.10440v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.10440v1-abstract-full" style="display: none;">
        We develop a graph
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        pipeline (GAP) to detect surface water and in-river sediment pixels in satellite images. The
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach is applied within the training process to optimally select specific pixels to generate a hand-labeled training set. Our method obtains higher accuracy with far fewer training pixels than both standard and deep learning models. According to our experiments, our GAP trained on a set of 3270 pixels reaches a better accuracy than the neural network method trained on 2.1 million pixels.
        <a class="is-size-7" onclick="document.getElementById('2306.10440v1-abstract-full').style.display = 'none'; document.getElementById('2306.10440v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        4 pages, 2 figures, 1 table. Accepted by IGARSS 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.10087">
         arXiv:2306.10087
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.10087">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.10087">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ActiveGLAE: A Benchmark for Deep
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with Transformers
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rauch%2C+L">
        Lukas Rauch
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=A%C3%9Fenmacher%2C+M">
        Matthias Aßenmacher
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Huseljic%2C+D">
        Denis Huseljic
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wirth%2C+M">
        Moritz Wirth
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bischl%2C+B">
        Bernd Bischl
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sick%2C+B">
        Bernhard Sick
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.10087v1-abstract-short" style="display: inline;">
        Deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (DAL) seeks to reduce annotation costs by enabling the model to actively query instance annotations from which it expects to learn the most. Despite extensive research, there is currently no standardized evaluation protocol for transformer-based language models in the field of DAL. Diverse experime…
        <a class="is-size-7" onclick="document.getElementById('2306.10087v1-abstract-full').style.display = 'inline'; document.getElementById('2306.10087v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.10087v1-abstract-full" style="display: none;">
        Deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (DAL) seeks to reduce annotation costs by enabling the model to actively query instance annotations from which it expects to learn the most. Despite extensive research, there is currently no standardized evaluation protocol for transformer-based language models in the field of DAL. Diverse experimental settings lead to difficulties in comparing research and deriving recommendations for practitioners. To tackle this challenge, we propose the ActiveGLAE benchmark, a comprehensive collection of data sets and evaluation guidelines for assessing DAL. Our benchmark aims to facilitate and streamline the evaluation process of novel DAL strategies. Additionally, we provide an extensive overview of current practice in DAL with transformer-based language models. We identify three key challenges - data set selection, model training, and DAL settings - that pose difficulties in comparing query strategies. We establish baseline results through an extensive set of experiments as a reference point for evaluating future work. Based on our findings, we provide guidelines for researchers and practitioners.
        <a class="is-size-7" onclick="document.getElementById('2306.10087v1-abstract-full').style.display = 'none'; document.getElementById('2306.10087v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       16 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted @ ECML PKDD 2023. This is the author's version of the work. The definitive Version of Record will be published in the Proceedings of ECML PKDD 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.09910">
         arXiv:2306.09910
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.09910">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.09910">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       LabelBench: A Comprehensive Framework for Benchmarking Adaptive Label-Efficient Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">
        Jifan Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">
        Yifang Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Canal%2C+G">
        Gregory Canal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mussmann%2C+S">
        Stephen Mussmann
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Das%2C+A+M">
        Arnav M. Das
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bhatt%2C+G">
        Gantavya Bhatt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhu%2C+Y">
        Yinglun Zhu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bilmes%2C+J">
        Jeffrey Bilmes
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Du%2C+S+S">
        Simon Shaolei Du
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jamieson%2C+K">
        Kevin Jamieson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nowak%2C+R+D">
        Robert D Nowak
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.09910v4-abstract-short" style="display: inline;">
        …machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.09910v4-abstract-full').style.display = 'inline'; document.getElementById('2306.09910v4-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.09910v4-abstract-full" style="display: none;">
        Labeled data are critical to modern machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , aim to be label-efficient: achieving high predictive performance from relatively few labeled examples. While obtaining the best label-efficiency in practice often requires combinations of these techniques, existing benchmark and evaluation frameworks do not capture a concerted combination of all such techniques. This paper addresses this deficiency by introducing LabelBench, a new computationally-efficient framework for joint evaluation of multiple label-efficient learning techniques. As an application of LabelBench, we introduce a novel benchmark of state-of-the-art
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods in combination with semi-supervised learning for fine-tuning pretrained vision transformers. Our benchmark demonstrates better label-efficiencies than previously reported in
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . LabelBench's modular codebase is open-sourced for the broader community to contribute label-efficient learning methods and benchmarks. The repository can be found at: https://github.com/EfficientTraining/LabelBench.
        <a class="is-size-7" onclick="document.getElementById('2306.09910v4-abstract-full').style.display = 'none'; document.getElementById('2306.09910v4-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       1 March, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 16 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.09819">
         arXiv:2306.09819
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.09819">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.09819">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Amortized Inference for Gaussian Process Hyperparameters of Structured Kernels
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Bitzer%2C+M">
        Matthias Bitzer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Meister%2C+M">
        Mona Meister
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zimmer%2C+C">
        Christoph Zimmer
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.09819v1-abstract-short" style="display: inline;">
        Learning the kernel parameters for Gaussian processes is often the computational bottleneck in applications such as online learning, Bayesian optimization, or
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Amortizing parameter inference over different datasets is a promising approach to dramatically speed up training time. However, existing methods…
        <a class="is-size-7" onclick="document.getElementById('2306.09819v1-abstract-full').style.display = 'inline'; document.getElementById('2306.09819v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.09819v1-abstract-full" style="display: none;">
        Learning the kernel parameters for Gaussian processes is often the computational bottleneck in applications such as online learning, Bayesian optimization, or
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Amortizing parameter inference over different datasets is a promising approach to dramatically speed up training time. However, existing methods restrict the amortized inference procedure to a fixed kernel structure. The amortization network must be redesigned manually and trained again in case a different kernel is employed, which leads to a large overhead in design time and training time. We propose amortizing kernel parameter inference over a complete kernel-structure-family rather than a fixed kernel structure. We do that via defining an amortization network over pairs of datasets and kernel structures. This enables fast kernel inference for each element in the kernel family without retraining the amortization network. As a by-product, our amortization network is able to do fast ensembling over kernel structures. In our experiments, we show drastically reduced inference time combined with competitive test performance for a large set of kernels and datasets.
        <a class="is-size-7" onclick="document.getElementById('2306.09819v1-abstract-full').style.display = 'none'; document.getElementById('2306.09819v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       16 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at UAI 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.09321">
         arXiv:2306.09321
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.09321">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.09321">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1109/TCSVT.2023.3233989">
           10.1109/TCSVT.2023.3233989
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Crowd-Powered Photo Enhancement Featuring an
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Based Local Filter
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kosugi%2C+S">
        Satoshi Kosugi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yamasaki%2C+T">
        Toshihiko Yamasaki
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.09321v1-abstract-short" style="display: inline;">
        …which is achieved by asking crowd workers to locally optimize parameters for image editing functions. To make it easier to locally optimize the parameters, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.09321v1-abstract-full').style.display = 'inline'; document.getElementById('2306.09321v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.09321v1-abstract-full" style="display: none;">
        In this study, we address local photo enhancement to improve the aesthetic quality of an input image by applying different effects to different regions. Existing photo enhancement methods are either not content-aware or not local; therefore, we propose a crowd-powered local enhancement method for content-aware local enhancement, which is achieved by asking crowd workers to locally optimize parameters for image editing functions. To make it easier to locally optimize the parameters, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        based local filter. The parameters need to be determined at only a few key pixels selected by an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method, and the parameters at the other pixels are automatically predicted using a regression model. The parameters at the selected key pixels are independently optimized, breaking down the optimization problem into a sequence of single-slider adjustments. Our experiments show that the proposed filter outperforms existing filters, and our enhanced results are more visually pleasing than the results by the existing enhancement methods. Our source code and results are available at https://github.com/satoshi-kosugi/crowd-powered.
        <a class="is-size-7" onclick="document.getElementById('2306.09321v1-abstract-full').style.display = 'none'; document.getElementById('2306.09321v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.08954">
         arXiv:2306.08954
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.08954">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.08954">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Re-Benchmarking Pool-Based
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Binary Classification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Lu%2C+P">
        Po-Yi Lu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+C">
        Chun-Liang Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lin%2C+H">
        Hsuan-Tien Lin
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.08954v2-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.08954v2-abstract-full').style.display = 'inline'; document.getElementById('2306.08954v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.08954v2-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is a paradigm that significantly enhances the performance of machine learning models when acquiring labeled data is expensive. While several benchmarks exist for evaluating
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies, their findings exhibit some misalignment. This discrepancy motivates us to develop a transparent and reproducible benchmark for the community. Our efforts result in an open-sourced implementation (https://github.com/ariapoy/
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -benchmark) that is reliable and extensible for future research. By conducting thorough re-benchmarking experiments, we have not only rectified misconfigurations in existing benchmark but also shed light on the under-explored issue of model compatibility, which directly causes the observed discrepancy. Resolving the discrepancy reassures that the uncertainty sampling strategy of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        remains an effective and preferred choice for most datasets. Our experience highlights the importance of dedicating research efforts towards re-benchmarking existing benchmarks to produce more credible results and gain deeper insights.
        <a class="is-size-7" onclick="document.getElementById('2306.08954v2-abstract-full').style.display = 'none'; document.getElementById('2306.08954v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 15 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.08306">
         arXiv:2306.08306
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.08306">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.08306">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multimedia">
         cs.MM
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1145/3581783.3612463">
           10.1145/3581783.3612463
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Towards Balanced
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Multimodal Classification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Shen%2C+M">
        Meng Shen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">
        Yizheng Huang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yin%2C+J">
        Jianxiong Yin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zou%2C+H">
        Heqing Zou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rajan%2C+D">
        Deepu Rajan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=See%2C+S">
        Simon See
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.08306v2-abstract-short" style="display: inline;">
        Training multimodal networks requires a vast amount of data due to their larger parameter space compared to unimodal networks.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.08306v2-abstract-full').style.display = 'inline'; document.getElementById('2306.08306v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.08306v2-abstract-full" style="display: none;">
        Training multimodal networks requires a vast amount of data due to their larger parameter space compared to unimodal networks.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is a widely used technique for reducing data annotation costs by selecting only those samples that could contribute to improving model performance. However, current
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies are mostly designed for unimodal tasks, and when applied to multimodal data, they often result in biased sample selection from the dominant modality. This unfairness hinders balanced multimodal learning, which is crucial for achieving optimal performance. To address this issue, we propose three guidelines for designing a more balanced multimodal
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy. Following these guidelines, a novel approach is proposed to achieve more fair data selection by modulating the gradient embedding with the dominance degree among modalities. Our studies demonstrate that the proposed method achieves more balanced multimodal learning by avoiding greedy sample selection from the dominant modality. Our approach outperforms existing
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies on a variety of multimodal classification tasks. Overall, our work highlights the importance of balancing sample selection in multimodal
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and provides a practical solution for achieving more balanced
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for multimodal classification.
        <a class="is-size-7" onclick="document.getElementById('2306.08306v2-abstract-full').style.display = 'none'; document.getElementById('2306.08306v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 14 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 pages, accepted by ACMMM 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.08273">
         arXiv:2306.08273
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.08273">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.08273">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Beyond potential energy surface benchmarking: a complete application of machine learning to chemical reactivity
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Guan%2C+X">
        Xingyi Guan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Heindel%2C+J">
        Joseph Heindel
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ko%2C+T">
        Taehee Ko
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+C">
        Chao Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Head-Gordon%2C+T">
        Teresa Head-Gordon
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.08273v1-abstract-short" style="display: inline;">
        …must also learn avoidance of unforeseen high energy intermediates or even unphysical energy configurations. Because this type of data is unintuitive to create, we introduce an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflow based on metadynamics that samples a lower dimensional manifold within collective variables that efficiently creates hi…
        <a class="is-size-7" onclick="document.getElementById('2306.08273v1-abstract-full').style.display = 'inline'; document.getElementById('2306.08273v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.08273v1-abstract-full" style="display: none;">
        We train an equivariant machine learning model to predict energies and forces for a real-world study of hydrogen combustion under conditions of finite temperature and pressure. This challenging case for reactive chemistry illustrates that ML learned potential energy surfaces (PESs) are always incomplete as they are overly reliant on chemical intuition of what data is important for training, i.e. stable or metastable energy states. Instead we show here that a negative design data acquisition strategy is necessary to create a more complete ML model of the PES, since it must also learn avoidance of unforeseen high energy intermediates or even unphysical energy configurations. Because this type of data is unintuitive to create, we introduce an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflow based on metadynamics that samples a lower dimensional manifold within collective variables that efficiently creates highly variable energy configurations for further ML training. This strategy more rapidly completes the ML PES such that deviations among query by committee ML models helps to now signal occasional calls to the external ab initio data source to further molecular dynamics in time without need for retraining the ML model. With the hybrid ML-physics model we predict the change in transition state and/or reaction mechanism at finite temperature and pressure for hydrogen combustion, thereby delivering on the promise of real application work using ML trained models of an ab initio PES with two orders of magnitude reduction in cost.
        <a class="is-size-7" onclick="document.getElementById('2306.08273v1-abstract-full').style.display = 'none'; document.getElementById('2306.08273v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       14 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.08269">
         arXiv:2306.08269
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.08269">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.08269">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Highly Accurate Prediction of NMR Chemical Shifts from Low-Level Quantum Mechanics Calculations Using Machine Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+J">
        Jie Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liang%2C+J">
        Jiashu Liang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">
        Zhe Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ptaszek%2C+A+L">
        Aleksandra L. Ptaszek
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+X">
        Xiao Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ganoe%2C+B">
        Brad Ganoe
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Head-Gordon%2C+M">
        Martin Head-Gordon
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Head-Gordon%2C+T">
        Teresa Head-Gordon
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.08269v1-abstract-short" style="display: inline;">
        …composite theory that is comparable to CCSD(T) in the complete basis set limit. The inexpensive shift machine learning (iShiftML) algorithm is trained through a new progressive
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflow that reduces the total number of expensive calculations required when constructing the dataset, while allowing the mod…
        <a class="is-size-7" onclick="document.getElementById('2306.08269v1-abstract-full').style.display = 'inline'; document.getElementById('2306.08269v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.08269v1-abstract-full" style="display: none;">
        Theoretical predictions of NMR chemical shifts from first-principles can greatly facilitate experimental interpretation and structure identification. However, accurate prediction of chemical shifts using the best coupled cluster methods can be prohibitively expensive for systems larger than ten to twenty non-hydrogen atoms on today's computers. By contrast machine learning methods offer inexpensive alternatives but are hampered by generalization to molecules outside the original training set. Here we propose a novel machine learning feature representation informed by intermediate calculations of atomic chemical shielding tensors within a molecular environment using an inexpensive quantum mechanics method, and training it to predict NMR chemical shieldings of a high-level composite theory that is comparable to CCSD(T) in the complete basis set limit. The inexpensive shift machine learning (iShiftML) algorithm is trained through a new progressive
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflow that reduces the total number of expensive calculations required when constructing the dataset, while allowing the model to continuously improve on data it has never seen. Furthermore, we show that the error estimations from our model correlate quite well with actual errors to provide confidence values on new predictions. We illustrate the predictive capacity of iShiftML across gas phase experimental chemical shifts for small organic molecules and much larger and more complex natural products in which we can accurately differentiate between subtle diastereomers based on chemical shift assignments.
        <a class="is-size-7" onclick="document.getElementById('2306.08269v1-abstract-full').style.display = 'none'; document.getElementById('2306.08269v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       14 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.08238">
         arXiv:2306.08238
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.08238">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.08238">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Maestro: A Gamified Platform for Teaching AI Robustness
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Geleta%2C+M">
        Margarita Geleta
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+J">
        Jiacen Xu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Loya%2C+M">
        Manikanta Loya
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+J">
        Junlin Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Singh%2C+S">
        Sameer Singh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Z">
        Zhou Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gago-Masague%2C+S">
        Sergio Gago-Masague
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.08238v1-abstract-short" style="display: inline;">
        …on students' engagement, motivation, and learning success in robust AI. This work also provides insights into the design features of online learning tools that promote
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        opportunities in the robust AI domain. We analyzed the reflection responses (measured with Likert scales) of 147 undergraduate stude…
        <a class="is-size-7" onclick="document.getElementById('2306.08238v1-abstract-full').style.display = 'inline'; document.getElementById('2306.08238v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.08238v1-abstract-full" style="display: none;">
        Although the prevention of AI vulnerabilities is critical to preserve the safety and privacy of users and businesses, educational tools for robust AI are still underdeveloped worldwide. We present the design, implementation, and assessment of Maestro. Maestro is an effective open-source game-based platform that contributes to the advancement of robust AI education. Maestro provides goal-based scenarios where college students are exposed to challenging life-inspired assignments in a competitive programming environment. We assessed Maestro's influence on students' engagement, motivation, and learning success in robust AI. This work also provides insights into the design features of online learning tools that promote
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        opportunities in the robust AI domain. We analyzed the reflection responses (measured with Likert scales) of 147 undergraduate students using Maestro in two quarterly college courses in AI. According to the results, students who felt the acquisition of new skills in robust AI tended to appreciate highly Maestro and scored highly on material consolidation, curiosity, and mastery in robust AI. Moreover, the leaderboard, our key gamification element in Maestro, has effectively contributed to students' engagement and learning. Results also indicate that Maestro can be effectively adapted to any course length and depth without losing its educational quality.
        <a class="is-size-7" onclick="document.getElementById('2306.08238v1-abstract-full').style.display = 'none'; document.getElementById('2306.08238v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       14 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        9 pages, 6 figures, published at the Thirteenth Symposium on Educational Advances in Artificial Intelligence (EAAI-23) in the Association for the Advancement of Artificial Intelligence Conference (AAAI), 2023
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        MSC Class:
       </span>
       68U35
       <span class="has-text-black-bis has-text-weight-semibold">
        ACM Class:
       </span>
       H.5.2; I.2.m; J.m
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.08001">
         arXiv:2306.08001
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.08001">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/ps/2306.08001">
          ps
         </a>
         ,
         <a href="https://arxiv.org/format/2306.08001">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A Markovian Formalism for Active Querying
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Ijju%2C+S">
        Sid Ijju
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.08001v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.08001v1-abstract-full').style.display = 'inline'; document.getElementById('2306.08001v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.08001v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms have been an integral part of recent advances in artificial intelligence. However, the research in the field is widely varying and lacks an overall organizing leans. We outline a Markovian formalism for the field of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and survey the literature to demonstrate the organizing capability of our proposed formalism. Our formalism takes a partially observable Markovian system approach to the
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        process as a whole. We specifically outline how querying, dataset augmentation, reward updates, and other aspects of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can be viewed as a transition between meta-states in a Markovian system, and give direction into how other aspects of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can fit into our formalism.
        <a class="is-size-7" onclick="document.getElementById('2306.08001v1-abstract-full').style.display = 'none'; document.getElementById('2306.08001v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       13 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        , Markov, Inverse Reinforcement Learning, Query
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.07480">
         arXiv:2306.07480
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.07480">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.07480">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Methodology">
         stat.ME
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ACE:
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Causal Inference with Expensive Experiments
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Song%2C+D">
        Difan Song
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mak%2C+S">
        Simon Mak
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+C+F+J">
        C. F. Jeff Wu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.07480v1-abstract-short" style="display: inline;">
        …of such experiments may offer greatly improved inference of causal quantities over non-adaptive approaches, particularly when experiments are expensive. We thus propose a novel
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method called ACE (
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for Causal i…
        <a class="is-size-7" onclick="document.getElementById('2306.07480v1-abstract-full').style.display = 'inline'; document.getElementById('2306.07480v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.07480v1-abstract-full" style="display: none;">
        Experiments are the gold standard for causal inference. In many applications, experimental units can often be recruited or chosen sequentially, and the adaptive execution of such experiments may offer greatly improved inference of causal quantities over non-adaptive approaches, particularly when experiments are expensive. We thus propose a novel
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method called ACE (
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for Causal inference with Expensive experiments), which leverages Gaussian process modeling of the conditional mean functions to guide an informed sequential design of costly experiments. In particular, we develop new acquisition functions for sequential design via the minimization of the posterior variance of a desired causal estimand. Our approach facilitates targeted learning of a variety of causal estimands, such as the average treatment effect (ATE), the average treatment effect on the treated (ATTE), and individualized treatment effects (ITE), and can be used for adaptive selection of an experimental unit and/or the applied treatment. We then demonstrate in a suite of numerical experiments the improved performance of ACE over baseline methods for estimating causal estimands given a limited number of experiments.
        <a class="is-size-7" onclick="document.getElementById('2306.07480v1-abstract-full').style.display = 'none'; document.getElementById('2306.07480v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        6 pages, 4 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.06908">
         arXiv:2306.06908
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.06908">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.06908">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Guided Fine-Tuning for enhancing Self-Supervised Based Multi-Label Classification of Remote Sensing Images
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=M%C3%B6llenbrok%2C+L">
        Lars Möllenbrok
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Demir%2C+B">
        Begüm Demir
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.06908v2-abstract-short" style="display: inline;">
        …on a small and biased training set may limit model performance. To address this issue, we investigate the effectiveness of the joint use of self-supervised pre-training with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL). The considered AL strategy aims at guiding the MLC fine-tuning of a self-supervised model by selecting informative training…
        <a class="is-size-7" onclick="document.getElementById('2306.06908v2-abstract-full').style.display = 'inline'; document.getElementById('2306.06908v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.06908v2-abstract-full" style="display: none;">
        In recent years, deep neural networks (DNNs) have been found very successful for multi-label classification (MLC) of remote sensing (RS) images. Self-supervised pre-training combined with fine-tuning on a randomly selected small training set has become a popular approach to minimize annotation efforts of data-demanding DNNs. However, fine-tuning on a small and biased training set may limit model performance. To address this issue, we investigate the effectiveness of the joint use of self-supervised pre-training with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL). The considered AL strategy aims at guiding the MLC fine-tuning of a self-supervised model by selecting informative training samples to annotate in an iterative manner. Experimental results show the effectiveness of applying AL-guided fine-tuning (particularly for the case where strong class-imbalance is present in MLC problems) compared to the application of fine-tuning using a randomly constructed small training set.
        <a class="is-size-7" onclick="document.getElementById('2306.06908v2-abstract-full').style.display = 'none'; document.getElementById('2306.06908v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 12 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at IEEE International Geoscience and Remote Sensing Symposium 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.06174">
         arXiv:2306.06174
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.06174">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.06174">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">
         cs.CE
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Dynamical Systems">
         math.DS
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Numerical Analysis">
         math.NA
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Fluid Dynamics">
         physics.flu-dyn
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       -
       <span class="search-hit mathjax">
        Learning
       </span>
       -Driven Surrogate Modeling for Efficient Simulation of Parametric Nonlinear Systems
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kapadia%2C+H">
        Harshit Kapadia
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Feng%2C+L">
        Lihong Feng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Benner%2C+P">
        Peter Benner
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.06174v1-abstract-short" style="display: inline;">
        …enabling us to effectively construct a parametric surrogate model. We consider separate parameter-specific proper orthogonal decomposition (POD) subspaces and propose an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -driven surrogate model using kernel-based shallow neural networks, abbreviated as ActLearn-POD-KSNN surrogate model. To demonstrate t…
        <a class="is-size-7" onclick="document.getElementById('2306.06174v1-abstract-full').style.display = 'inline'; document.getElementById('2306.06174v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.06174v1-abstract-full" style="display: none;">
        When repeated evaluations for varying parameter configurations of a high-fidelity physical model are required, surrogate modeling techniques based on model order reduction are desired. In absence of the governing equations describing the dynamics, we need to construct the parametric reduced-order surrogate model in a non-intrusive fashion. In this setting, the usual residual-based error estimate for optimal parameter sampling associated with the reduced basis method is not directly available. Our work provides a non-intrusive optimality criterion to efficiently populate the parameter snapshots, thereby, enabling us to effectively construct a parametric surrogate model. We consider separate parameter-specific proper orthogonal decomposition (POD) subspaces and propose an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -driven surrogate model using kernel-based shallow neural networks, abbreviated as ActLearn-POD-KSNN surrogate model. To demonstrate the validity of our proposed ideas, we present numerical experiments using two physical models, namely Burgers' equation and shallow water equations. Both the models have mixed -- convective and diffusive -- effects within their respective parameter domains, with each of them dominating in certain regions. The proposed ActLearn-POD-KSNN surrogate model efficiently predicts the solution at new parameter locations, even for a setting with multiple interacting shock profiles.
        <a class="is-size-7" onclick="document.getElementById('2306.06174v1-abstract-full').style.display = 'none'; document.getElementById('2306.06174v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       9 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        31 pages, 24 figures, 1 table; Under review
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.05843">
         arXiv:2306.05843
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.05843">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.05843">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Numerical Analysis">
         math.NA
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation">
         stat.CO
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Adaptive Batch Sizes for
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       A Probabilistic Numerics Approach
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Adachi%2C+M">
        Masaki Adachi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hayakawa%2C+S">
        Satoshi Hayakawa
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=J%C3%B8rgensen%2C+M">
        Martin Jørgensen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wan%2C+X">
        Xingchen Wan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nguyen%2C+V">
        Vu Nguyen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Oberhauser%2C+H">
        Harald Oberhauser
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Osborne%2C+M+A">
        Michael A. Osborne
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.05843v2-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.05843v2-abstract-full').style.display = 'inline'; document.getElementById('2306.05843v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.05843v2-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed -- larger batches are more costly, smaller batches lead to slower wall-clock run-times -- and the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and Bayesian optimization applications.
        <a class="is-size-7" onclick="document.getElementById('2306.05843v2-abstract-full').style.display = 'none'; document.getElementById('2306.05843v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 February, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 9 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at AISTATS 2024. 33 pages, 6 figures
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        MSC Class:
       </span>
       62C10; 62F15
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.05724">
         arXiv:2306.05724
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.05724">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.05724">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Explaining Predictive Uncertainty with Information Theoretic Shapley Values
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Watson%2C+D+S">
        David S. Watson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=O%27Hara%2C+J">
        Joshua O'Hara
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tax%2C+N">
        Niek Tax
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mudd%2C+R">
        Richard Mudd
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Guy%2C+I">
        Ido Guy
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.05724v2-abstract-short" style="display: inline;">
        …guarantees, and implement efficient algorithms that perform well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , feature selection, and active feature-value acquisition.
        <a class="is-size-7" onclick="document.getElementById('2306.05724v2-abstract-full').style.display = 'inline'; document.getElementById('2306.05724v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.05724v2-abstract-full" style="display: none;">
        Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement efficient algorithms that perform well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , feature selection, and active feature-value acquisition.
        <a class="is-size-7" onclick="document.getElementById('2306.05724v2-abstract-full').style.display = 'none'; document.getElementById('2306.05724v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       31 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 9 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Camera ready version (NeurIPS 2023)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.05331">
         arXiv:2306.05331
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.05331">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.05331">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">
         cs.CE
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Actively
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       a Bayesian matrix fusion model with deep side information
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yu%2C+Y">
        Yangyang Yu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Suchow%2C+J+W">
        Jordan W. Suchow
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.05331v1-abstract-short" style="display: inline;">
        …such alignment requires the costly collection of behavioral responses, such that, in practice, the deep-feature spaces are only ever sparsely sampled. Here, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach to adaptively sampling experimental stimuli to efficiently learn a Bayesian matrix factorization model with deep side infor…
        <a class="is-size-7" onclick="document.getElementById('2306.05331v1-abstract-full').style.display = 'inline'; document.getElementById('2306.05331v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.05331v1-abstract-full" style="display: none;">
        High-dimensional deep neural network representations of images and concepts can be aligned to predict human annotations of diverse stimuli. However, such alignment requires the costly collection of behavioral responses, such that, in practice, the deep-feature spaces are only ever sparsely sampled. Here, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach to adaptively sampling experimental stimuli to efficiently learn a Bayesian matrix factorization model with deep side information. We observe a significant efficiency gain over a passive baseline. Furthermore, with a sequential batched sampling strategy, the algorithm is applicable not only to small datasets collected from traditional laboratory experiments but also to settings where large-scale crowdsourced data collection is needed to accurately align the high-dimensional deep feature representations derived from pre-trained networks.
        <a class="is-size-7" onclick="document.getElementById('2306.05331v1-abstract-full').style.display = 'none'; document.getElementById('2306.05331v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       8 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.04806">
         arXiv:2306.04806
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.04806">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.04806">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Autonomous Capability Assessment of Sequential Decision-Making Systems in Stochastic Settings (Extended Version)
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Verma%2C+P">
        Pulkit Verma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Karia%2C+R">
        Rushang Karia
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Srivastava%2C+S">
        Siddharth Srivastava
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.04806v2-abstract-short" style="display: inline;">
        …of black-box AI systems that can plan and act, along with the possible effects and requirements for executing those capabilities in stochastic settings. We present an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        approach that can effectively interact with a black-box SDM system and learn an interpretable probabilistic model describing its capabili…
        <a class="is-size-7" onclick="document.getElementById('2306.04806v2-abstract-full').style.display = 'inline'; document.getElementById('2306.04806v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.04806v2-abstract-full" style="display: none;">
        It is essential for users to understand what their AI systems can and can't do in order to use them safely. However, the problem of enabling users to assess AI systems with sequential decision-making (SDM) capabilities is relatively understudied. This paper presents a new approach for modeling the capabilities of black-box AI systems that can plan and act, along with the possible effects and requirements for executing those capabilities in stochastic settings. We present an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        approach that can effectively interact with a black-box SDM system and learn an interpretable probabilistic model describing its capabilities. Theoretical analysis of the approach identifies the conditions under which the learning process is guaranteed to converge to the correct model of the agent; empirical evaluations on different agents and simulated scenarios show that this approach is few-shot generalizable and can effectively describe the capabilities of arbitrary black-box SDM agents in a sample-efficient manner.
        <a class="is-size-7" onclick="document.getElementById('2306.04806v2-abstract-full').style.display = 'none'; document.getElementById('2306.04806v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 7 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        NeurIPS 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.04579">
         arXiv:2306.04579
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.04579">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.04579">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A Dataset for Deep Learning-based Bone Structure Analyses in Total Hip Arthroplasty
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+K">
        Kaidong Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gan%2C+Z">
        Ziyang Gan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+D">
        Dong Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shang%2C+X">
        Xifu Shang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.04579v1-abstract-short" style="display: inline;">
        …pipeline for producing a deep learning-oriented dataset. Our pipeline consists of non-learning-based bone extraction (BE) and acetabulum and femoral head segmentation (AFS) and
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -based annotation refinement (AAR). For BE we use the classic graph-cut algorithm. For AFS we propose an improved algorithm, inc…
        <a class="is-size-7" onclick="document.getElementById('2306.04579v1-abstract-full').style.display = 'inline'; document.getElementById('2306.04579v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.04579v1-abstract-full" style="display: none;">
        Total hip arthroplasty (THA) is a widely used surgical procedure in orthopedics. For THA, it is of clinical significance to analyze the bone structure from the CT images, especially to observe the structure of the acetabulum and femoral head, before the surgical procedure. For such bone structure analyses, deep learning technologies are promising but require high-quality labeled data for the learning, while the data labeling is costly. We address this issue and propose an efficient data annotation pipeline for producing a deep learning-oriented dataset. Our pipeline consists of non-learning-based bone extraction (BE) and acetabulum and femoral head segmentation (AFS) and
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -based annotation refinement (AAR). For BE we use the classic graph-cut algorithm. For AFS we propose an improved algorithm, including femoral head boundary localization using first-order and second-order gradient regularization, line-based non-maximum suppression, and anatomy prior-based femoral head extraction. For AAR, we refine the algorithm-produced pseudo labels with the help of trained deep models: we measure the uncertainty based on the disagreement between the original pseudo labels and the deep model predictions, and then find out the samples with the largest uncertainty to ask for manual labeling. Using the proposed pipeline, we construct a large-scale bone structure analyses dataset from more than 300 clinical and diverse CT scans. We perform careful manual labeling for the test set of our data. We then benchmark multiple state-of-the art deep learning-based methods of medical image segmentation using the training and test sets of our data. The extensive experimental results validate the efficacy of the proposed data annotation pipeline. The dataset, related codes and models will be publicly available at https://github.com/hitachinsk/THA.
        <a class="is-size-7" onclick="document.getElementById('2306.04579v1-abstract-full').style.display = 'none'; document.getElementById('2306.04579v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        16 pages, 17 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.04454">
         arXiv:2306.04454
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.04454">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.04454">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Training-Free Neural
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with Initialization-Robustness Guarantees
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hemachandra%2C+A">
        Apivich Hemachandra
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dai%2C+Z">
        Zhongxiang Dai
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Singh%2C+J">
        Jasraj Singh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ng%2C+S">
        See-Kiong Ng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Low%2C+B+K+H">
        Bryan Kian Hsiang Low
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.04454v1-abstract-short" style="display: inline;">
        Existing neural
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.04454v1-abstract-full').style.display = 'inline'; document.getElementById('2306.04454v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.04454v1-abstract-full" style="display: none;">
        Existing neural
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms have aimed to optimize the predictive performance of neural networks (NNs) by selecting data for labelling. However, other than a good predictive performance, being robust against random parameter initializations is also a crucial requirement in safety-critical applications. To this end, we introduce our expected variance with Gaussian processes (EV-GP) criterion for neural
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , which is theoretically guaranteed to select data points which lead to trained NNs with both (a) good predictive performances and (b) initialization robustness. Importantly, our EV-GP criterion is training-free, i.e., it does not require any training of the NN during data selection, which makes it computationally efficient. We empirically demonstrate that our EV-GP criterion is highly correlated with both initialization robustness and generalization performance, and show that it consistently outperforms baseline methods in terms of both desiderata, especially in situations with limited initial data or large batch sizes.
        <a class="is-size-7" onclick="document.getElementById('2306.04454v1-abstract-full').style.display = 'none'; document.getElementById('2306.04454v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to 40th International Conference on Machine Learning (ICML 2023), 41 pages
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.04099">
         arXiv:2306.04099
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.04099">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.04099">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       NTKCPL:
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       on Top of Self-Supervised Model by Estimating True Coverage
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Wen%2C+Z">
        Ziting Wen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pizarro%2C+O">
        Oscar Pizarro
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Williams%2C+S">
        Stefan Williams
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.04099v1-abstract-short" style="display: inline;">
        High annotation cost for training machine learning classifiers has driven extensive research in
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.04099v1-abstract-full').style.display = 'inline'; document.getElementById('2306.04099v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.04099v1-abstract-full" style="display: none;">
        High annotation cost for training machine learning classifiers has driven extensive research in
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and self-supervised learning. Recent research has shown that in the context of supervised learning different
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies need to be applied at various stages of the training process to ensure improved performance over the random baseline. We refer to the point where the number of available annotations changes the suitable
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy as the phase transition point. In this paper, we establish that when combining
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        with self-supervised models to achieve improved performance, the phase transition point occurs earlier. It becomes challenging to determine which strategy should be used for previously unseen datasets. We argue that existing
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms are heavily influenced by the phase transition because the empirical risk over the entire
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        pool estimated by these algorithms is inaccurate and influenced by the number of labeled samples. To address this issue, we propose a novel
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy, neural tangent kernel clustering-pseudo-labels (NTKCPL). It estimates empirical risk based on pseudo-labels and the model prediction with NTK approximation. We analyze the factors affecting this approximation error and design a pseudo-label clustering generation method to reduce the approximation error. We validate our method on five datasets, empirically demonstrating that it outperforms the baseline methods in most cases and is valid over a wider range of training budgets.
        <a class="is-size-7" onclick="document.getElementById('2306.04099v1-abstract-full').style.display = 'none'; document.getElementById('2306.04099v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       6 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.03696">
         arXiv:2306.03696
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.03696">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.03696">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Biomolecules">
         q-bio.BM
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Soft Condensed Matter">
         cond-mat.soft
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Biological Physics">
         physics.bio-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       of the thermodynamics-dynamics tradeoff in protein condensates
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=An%2C+Y">
        Yaxin An
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Webb%2C+M+A">
        Michael A. Webb
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jacobs%2C+W+M">
        William M. Jacobs
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.03696v3-abstract-short" style="display: inline;">
        …of homopolymer condensates are strongly correlated, with increased condensate stability being coincident with low mobilities and high viscosities. We then apply an "
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        " strategy to identify heteropolymer sequences that break this correlation. This data-driven approach and accompanying analysis reve…
        <a class="is-size-7" onclick="document.getElementById('2306.03696v3-abstract-full').style.display = 'inline'; document.getElementById('2306.03696v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.03696v3-abstract-full" style="display: none;">
        Phase-separated biomolecular condensates exhibit a wide range of dynamical properties, which depend on the sequences of the constituent proteins and RNAs. However, it is unclear to what extent condensate dynamics can be tuned without also changing the thermodynamic properties that govern phase separation. Using coarse-grained simulations of intrinsically disordered proteins, we show that the dynamics and thermodynamics of homopolymer condensates are strongly correlated, with increased condensate stability being coincident with low mobilities and high viscosities. We then apply an "
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        " strategy to identify heteropolymer sequences that break this correlation. This data-driven approach and accompanying analysis reveal how heterogeneous amino-acid compositions and non-uniform sequence patterning map to a range of independently tunable dynamical and thermodynamic properties of biomolecular condensates. Our results highlight key molecular determinants governing the physical properties of biomolecular condensates and establish design rules for the development of stimuli-responsive biomaterials.
        <a class="is-size-7" onclick="document.getElementById('2306.03696v3-abstract-full').style.display = 'none'; document.getElementById('2306.03696v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       9 December, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 6 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.03566">
         arXiv:2306.03566
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.03566">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.03566">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Memory-Based Dual Gaussian Processes for Sequential Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chang%2C+P+E">
        Paul E. Chang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Verma%2C+P">
        Prakhar Verma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=John%2C+S+T">
        S. T. John
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Solin%2C+A">
        Arno Solin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Khan%2C+M+E">
        Mohammad Emtiyaz Khan
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.03566v1-abstract-short" style="display: inline;">
        Sequential learning with Gaussian processes (GPs) is challenging when access to past data is limited, for example, in continual and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.03566v1-abstract-full').style.display = 'inline'; document.getElementById('2306.03566v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.03566v1-abstract-full" style="display: none;">
        Sequential learning with Gaussian processes (GPs) is challenging when access to past data is limited, for example, in continual and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . In such cases, errors can accumulate over time due to inaccuracies in the posterior, hyperparameters, and inducing points, making accurate learning challenging. Here, we present a method to keep all such errors in check using the recently proposed dual sparse variational GP. Our method enables accurate inference for generic likelihoods and improves learning by actively building and updating a memory of past data. We demonstrate its effectiveness in several applications involving Bayesian optimization,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , and continual learning.
        <a class="is-size-7" onclick="document.getElementById('2306.03566v1-abstract-full').style.display = 'none'; document.getElementById('2306.03566v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       6 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        International Conference on Machine Learning (ICML) 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.03543">
         arXiv:2306.03543
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.03543">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.03543">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       How to Select Which
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Strategy is Best Suited for Your Specific Problem and Budget
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hacohen%2C+G">
        Guy Hacohen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Weinshall%2C+D">
        Daphna Weinshall
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.03543v2-abstract-short" style="display: inline;">
        In the domain of
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL), a learner actively selects which unlabeled examples to seek labels from an oracle, while operating within predefined budget constraints. Importantly, it has been recently shown that distinct query strategies are better suited for different conditions and budgetary constraints. In…
        <a class="is-size-7" onclick="document.getElementById('2306.03543v2-abstract-full').style.display = 'inline'; document.getElementById('2306.03543v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.03543v2-abstract-full" style="display: none;">
        In the domain of
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL), a learner actively selects which unlabeled examples to seek labels from an oracle, while operating within predefined budget constraints. Importantly, it has been recently shown that distinct query strategies are better suited for different conditions and budgetary constraints. In practice, the determination of the most appropriate AL strategy for a given situation remains an open problem. To tackle this challenge, we propose a practical derivative-based method that dynamically identifies the best strategy for a given budget. Intuitive motivation for our approach is provided by the theoretical analysis of a simplified scenario. We then introduce a method to dynamically select an AL strategy, which takes into account the unique characteristics of the problem and the available budget. Empirical results showcase the effectiveness of our approach across diverse budgets and computer vision tasks.
        <a class="is-size-7" onclick="document.getElementById('2306.03543v2-abstract-full').style.display = 'none'; document.getElementById('2306.03543v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 6 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Proceedings: 37th Conference on Neural Information Processing Systems (NeurIPS), Dec 2023
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.03356">
         arXiv:2306.03356
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.03356">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.03356">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Query Complexity of
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Function Family With Nearly Orthogonal Basis
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chen%2C+X">
        Xiang Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Song%2C+Z">
        Zhao Song
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sun%2C+B">
        Baocheng Sun
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yin%2C+J">
        Junze Yin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhuo%2C+D">
        Danyang Zhuo
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.03356v1-abstract-short" style="display: inline;">
        …such as medical diagnosis and fraud detection, though there is an abundance of unlabeled data, it is costly to label the data by experts, experiments, or simulations.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms aim to reduce the number of required labeled data points while preserving performance. For many convex optimization problems s…
        <a class="is-size-7" onclick="document.getElementById('2306.03356v1-abstract-full').style.display = 'inline'; document.getElementById('2306.03356v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.03356v1-abstract-full" style="display: none;">
        Many machine learning algorithms require large numbers of labeled data to deliver state-of-the-art results. In applications such as medical diagnosis and fraud detection, though there is an abundance of unlabeled data, it is costly to label the data by experts, experiments, or simulations.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms aim to reduce the number of required labeled data points while preserving performance. For many convex optimization problems such as linear regression and $p$-norm regression, there are theoretical bounds on the number of required labels to achieve a certain accuracy. We call this the query complexity of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . However, today's
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms require the underlying learned function to have an orthogonal basis. For example, when applying
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to linear regression, the requirement is the target function is a linear composition of a set of orthogonal linear functions, and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can find the coefficients of these linear functions. We present a theoretical result to show that
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        does not need an orthogonal basis but rather only requires a nearly orthogonal basis. We provide the corresponding theoretical proofs for the function family of nearly orthogonal basis, and its applications associated with the algorithmically efficient
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework.
        <a class="is-size-7" onclick="document.getElementById('2306.03356v1-abstract-full').style.display = 'none'; document.getElementById('2306.03356v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.02808">
         arXiv:2306.02808
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.02808">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.02808">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with Structured Neural Depth Search
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">
        Xiaoyun Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ping%2C+X">
        Xieyi Ping
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">
        Jianwei Zhang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.02808v1-abstract-short" style="display: inline;">
        Previous work optimizes traditional
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.02808v1-abstract-full').style.display = 'inline'; document.getElementById('2306.02808v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.02808v1-abstract-full" style="display: none;">
        Previous work optimizes traditional
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) processes with incremental neural network architecture search (Active-iNAS) based on data complexity change, which improves the accuracy and learning efficiency. However, Active-iNAS trains several models and selects the model with the best generalization performance for querying the subsequent samples after each
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        cycle. The independent training processes lead to an insufferable computational budget, which is significantly inefficient and limits search flexibility and final performance. To address this issue, we propose a novel active strategy with the method called structured variational inference (SVI) or structured neural depth search (SNDS) whereby we could use the gradient descent method in neural network depth search during AL processes. At the same time, we theoretically demonstrate that the current VI-based methods based on the mean-field assumption could lead to poor performance. We apply our strategy using three querying techniques and three datasets and show that our strategy outperforms current methods.
        <a class="is-size-7" onclick="document.getElementById('2306.02808v1-abstract-full').style.display = 'none'; document.getElementById('2306.02808v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        10 pages, 8 figures, prepare for TNNLS
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.01922">
         arXiv:2306.01922
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.01922">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.01922">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Agnostic Multi-Group
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rittler%2C+N">
        Nick Rittler
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chaudhuri%2C+K">
        Kamalika Chaudhuri
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.01922v1-abstract-short" style="display: inline;">
        …learning where the goal is to generalize to a collection of distributions, each representing a ``group''. We consider a variant of this problem from the perspective of
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.01922v1-abstract-full').style.display = 'inline'; document.getElementById('2306.01922v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.01922v1-abstract-full" style="display: none;">
        Inspired by the problem of improving classification accuracy on rare or hard subsets of a population, there has been recent interest in models of learning where the goal is to generalize to a collection of distributions, each representing a ``group''. We consider a variant of this problem from the perspective of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , where the learner is endowed with the power to decide which examples are labeled from each distribution in the collection, and the goal is to minimize the number of label queries while maintaining PAC-learning guarantees. Our main challenge is that standard
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        techniques such as disagreement-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        do not directly apply to the multi-group learning objective. We modify existing algorithms to provide a consistent
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm for an agnostic formulation of multi-group learning, which given a collection of $G$ distributions and a hypothesis class $\mathcal{H}$ with VC-dimension $d$, outputs an $ε$-optimal hypothesis using $\tilde{O}\left( (ν^2/ε^2+1) G d θ_{\mathcal{G}}^2 \log^2(1/ε) + G\log(1/ε)/ε^2 \right)$ label queries, where $θ_{\mathcal{G}}$ is the worst-case disagreement coefficient over the collection. Roughly speaking, this guarantee improves upon the label complexity of standard multi-group learning in regimes where disagreement-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms may be expected to succeed, and the number of groups is not too large. We also consider the special case where each distribution in the collection is individually realizable with respect to $\mathcal{H}$, and demonstrate $\tilde{O}\left( G d θ_{\mathcal{G}} \log(1/ε) \right)$ label queries are sufficient for learning in this case. We further give an approximation result for the full agnostic case inspired by the group realizable strategy.
        <a class="is-size-7" onclick="document.getElementById('2306.01922v1-abstract-full').style.display = 'none'; document.getElementById('2306.01922v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.01827">
         arXiv:2306.01827
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.01827">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.01827">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       on Medical Image
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Biswas%2C+A">
        Angona Biswas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nasim%2C+M+A+A">
        MD Abdullah Al Nasim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ali%2C+M+S">
        Md Shahin Ali
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hossain%2C+I">
        Ismail Hossain
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ullah%2C+D+M+A">
        Dr. Md Azim Ullah
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Talukder%2C+S">
        Sajedul Talukder
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.01827v2-abstract-short" style="display: inline;">
        …can impede the pattern-learning process of machine-learning algorithms. Additionally, the lack of labeled data is another critical issue for machine learning. In this context,
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.01827v2-abstract-full').style.display = 'inline'; document.getElementById('2306.01827v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.01827v2-abstract-full" style="display: none;">
        The development of medical science greatly depends on the increased utilization of machine learning algorithms. By incorporating machine learning, the medical imaging field can significantly improve in terms of the speed and accuracy of the diagnostic process. Computed tomography (CT), magnetic resonance imaging (MRI), X-ray imaging, ultrasound imaging, and positron emission tomography (PET) are the most commonly used types of imaging data in the diagnosis process, and machine learning can aid in detecting diseases at an early stage. However, training machine learning models with limited annotated medical image data poses a challenge. The majority of medical image datasets have limited data, which can impede the pattern-learning process of machine-learning algorithms. Additionally, the lack of labeled data is another critical issue for machine learning. In this context,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        techniques can be employed to address the challenge of limited annotated medical image data.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        involves iteratively selecting the most informative samples from a large pool of unlabeled data for annotation by experts. By actively selecting the most relevant and informative samples,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        reduces the reliance on large amounts of labeled data and maximizes the model's learning capacity with minimal human labeling effort. By incorporating
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        into the training process, medical imaging machine learning models can make more efficient use of the available labeled data, improving their accuracy and performance. This approach allows medical professionals to focus their efforts on annotating the most critical cases, while the machine learning model
        <span class="search-hit mathjax">
         actively
        </span>
        <span class="search-hit mathjax">
         learns
        </span>
        from these annotated samples to improve its diagnostic capabilities.
        <a class="is-size-7" onclick="document.getElementById('2306.01827v2-abstract-full').style.display = 'none'; document.getElementById('2306.01827v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 2 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 pages, 8 figures; Acceptance of the chapter for the Springer book "Data-driven approaches to medical imaging"
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.01277">
         arXiv:2306.01277
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.01277">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.01277">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Beyond
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       : Leveraging the Full Potential of Human Interaction via Auto-Labeling, Human Correction, and Human Verification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Beck%2C+N">
        Nathan Beck
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Killamsetty%2C+K">
        Krishnateja Killamsetty
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kothawade%2C+S">
        Suraj Kothawade
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Iyer%2C+R">
        Rishabh Iyer
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.01277v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) is a human-in-the-loop framework to interactively and adaptively label data instances, thereby enabling significant gains in model performance compared to random sampling. AL approaches function by selecting the hardest instances to label, often relying on notions of diversity and uncertainty. Howe…
        <a class="is-size-7" onclick="document.getElementById('2306.01277v1-abstract-full').style.display = 'inline'; document.getElementById('2306.01277v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.01277v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) is a human-in-the-loop framework to interactively and adaptively label data instances, thereby enabling significant gains in model performance compared to random sampling. AL approaches function by selecting the hardest instances to label, often relying on notions of diversity and uncertainty. However, we believe that these current paradigms of AL do not leverage the full potential of human interaction granted by automated label suggestions. Indeed, we show that for many classification tasks and datasets, most people verifying if an automatically suggested label is correct take $3\times$ to $4\times$ less time than they do changing an incorrect suggestion to the correct label (or labeling from scratch without any suggestion). Utilizing this result, we propose CLARIFIER (
        <span class="search-hit mathjax">
         aCtive
        </span>
        <span class="search-hit mathjax">
         LeARnIng
        </span>
        From tIEred haRdness), an Interactive Learning framework that admits more effective use of human interaction by leveraging the reduced cost of verification. By targeting the hard (uncertain) instances with existing AL methods, the intermediate instances with a novel label suggestion scheme using submodular mutual information functions on a per-class basis, and the easy (confident) instances with highest-confidence auto-labeling, CLARIFIER can improve over the performance of existing AL approaches on multiple datasets -- particularly on those that have a large number of classes -- by almost 1.5$\times$ to 2$\times$ in terms of relative labeling cost.
        <a class="is-size-7" onclick="document.getElementById('2306.01277v1-abstract-full').style.display = 'none'; document.getElementById('2306.01277v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        14 pages, 8 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.01250">
         arXiv:2306.01250
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.01250">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.01250">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">
         cs.SE
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Code Learning: Benchmarking Sample-Efficient Training of Code Models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hu%2C+Q">
        Qiang Hu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Guo%2C+Y">
        Yuejun Guo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xie%2C+X">
        Xiaofei Xie
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cordy%2C+M">
        Maxime Cordy
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ma%2C+L">
        Lei Ma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Papadakis%2C+M">
        Mike Papadakis
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Traon%2C+Y+L">
        Yves Le Traon
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.01250v1-abstract-short" style="display: inline;">
        …software engineering (ML4Code), especially for those with limited budgets. Therefore, efficiently training models of code with less human effort has become an emergent problem.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.01250v1-abstract-full').style.display = 'inline'; document.getElementById('2306.01250v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.01250v1-abstract-full" style="display: none;">
        The costly human effort required to prepare the training data of machine learning (ML) models hinders their practical development and usage in software engineering (ML4Code), especially for those with limited budgets. Therefore, efficiently training models of code with less human effort has become an emergent problem.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is such a technique to address this issue that allows developers to train a model with reduced data while producing models with desired performance, which has been well studied in computer vision and natural language processing domains. Unfortunately, there is no such work that explores the effectiveness of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for code models. In this paper, we bridge this gap by building the first benchmark to study this critical problem - active code learning. Specifically, we collect 11 acquisition functions~(which are used for data selection in
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        ) from existing works and adapt them for code-related tasks. Then, we conduct an empirical study to check whether these acquisition functions maintain performance for code data. The results demonstrate that feature selection highly affects
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and using output vectors to select data is the best choice. For the code summarization task, active code learning is ineffective which produces models with over a 29.64\% gap compared to the expected performance. Furthermore, we explore future directions of active code learning with an exploratory study. We propose to replace distance calculation methods with evaluation metrics and find a correlation between these evaluation-based distance methods and the performance of code models.
        <a class="is-size-7" onclick="document.getElementById('2306.01250v1-abstract-full').style.display = 'none'; document.getElementById('2306.01250v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       1 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 pages, ongoing work
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.01006">
         arXiv:2306.01006
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.01006">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.01006">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Scaling Evidence-based Instructional Design Expertise through Large Language Models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yadav%2C+G">
        Gautam Yadav
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.01006v2-abstract-short" style="display: inline;">
        …ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT-4 in creating complex higher-order assessments and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        components for different courses. From our experiences, we provide best practices for effectively using LLMs in instructional d…
        <a class="is-size-7" onclick="document.getElementById('2306.01006v2-abstract-full').style.display = 'inline'; document.getElementById('2306.01006v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.01006v2-abstract-full" style="display: none;">
        This paper presents a comprehensive exploration of leveraging Large Language Models (LLMs), specifically GPT-4, in the field of instructional design. With a focus on scaling evidence-based instructional design expertise, our research aims to bridge the gap between theoretical educational studies and practical implementation. We discuss the benefits and limitations of AI-driven content generation, emphasizing the necessity of human oversight in ensuring the quality of educational materials. This work is elucidated through two detailed case studies where we applied GPT-4 in creating complex higher-order assessments and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        components for different courses. From our experiences, we provide best practices for effectively using LLMs in instructional design tasks, such as utilizing templates, fine-tuning, handling unexpected output, implementing LLM chains, citing references, evaluating output, creating rubrics, grading, and generating distractors. We also share our vision of a future recommendation system, where a customized GPT-4 extracts instructional design principles from educational studies and creates personalized, evidence-supported strategies for users' unique educational contexts. Our research contributes to understanding and optimally harnessing the potential of AI-driven language models in enhancing educational outcomes.
        <a class="is-size-7" onclick="document.getElementById('2306.01006v2-abstract-full').style.display = 'none'; document.getElementById('2306.01006v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 31 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.00945">
         arXiv:2306.00945
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.00945">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.00945">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Numerical Analysis">
         math.NA
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       CS4ML: A general framework for
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       with arbitrary data based on Christoffel functions
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Adcock%2C+B">
        Ben Adcock
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cardenas%2C+J+M">
        Juan M. Cardenas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dexter%2C+N">
        Nick Dexter
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.00945v2-abstract-short" style="display: inline;">
        We introduce a general framework for
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2306.00945v2-abstract-full').style.display = 'inline'; document.getElementById('2306.00945v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.00945v2-abstract-full" style="display: none;">
        We introduce a general framework for
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in regression problems. Our framework extends the standard setup by allowing for general types of data, rather than merely pointwise samples of the target function. This generalization covers many cases of practical interest, such as data acquired in transform domains (e.g., Fourier data), vector-valued data (e.g., gradient-augmented data), data acquired along continuous curves, and, multimodal data (i.e., combinations of different types of measurements). Our framework considers random sampling according to a finite number of sampling measures and arbitrary nonlinear approximation spaces (model classes). We introduce the concept of generalized Christoffel functions and show how these can be used to optimize the sampling measures. We prove that this leads to near-optimal sample complexity in various important cases. This paper focuses on applications in scientific computing, where
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is often desirable, since it is usually expensive to generate data. We demonstrate the efficacy of our framework for gradient-augmented learning with polynomials, Magnetic Resonance Imaging (MRI) using generative models and adaptive sampling for solving PDEs using Physics-Informed Neural Networks (PINNs).
        <a class="is-size-7" onclick="document.getElementById('2306.00945v2-abstract-full').style.display = 'none'; document.getElementById('2306.00945v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 December, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 1 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.00128">
         arXiv:2306.00128
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.00128">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.00128">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A set of moment tensor potentials for zirconium with increasing complexity
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Luo%2C+Y">
        Yu Luo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Meziere%2C+J+A">
        Jason A. Meziere
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Samolyuk%2C+G+D">
        German D. Samolyuk
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hart%2C+G+L+W">
        Gus L. W. Hart
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Daymond%2C+M+R">
        Mark R Daymond
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=B%C3%A9land%2C+L+K">
        Laurent Karim Béland
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.00128v1-abstract-short" style="display: inline;">
        …choice for atomistic simulations due to their high fidelity and improvable nature. Here, we propose a hybrid small-cell approach that combines attributes of both offline and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to systematically expand a quantum mechanical (QM) database while constructing MLFFs with increasing model complexity. Our MLFFs e…
        <a class="is-size-7" onclick="document.getElementById('2306.00128v1-abstract-full').style.display = 'inline'; document.getElementById('2306.00128v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.00128v1-abstract-full" style="display: none;">
        Machine learning force fields (MLFFs) are an increasingly popular choice for atomistic simulations due to their high fidelity and improvable nature. Here, we propose a hybrid small-cell approach that combines attributes of both offline and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to systematically expand a quantum mechanical (QM) database while constructing MLFFs with increasing model complexity. Our MLFFs employ the moment tensor potential formalism. During this process, we quantitatively assessed structural properties, elastic properties, dimer potential energies, melting temperatures, phase stability, point defect formation energies, point defect migration energies, free surface energies, and generalized stacking fault (GSF) energies of Zr as predicted by our MLFFs. Unsurprisingly, model complexity has a positive correlation with prediction accuracy. We also find that the MLFFs wee able to predict the properties of out-of-sample configurations without directly including these specific configurations in the training dataset. Additionally, we generated 100 MLFFs of high complexity (1513 parameters each) that reached different local optima during training. Their predictions cluster around the benchmark DFT values, but subtle physical features such as the location of local minima on the GSFE surface are washed out by statistical noise.
        <a class="is-size-7" onclick="document.getElementById('2306.00128v1-abstract-full').style.display = 'none'; document.getElementById('2306.00128v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       31 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2306.00096">
         arXiv:2306.00096
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2306.00096">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2306.00096">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Pareto Front Identification with Regret Minimization
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+W">
        Wonyoung Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Iyengar%2C+G">
        Garud Iyengar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zeevi%2C+A">
        Assaf Zeevi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2306.00096v1-abstract-short" style="display: inline;">
        …are not dominated by any of the others when the mean reward vector is a linear function of the context. PFILin includes the best arm identification problem and multi-objective
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        as special cases. The sample complexity of our proposed algorithm is $\tilde{O}(d/Δ^2)$, where $d$ is the dimension of contexts…
        <a class="is-size-7" onclick="document.getElementById('2306.00096v1-abstract-full').style.display = 'inline'; document.getElementById('2306.00096v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2306.00096v1-abstract-full" style="display: none;">
        We consider Pareto front identification for linear bandits (PFILin) where the goal is to identify a set of arms whose reward vectors are not dominated by any of the others when the mean reward vector is a linear function of the context. PFILin includes the best arm identification problem and multi-objective
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        as special cases. The sample complexity of our proposed algorithm is $\tilde{O}(d/Δ^2)$, where $d$ is the dimension of contexts and $Δ$ is a measure of problem complexity. Our sample complexity is optimal up to a logarithmic factor. A novel feature of our algorithm is that it uses the contexts of all actions. In addition to efficiently identifying the Pareto front, our algorithm also guarantees $\tilde{O}(\sqrt{d/t})$ bound for instantaneous Pareto regret when the number of samples is larger than $Ω(d\log dL)$ for $L$ dimensional vector rewards. By using the contexts of all arms, our proposed algorithm simultaneously provides efficient Pareto front identification and regret minimization. Numerical experiments demonstrate that the proposed algorithm successfully identifies the Pareto front while minimizing the regret.
        <a class="is-size-7" onclick="document.getElementById('2306.00096v1-abstract-full').style.display = 'none'; document.getElementById('2306.00096v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       31 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       June 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        25 pages including appendix
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.20050">
         arXiv:2305.20050
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.20050">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.20050">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Let's Verify Step by Step
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Lightman%2C+H">
        Hunter Lightman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kosaraju%2C+V">
        Vineet Kosaraju
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Burda%2C+Y">
        Yura Burda
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Edwards%2C+H">
        Harri Edwards
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Baker%2C+B">
        Bowen Baker
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lee%2C+T">
        Teddy Lee
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Leike%2C+J">
        Jan Leike
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schulman%2C+J">
        John Schulman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sutskever%2C+I">
        Ilya Sutskever
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cobbe%2C+K">
        Karl Cobbe
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.20050v1-abstract-short" style="display: inline;">
        …problems from the challenging MATH dataset. Our process-supervised model solves 78% of problems from a representative subset of the MATH test set. Additionally, we show that
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        significantly improves the efficacy of process supervision. To support related research, we also release PRM800K, the complete dat…
        <a class="is-size-7" onclick="document.getElementById('2305.20050v1-abstract-full').style.display = 'inline'; document.getElementById('2305.20050v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.20050v1-abstract-full" style="display: none;">
        In recent years, large language models have greatly improved in their ability to perform complex multi-step reasoning. However, even state-of-the-art models still regularly produce logical mistakes. To train more reliable models, we can turn either to outcome supervision, which provides feedback for a final result, or process supervision, which provides feedback for each intermediate reasoning step. Given the importance of training reliable models, and given the high cost of human feedback, it is important to carefully compare the both methods. Recent work has already begun this comparison, but many questions still remain. We conduct our own investigation, finding that process supervision significantly outperforms outcome supervision for training models to solve problems from the challenging MATH dataset. Our process-supervised model solves 78% of problems from a representative subset of the MATH test set. Additionally, we show that
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        significantly improves the efficacy of process supervision. To support related research, we also release PRM800K, the complete dataset of 800,000 step-level human feedback labels used to train our best reward model.
        <a class="is-size-7" onclick="document.getElementById('2305.20050v1-abstract-full').style.display = 'none'; document.getElementById('2305.20050v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       31 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.19885">
         arXiv:2305.19885
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.19885">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.19885">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Methodology">
         stat.ME
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applications">
         stat.AP
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation">
         stat.CO
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Reliability analysis of arbitrary systems based on
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       and global sensitivity analysis
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Moustapha%2C+M">
        Maliki Moustapha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Parisi%2C+P">
        Pietro Parisi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Marelli%2C+S">
        Stefano Marelli
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sudret%2C+B">
        Bruno Sudret
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.19885v1-abstract-short" style="display: inline;">
        System reliability analysis aims at computing the probability of failure of an engineering system given a set of uncertain inputs and limit state functions.
        <span class="search-hit mathjax">
         Active
        </span>
        -…
        <a class="is-size-7" onclick="document.getElementById('2305.19885v1-abstract-full').style.display = 'inline'; document.getElementById('2305.19885v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.19885v1-abstract-full" style="display: none;">
        System reliability analysis aims at computing the probability of failure of an engineering system given a set of uncertain inputs and limit state functions.
        <span class="search-hit mathjax">
         Active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        solution schemes have been shown to be a viable tool but as of yet they are not as efficient as in the context of component reliability analysis. This is due to some peculiarities of system problems, such as the presence of multiple failure modes and their uneven contribution to failure, or the dependence on the system configuration (e.g., series or parallel). In this work, we propose a novel
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy designed for solving general system reliability problems. This algorithm combines subset simulation and Kriging/PC-Kriging, and relies on an enrichment scheme tailored to specifically address the weaknesses of this class of methods. More specifically, it relies on three components: (i) a new learning function that does not require the specification of the system configuration, (ii) a density-based clustering technique that allows one to automatically detect the different failure modes, and (iii) sensitivity analysis to estimate the contribution of each limit state to system failure so as to select only the most relevant ones for enrichment. The proposed method is validated on two analytical examples and compared against results gathered in the literature. Finally, a complex engineering problem related to power transmission is solved, thereby showcasing the efficiency of the proposed method in a real-case scenario.
        <a class="is-size-7" onclick="document.getElementById('2305.19885v1-abstract-full').style.display = 'none'; document.getElementById('2305.19885v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       31 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Report number:
       </span>
       RSUQ-2023-002A
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.19344">
         arXiv:2305.19344
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.19344">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.19344">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       infoVerse: A Universal Framework for Dataset Characterization with Multidimensional Meta-information
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+J">
        Jaehyung Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kim%2C+Y">
        Yekyung Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=de+Langis%2C+K">
        Karin de Langis
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shin%2C+J">
        Jinwoo Shin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kang%2C+D">
        Dongyeop Kang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.19344v2-abstract-short" style="display: inline;">
        …Additionally, we propose a novel sampling method on infoVerse to select a set of data points that maximizes informativeness. In three real-world applications (data pruning,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , and data annotation), the samples chosen on infoVerse space consistently outperform strong baselines in all applications. Our cod…
        <a class="is-size-7" onclick="document.getElementById('2305.19344v2-abstract-full').style.display = 'inline'; document.getElementById('2305.19344v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.19344v2-abstract-full" style="display: none;">
        The success of NLP systems often relies on the availability of large, high-quality datasets. However, not all samples in these datasets are equally valuable for learning, as some may be redundant or noisy. Several methods for characterizing datasets based on model-driven meta-information (e.g., model's confidence) have been developed, but the relationship and complementary effects of these methods have received less attention. In this paper, we introduce infoVerse, a universal framework for dataset characterization, which provides a new feature space that effectively captures multidimensional characteristics of datasets by incorporating various model-driven meta-information. infoVerse reveals distinctive regions of the dataset that are not apparent in the original semantic space, hence guiding users (or models) in identifying which samples to focus on for exploration, assessment, or annotation. Additionally, we propose a novel sampling method on infoVerse to select a set of data points that maximizes informativeness. In three real-world applications (data pruning,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , and data annotation), the samples chosen on infoVerse space consistently outperform strong baselines in all applications. Our code and demo are publicly available.
        <a class="is-size-7" onclick="document.getElementById('2305.19344v2-abstract-full').style.display = 'none'; document.getElementById('2305.19344v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 30 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        26 pages, accepted at ACL 2023 conference as a full paper
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.19267">
         arXiv:2305.19267
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.19267">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.19267">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cosmology and Nongalactic Astrophysics">
         astro-ph.CO
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Instrumentation and Methods for Astrophysics">
         astro-ph.IM
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Parallelized Acquisition for
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       using Monte Carlo Sampling
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Torrado%2C+J">
        Jesús Torrado
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sch%C3%B6neberg%2C+N">
        Nils Schöneberg
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gammal%2C+J+E">
        Jonas El Gammal
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.19267v1-abstract-short" style="display: inline;">
        Bayesian inference remains one of the most important tool-kits for any scientist, but increasingly expensive likelihood functions are required for ever-more complex experiments, raising the cost of generating a Monte Carlo sample of the posterior. Recent attention has been directed towards the use of emulators of the posterior based on Gaussian Process (GP) regression combined with active sampling…
        <a class="is-size-7" onclick="document.getElementById('2305.19267v1-abstract-full').style.display = 'inline'; document.getElementById('2305.19267v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.19267v1-abstract-full" style="display: none;">
        Bayesian inference remains one of the most important tool-kits for any scientist, but increasingly expensive likelihood functions are required for ever-more complex experiments, raising the cost of generating a Monte Carlo sample of the posterior. Recent attention has been directed towards the use of emulators of the posterior based on Gaussian Process (GP) regression combined with active sampling to achieve comparable precision with far fewer costly likelihood evaluations. Key to this approach is the batched acquisition of proposals, so that the true posterior can be evaluated in parallel. This is usually achieved via sequential maximization of the highly multimodal acquisition function. Unfortunately, this approach parallelizes poorly and is prone to getting stuck in local maxima. Our approach addresses this issue by generating nearly-optimal batches of candidates using an almost-embarrassingly parallel Nested Sampler on the mean prediction of the GP. The resulting nearly-sorted Monte Carlo sample is used to generate a batch of candidates ranked according to their sequentially conditioned acquisition function values at little cost. The final sample can also be used for inferring marginal quantities. Our proposed implementation (NORA) demonstrates comparable accuracy to sequential conditioned acquisition optimization and efficient parallelization in various synthetic and cosmological inference problems.
        <a class="is-size-7" onclick="document.getElementById('2305.19267v1-abstract-full').style.display = 'none'; document.getElementById('2305.19267v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        21 pages, 10 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.18905">
         arXiv:2305.18905
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.18905">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/ps/2305.18905">
          ps
         </a>
         ,
         <a href="https://arxiv.org/format/2305.18905">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       atTRACTive: Semi-automatic white matter tract segmentation using
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Peretzke%2C+R">
        Robin Peretzke
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Maier-Hein%2C+K">
        Klaus Maier-Hein
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bohn%2C+J">
        Jonas Bohn
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kirchhoff%2C+Y">
        Yannick Kirchhoff
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Roy%2C+S">
        Saikat Roy
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Oberli-Palma%2C+S">
        Sabrina Oberli-Palma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Becker%2C+D">
        Daniela Becker
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lenga%2C+P">
        Pavlina Lenga
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Neher%2C+P">
        Peter Neher
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.18905v3-abstract-short" style="display: inline;">
        …such as preoperative planning, wherefore time-consuming and challenging manual delineation of the target tract is typically employed. We propose semi-automatic entropy-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for quick and intuitive segmentation of white matter tracts from whole-brain tractography consisting of millions of streamlines. T…
        <a class="is-size-7" onclick="document.getElementById('2305.18905v3-abstract-full').style.display = 'inline'; document.getElementById('2305.18905v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.18905v3-abstract-full" style="display: none;">
        Accurately identifying white matter tracts in medical images is essential for various applications, including surgery planning and tract-specific analysis. Supervised machine learning models have reached state-of-the-art solving this task automatically. However, these models are primarily trained on healthy subjects and struggle with strong anatomical aberrations, e.g. caused by brain tumors. This limitation makes them unsuitable for tasks such as preoperative planning, wherefore time-consuming and challenging manual delineation of the target tract is typically employed. We propose semi-automatic entropy-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for quick and intuitive segmentation of white matter tracts from whole-brain tractography consisting of millions of streamlines. The method is evaluated on 21 openly available healthy subjects from the Human Connectome Project and an internal dataset of ten neurosurgical cases. With only a few annotations, the proposed approach enables segmenting tracts on tumor cases comparable to healthy subjects (dice=0.71), while the performance of automatic methods, like TractSeg dropped substantially (dice=0.34) in comparison to healthy subjects. The method is implemented as a prototype named atTRACTive in the freely available software MITK Diffusion. Manual experiments on tumor data showed higher efficiency due to lower segmentation times compared to traditional ROI-based segmentation.
        <a class="is-size-7" onclick="document.getElementById('2305.18905v3-abstract-full').style.display = 'none'; document.getElementById('2305.18905v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       3 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 30 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.17874">
         arXiv:2305.17874
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.17874">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.17874">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Ab initio investigation of the crystallization mechanism of cadmium selenide
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">
        Linshuang Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+M">
        Manyi Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">
        Shiwei Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Niu%2C+H">
        Haiyang Niu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.17874v1-abstract-short" style="display: inline;">
        …crystallization mechanism of CdSe. Unfortunately, such studies are still absent in the literature.To overcome this limitation, we employed an enhanced sampling-accelerated
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach to construct a deep neural potential with ab initio accuracy for studying the crystallization of CdSe.Our brute-force molec…
        <a class="is-size-7" onclick="document.getElementById('2305.17874v1-abstract-full').style.display = 'inline'; document.getElementById('2305.17874v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.17874v1-abstract-full" style="display: none;">
        Cadmium selenide (CdSe) is an inorganic semiconductor with unique optical and electronic properties that made it useful in various applications, including solar cells, light-emitting diodes, and biofluorescent tagging. In order to synthesize high-quality crystals and subsequently integrate them into devices, it is crucial to understand the atomic scale crystallization mechanism of CdSe. Unfortunately, such studies are still absent in the literature.To overcome this limitation, we employed an enhanced sampling-accelerated
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach to construct a deep neural potential with ab initio accuracy for studying the crystallization of CdSe.Our brute-force molecular dynamics simulations revealed that a spherical-like nucleus formed spontaneously and stochastically, resulting in a stacking disordered structure where the competition between hexagonal wurtzite and cubic zinc blende polymorphs is temperature-dependent. We found that pure hexagonal crystal can only be obtained approximately above 1430 K, which is 35 K below its melting temperature. We observed that the solidification dynamics of Cd and Se atoms were distinct due to their different diffusion coefficients. The solidification process was initiated by lower mobile Se atoms forming tetrahedral frameworks, followed by Cd atoms occupying these tetrahedral centers and settling down until the third-shell neighbor of Se atoms sited on their lattice positions. Therefore, the medium-range ordering of Se atoms governs the crystallization process of CdSe. Our findings indicate that understanding the complex dynamical process is the key to comprehending the crystallization mechanism of compounds like CdSe, and can shed lights in the synthesis of high-quality crystals.
        <a class="is-size-7" onclick="document.getElementById('2305.17874v1-abstract-full').style.display = 'none'; document.getElementById('2305.17874v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        25 pages, 7 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.17742">
         arXiv:2305.17742
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.17742">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.17742">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Formal Languages and Automata Theory">
         cs.FL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       of Deterministic Timed Automata with Myhill-Nerode Style Characterization
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Waga%2C+M">
        Masaki Waga
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.17742v1-abstract-short" style="display: inline;">
        We present an algorithm to learn a deterministic timed automaton (DTA) via membership and equivalence queries. Our algorithm is an extension of the L* algorithm with a Myhill-Nerode style characterization of recognizable timed languages, which is the class of timed languages recognizable by DTAs. We first characterize the recognizable timed languages with a Nerode-style congruence. Using it, we gi…
        <a class="is-size-7" onclick="document.getElementById('2305.17742v1-abstract-full').style.display = 'inline'; document.getElementById('2305.17742v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.17742v1-abstract-full" style="display: none;">
        We present an algorithm to learn a deterministic timed automaton (DTA) via membership and equivalence queries. Our algorithm is an extension of the L* algorithm with a Myhill-Nerode style characterization of recognizable timed languages, which is the class of timed languages recognizable by DTAs. We first characterize the recognizable timed languages with a Nerode-style congruence. Using it, we give an algorithm with a smart teacher answering symbolic membership queries in addition to membership and equivalence queries. With a symbolic membership query, one can ask the membership of a certain set of timed words at one time. We prove that for any recognizable timed language, our learning algorithm returns a DTA recognizing it. We show how to answer a symbolic membership query with finitely many membership queries. We also show that our learning algorithm requires a polynomial number of queries with a smart teacher and an exponential number of queries with a normal teacher. We applied our algorithm to various benchmarks and confirmed its effectiveness with a normal teacher.
        <a class="is-size-7" onclick="document.getElementById('2305.17742v1-abstract-full').style.display = 'none'; document.getElementById('2305.17742v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.17520">
         arXiv:2305.17520
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.17520">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.17520">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       USIM-DAL: Uncertainty-aware Statistical Image Modeling-based Dense
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Super-resolution
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rangnekar%2C+V">
        Vikrant Rangnekar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Upadhyay%2C+U">
        Uddeshya Upadhyay
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Akata%2C+Z">
        Zeynep Akata
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Banerjee%2C+B">
        Biplab Banerjee
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.17520v1-abstract-short" style="display: inline;">
        …enhancement, depth estimation, etc. However, the high cost of annotation and labeling makes it challenging to achieve accurate results. We propose incorporating
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.17520v1-abstract-full').style.display = 'inline'; document.getElementById('2305.17520v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.17520v1-abstract-full" style="display: none;">
        Dense regression is a widely used approach in computer vision for tasks such as image super-resolution, enhancement, depth estimation, etc. However, the high cost of annotation and labeling makes it challenging to achieve accurate results. We propose incorporating
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        into dense regression models to address this problem.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        allows models to select the most informative samples for labeling, reducing the overall annotation cost while improving performance. Despite its potential,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        has not been widely explored in high-dimensional computer vision regression tasks like super-resolution. We address this research gap and propose a new framework called USIM-DAL that leverages the statistical properties of colour images to learn informative priors using probabilistic deep neural networks that model the heteroscedastic predictive distribution allowing uncertainty quantification. Moreover, the aleatoric uncertainty from the network serves as a proxy for error that is used for
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Our experiments on a wide variety of datasets spanning applications in natural images (visual genome, BSD100), medical imaging (histopathology slides), and remote sensing (satellite images) demonstrate the efficacy of the newly proposed USIM-DAL and superiority over several dense regression
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods.
        <a class="is-size-7" onclick="document.getElementById('2305.17520v1-abstract-full').style.display = 'none'; document.getElementById('2305.17520v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at UAI 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.17013">
         arXiv:2305.17013
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.17013">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.17013">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       D-CALM: A Dynamic Clustering-based
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Approach for Mitigating Bias
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hassan%2C+S">
        Sabit Hassan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Alikhani%2C+M">
        Malihe Alikhani
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.17013v1-abstract-short" style="display: inline;">
        …can propagate through the annotation process. Escalated integration of these models in our lives calls for methods to mitigate bias without overbearing annotation costs. While
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.17013v1-abstract-full').style.display = 'inline'; document.getElementById('2305.17013v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.17013v1-abstract-full" style="display: none;">
        Despite recent advancements, NLP models continue to be vulnerable to bias. This bias often originates from the uneven distribution of real-world data and can propagate through the annotation process. Escalated integration of these models in our lives calls for methods to mitigate bias without overbearing annotation costs. While
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) has shown promise in training models with a small amount of annotated data, AL's reliance on the model's behavior for selective sampling can lead to an accumulation of unwanted bias rather than bias mitigation. However, infusing clustering with AL can overcome the bias issue of both AL and traditional annotation methods while exploiting AL's annotation efficiency. In this paper, we propose a novel adaptive clustering-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm, D-CALM, that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate. Experiments on eight datasets for a diverse set of text classification tasks, including emotion, hatespeech, dialog act, and book type detection, demonstrate that our proposed algorithm significantly outperforms baseline AL approaches with both pretrained transformers and traditional Support Vector Machines. D-CALM showcases robustness against different measures of information gain and, as evident from our analysis of label and error distribution, can significantly reduce unwanted model bias.
        <a class="is-size-7" onclick="document.getElementById('2305.17013v1-abstract-full').style.display = 'none'; document.getElementById('2305.17013v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       26 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        ACL FINDINGS 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.16334">
         arXiv:2305.16334
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.16334">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.16334">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Xie%2C+Y">
        Yuanzhen Xie
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xie%2C+T">
        Tao Xie
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lin%2C+M">
        Mingxiong Lin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wei%2C+W">
        WenTao Wei
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+C">
        Chenglin Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kong%2C+B">
        Beibei Kong
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+L">
        Lei Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhuo%2C+C">
        Chengxiang Zhuo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hu%2C+B">
        Bo Hu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Z">
        Zang Li
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.16334v1-abstract-short" style="display: inline;">
        …approximating different cognitive modules, including attention, memory, reasoning, learning, and corresponding scheduling and decision-making mechanisms. Inspired by the
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        mechanism of human beings, it proposes a learning unit to record previous mistakes and expert opinions, and dynamically refer to them…
        <a class="is-size-7" onclick="document.getElementById('2305.16334v1-abstract-full').style.display = 'inline'; document.getElementById('2305.16334v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.16334v1-abstract-full" style="display: none;">
        In most current research, large language models (LLMs) are able to perform reasoning tasks by generating chains of thought through the guidance of specific prompts. However, there still exists a significant discrepancy between their capability in solving complex reasoning problems and that of humans. At present, most approaches focus on chains of thought (COT) and tool use, without considering the adoption and application of human cognitive frameworks. It is well-known that when confronting complex reasoning challenges, humans typically employ various cognitive abilities, and necessitate interaction with all aspects of tools, knowledge, and the external environment information to accomplish intricate tasks. This paper introduces a novel intelligent framework, referred to as OlaGPT. OlaGPT carefully studied a cognitive architecture framework, and propose to simulate certain aspects of human cognition. The framework involves approximating different cognitive modules, including attention, memory, reasoning, learning, and corresponding scheduling and decision-making mechanisms. Inspired by the
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        mechanism of human beings, it proposes a learning unit to record previous mistakes and expert opinions, and dynamically refer to them to strengthen their ability to solve similar problems. The paper also outlines common effective reasoning frameworks for human problem-solving and designs Chain-of-Thought (COT) templates accordingly. A comprehensive decision-making mechanism is also proposed to maximize model accuracy. The efficacy of OlaGPT has been stringently evaluated on multiple reasoning datasets, and the experimental outcomes reveal that OlaGPT surpasses state-of-the-art benchmarks, demonstrating its superior performance. Our implementation of OlaGPT is available on GitHub: \url{https://github.com/oladata-team/OlaGPT}.
        <a class="is-size-7" onclick="document.getElementById('2305.16334v1-abstract-full').style.display = 'none'; document.getElementById('2305.16334v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.16312">
         arXiv:2305.16312
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.16312">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.16312">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">
         cs.GR
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1109/CVPR52729.2023.00558">
           10.1109/CVPR52729.2023.00558
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       UMat: Uncertainty-Aware Single Image High Resolution Material Capture
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rodriguez-Pardo%2C+C">
        Carlos Rodriguez-Pardo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dominguez-Elvira%2C+H">
        Henar Dominguez-Elvira
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pascual-Hernandez%2C+D">
        David Pascual-Hernandez
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Garces%2C+E">
        Elena Garces
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.16312v1-abstract-short" style="display: inline;">
        …uncertainty in material digitization, increasing the trustworthiness of the process and enabling more intelligent strategies for dataset creation, as we demonstrate with an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        experiment.
        <a class="is-size-7" onclick="document.getElementById('2305.16312v1-abstract-full').style.display = 'inline'; document.getElementById('2305.16312v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.16312v1-abstract-full" style="display: none;">
        We propose a learning-based method to recover normals, specularity, and roughness from a single diffuse image of a material, using microgeometry appearance as our primary cue. Previous methods that work on single images tend to produce over-smooth outputs with artifacts, operate at limited resolution, or train one model per class with little room for generalization. Previous methods that work on single images tend to produce over-smooth outputs with artifacts, operate at limited resolution, or train one model per class with little room for generalization. In contrast, in this work, we propose a novel capture approach that leverages a generative network with attention and a U-Net discriminator, which shows outstanding performance integrating global information at reduced computational complexity. We showcase the performance of our method with a real dataset of digitized textile materials and show that a commodity flatbed scanner can produce the type of diffuse illumination required as input to our method. Additionally, because the problem might be illposed -- more than a single diffuse image might be needed to disambiguate the specular reflection -- or because the training dataset is not representative enough of the real distribution, we propose a novel framework to quantify the model's confidence about its prediction at test time. Our method is the first one to deal with the problem of modeling uncertainty in material digitization, increasing the trustworthiness of the process and enabling more intelligent strategies for dataset creation, as we demonstrate with an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        experiment.
        <a class="is-size-7" onclick="document.getElementById('2305.16312v1-abstract-full').style.display = 'none'; document.getElementById('2305.16312v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       25 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        CVPR 2023. Project website: https://carlosrodriguezpardo.es/projects/UMat/
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        MSC Class:
       </span>
       68T07 (Primary) 68T45; 68U10; 68U05 (Secondary)
       <span class="has-text-black-bis has-text-weight-semibold">
        ACM Class:
       </span>
       I.4.0; I.2.6; I.3.0
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Vancouver, BC, Canada, 2023 pp. 5764-5774
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.15846">
         arXiv:2305.15846
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.15846">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.15846">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Astrophysics of Galaxies">
         astro-ph.GA
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1063/5.0150379">
           10.1063/5.0150379
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A machine learning potential for simulating infrared spectra of nanosilicate clusters
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tang%2C+Z">
        Zeyuan Tang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bromley%2C+S+T">
        Stefan T. Bromley
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hammer%2C+B">
        Bjørk Hammer
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.15846v1-abstract-short" style="display: inline;">
        …potential for nanosilicate clusters. Initial training data are taken from normal modes and farthest point sampling. Later on, the set of training data is extended via an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy in which new data are identified by the disagreement between an ensemble of ML models. The whole process is further accelerat…
        <a class="is-size-7" onclick="document.getElementById('2305.15846v1-abstract-full').style.display = 'inline'; document.getElementById('2305.15846v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.15846v1-abstract-full" style="display: none;">
        The use of machine learning (ML) in chemical physics has enabled the construction of interatomic potentials having the accuracy of ab initio methods and a computational cost comparable to that of classical force fields. Training an ML model requires an efficient method for the generation of training data. Here we apply an accurate and efficient protocol to collect training data for constructing a neural network based ML interatomic potential for nanosilicate clusters. Initial training data are taken from normal modes and farthest point sampling. Later on, the set of training data is extended via an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy in which new data are identified by the disagreement between an ensemble of ML models. The whole process is further accelerated by parallel sampling over structures. We use the ML model to run molecular dynamics (MD) simulations of nanosilicate clusters with various sizes, from which infrared spectra with anharmonicity included can be extracted. Such spectroscopic data are needed for understanding the properties of silicate dust grains in the interstellar medium (ISM) and in circumstellar environments.
        <a class="is-size-7" onclick="document.getElementById('2305.15846v1-abstract-full').style.display = 'none'; document.getElementById('2305.15846v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       25 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        11 pages, 8 figures, accpected by J. Chem. Phys
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.15040">
         arXiv:2305.15040
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.15040">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.15040">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Natural Language Generation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Perlitz%2C+Y">
        Yotam Perlitz
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gera%2C+A">
        Ariel Gera
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shmueli-Scheuer%2C+M">
        Michal Shmueli-Scheuer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sheinwald%2C+D">
        Dafna Sheinwald
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Slonim%2C+N">
        Noam Slonim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ein-Dor%2C+L">
        Liat Ein-Dor
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.15040v2-abstract-short" style="display: inline;">
        …a severe shortage of labeled data due to the extremely expensive and time-consuming process involved in manual annotation. A natural approach for coping with this problem is
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.15040v2-abstract-full').style.display = 'inline'; document.getElementById('2305.15040v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.15040v2-abstract-full" style="display: none;">
        The field of Natural Language Generation (NLG) suffers from a severe shortage of labeled data due to the extremely expensive and time-consuming process involved in manual annotation. A natural approach for coping with this problem is
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL), a well-known machine learning technique for improving annotation efficiency by selectively choosing the most informative examples to label. However, while AL has been well-researched in the context of text classification, its application to NLG remains largely unexplored. In this paper, we present a first systematic study of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for NLG, considering a diverse set of tasks and multiple leading selection strategies, and harnessing a strong instruction-tuned model. Our results indicate that the performance of existing AL strategies is inconsistent, surpassing the baseline of random example selection in some cases but not in others. We highlight some notable differences between the classification and generation scenarios, and analyze the selection behaviors of existing AL strategies. Our findings motivate exploring novel approaches for applying AL to generation tasks.
        <a class="is-size-7" onclick="document.getElementById('2305.15040v2-abstract-full').style.display = 'none'; document.getElementById('2305.15040v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 24 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to EMNLP2023 as a long paper
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.14691">
         arXiv:2305.14691
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.14691">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.14691">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Label-Efficient Learning in Agriculture: A Comprehensive Review
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+J">
        Jiajia Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+D">
        Dong Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Qi%2C+X">
        Xinda Qi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Z">
        Zhaojian Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">
        Yanbo Huang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Morris%2C+D">
        Daniel Morris
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tan%2C+X">
        Xiaobo Tan
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.14691v1-abstract-short" style="display: inline;">
        …applications. To this end, we first develop a principled taxonomy to organize these methods according to the degree of supervision, including weak supervision (i.e.,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and semi-/weakly- supervised learning), and no supervision (i.e., un-/self- supervised learning), supplemented by representative state-of-…
        <a class="is-size-7" onclick="document.getElementById('2305.14691v1-abstract-full').style.display = 'inline'; document.getElementById('2305.14691v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.14691v1-abstract-full" style="display: none;">
        The past decade has witnessed many great successes of machine learning (ML) and deep learning (DL) applications in agricultural systems, including weed control, plant disease diagnosis, agricultural robotics, and precision livestock management. Despite tremendous progresses, one downside of such ML/DL models is that they generally rely on large-scale labeled datasets for training, and the performance of such models is strongly influenced by the size and quality of available labeled data samples. In addition, collecting, processing, and labeling such large-scale datasets is extremely costly and time-consuming, partially due to the rising cost in human labor. Therefore, developing label-efficient ML/DL methods for agricultural applications has received significant interests among researchers and practitioners. In fact, there are more than 50 papers on developing and applying deep-learning-based label-efficient techniques to address various agricultural problems since 2016, which motivates the authors to provide a timely and comprehensive review of recent label-efficient ML/DL methods in agricultural applications. To this end, we first develop a principled taxonomy to organize these methods according to the degree of supervision, including weak supervision (i.e.,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and semi-/weakly- supervised learning), and no supervision (i.e., un-/self- supervised learning), supplemented by representative state-of-the-art label-efficient ML/DL methods. In addition, a systematic review of various agricultural applications exploiting these label-efficient algorithms, such as precision agriculture, plant phenotyping, and postharvest quality assessment, is presented. Finally, we discuss the current problems and challenges, as well as future research directions. A well-classified paper list can be accessed at https://github.com/DongChen06/Label-efficient-in-Agriculture.
        <a class="is-size-7" onclick="document.getElementById('2305.14691v1-abstract-full').style.display = 'none'; document.getElementById('2305.14691v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        34 pages, 23 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.14576">
         arXiv:2305.14576
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.14576">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.14576">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Parameter-Efficient Language Model Tuning with
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in Low-Resource Settings
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Juki%C4%87%2C+J">
        Josip Jukić
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=%C5%A0najder%2C+J">
        Jan Šnajder
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.14576v2-abstract-short" style="display: inline;">
        Pre-trained language models (PLMs) have ignited a surge in demand for effective fine-tuning techniques, particularly in low-resource domains and languages.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL), a set of algorithms designed to decrease labeling costs by minimizing label complexity, has shown promise in confronting the labeling bottlene…
        <a class="is-size-7" onclick="document.getElementById('2305.14576v2-abstract-full').style.display = 'inline'; document.getElementById('2305.14576v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.14576v2-abstract-full" style="display: none;">
        Pre-trained language models (PLMs) have ignited a surge in demand for effective fine-tuning techniques, particularly in low-resource domains and languages.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL), a set of algorithms designed to decrease labeling costs by minimizing label complexity, has shown promise in confronting the labeling bottleneck. In parallel, adapter modules designed for parameter-efficient fine-tuning (PEFT) have demonstrated notable potential in low-resource settings. However, the interplay between AL and adapter-based PEFT remains unexplored. We present an empirical study of PEFT behavior with AL in low-resource settings for text classification tasks. Our findings affirm the superiority of PEFT over full-fine tuning (FFT) in low-resource settings and demonstrate that this advantage persists in AL setups. We further examine the properties of PEFT and FFT through the lens of forgetting dynamics and instance-level representations, where we find that PEFT yields more stable representations of early and middle layers compared to FFT. Our research underscores the synergistic potential of AL and PEFT in low-resource settings, paving the way for advancements in efficient and effective fine-tuning.
        <a class="is-size-7" onclick="document.getElementById('2305.14576v2-abstract-full').style.display = 'none'; document.getElementById('2305.14576v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 23 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at EMNLP 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.14264">
         arXiv:2305.14264
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.14264">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.14264">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Principles for In-Context Learning with Large Language Models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Margatina%2C+K">
        Katerina Margatina
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schick%2C+T">
        Timo Schick
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Aletras%2C+N">
        Nikolaos Aletras
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dwivedi-Yu%2C+J">
        Jane Dwivedi-Yu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.14264v2-abstract-short" style="display: inline;">
        …limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) problem over a single iteration. Our objective is to investigate how AL algorithms can serve as effective demonstration selectio…
        <a class="is-size-7" onclick="document.getElementById('2305.14264v2-abstract-full').style.display = 'inline'; document.getElementById('2305.14264v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.14264v2-abstract-full" style="display: none;">
        The remarkable advancements in large language models (LLMs) have significantly enhanced the performance in few-shot learning settings. By using only a small number of labeled examples, referred to as demonstrations, LLMs can effectively grasp the task at hand through in-context learning. However, the process of selecting appropriate demonstrations has received limited attention in prior work. This paper addresses the issue of identifying the most informative demonstrations for few-shot learning by approaching it as a pool-based
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) problem over a single iteration. Our objective is to investigate how AL algorithms can serve as effective demonstration selection methods for in-context learning. We compare various standard AL algorithms based on uncertainty, diversity, and similarity, and consistently observe that the latter outperforms all other methods, including random sampling. Notably, uncertainty sampling, despite its success in conventional supervised learning scenarios, performs poorly in this context. Our extensive experimentation involving a diverse range of GPT and OPT models across $24$ classification and multi-choice tasks, coupled with thorough analysis, unambiguously demonstrates that in-context example selection through AL prioritizes high-quality examples that exhibit low uncertainty and bear similarity to the test examples.
        <a class="is-size-7" onclick="document.getElementById('2305.14264v2-abstract-full').style.display = 'none'; document.getElementById('2305.14264v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       22 November, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 23 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        To appear at Findings of EMNLP (Camera Ready version)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.14169">
         arXiv:2305.14169
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.14169">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.14169">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       EASE: An Easily-Customized Annotation System Powered by Efficiency Enhancement Mechanisms
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Deng%2C+N">
        Naihao Deng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">
        Yikai Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+M">
        Mingye Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+W">
        Winston Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+S">
        Siyang Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">
        Yulong Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">
        Yue Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mihalcea%2C+R">
        Rada Mihalcea
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.14169v1-abstract-short" style="display: inline;">
        …are usually collected through annotation tools, which are often designed for specific tasks and are difficult to customize. Moreover, existing annotation tools with an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.14169v1-abstract-full').style.display = 'inline'; document.getElementById('2305.14169v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.14169v1-abstract-full" style="display: none;">
        The performance of current supervised AI systems is tightly connected to the availability of annotated datasets. Annotations are usually collected through annotation tools, which are often designed for specific tasks and are difficult to customize. Moreover, existing annotation tools with an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        mechanism often only support limited use cases. To address these limitations, we present EASE, an Easily-Customized Annotation System Powered by Efficiency Enhancement Mechanisms. \sysname provides modular annotation units for building customized annotation interfaces and also provides multiple back-end options that suggest annotations using (1) multi-task
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        ; (2) demographic feature based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        ; (3) a prompt system that can query the API of large language models. We conduct multiple experiments and user studies to evaluate our system's flexibility and effectiveness. Our results show that our system can meet the diverse needs of NLP researchers and significantly accelerate the annotation process.
        <a class="is-size-7" onclick="document.getElementById('2305.14169v1-abstract-full').style.display = 'none'; document.getElementById('2305.14169v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        20 pages
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.13402">
         arXiv:2305.13402
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.13402">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.13402">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">
         cs.DS
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=DePavia%2C+A+F">
        Adela Frances DePavia
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=del+Campo%2C+O+M+M">
        Olga Medrano Martín del Campo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tani%2C+E">
        Erasmo Tani
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.13402v2-abstract-short" style="display: inline;">
        This paper initiates the study of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for exact recovery of partitions exclusively through access to a same-cluster oracle in the presence of bounded adversarial error. We first highlight a novel connection between learning partitions and correlation clustering. Then we use this connection to build a Rényi-…
        <a class="is-size-7" onclick="document.getElementById('2305.13402v2-abstract-full').style.display = 'inline'; document.getElementById('2305.13402v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.13402v2-abstract-full" style="display: none;">
        This paper initiates the study of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for exact recovery of partitions exclusively through access to a same-cluster oracle in the presence of bounded adversarial error. We first highlight a novel connection between learning partitions and correlation clustering. Then we use this connection to build a Rényi-Ulam style analytical framework for this problem, and prove upper and lower bounds on its worst-case query complexity. Further, we bound the expected performance of a relevant randomized algorithm. Finally, we study the relationship between adaptivity and query complexity for this problem and related variants.
        <a class="is-size-7" onclick="document.getElementById('2305.13402v2-abstract-full').style.display = 'none'; document.getElementById('2305.13402v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       16 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 22 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        28 pages, 2 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.13342">
         arXiv:2305.13342
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.13342">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.13342">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       On the Limitations of Simulating
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Margatina%2C+K">
        Katerina Margatina
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Aletras%2C+N">
        Nikolaos Aletras
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.13342v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.13342v1-abstract-full').style.display = 'inline'; document.getElementById('2305.13342v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.13342v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) is a human-and-model-in-the-loop paradigm that iteratively selects informative unlabeled data for human annotation, aiming to improve over random sampling. However, performing AL experiments with human annotations on-the-fly is a laborious and expensive process, thus unrealistic for academic research. An easy fix to this impediment is to simulate AL, by treating an already labeled and publicly available dataset as the pool of unlabeled data. In this position paper, we first survey recent literature and highlight the challenges across all different steps within the AL loop. We further unveil neglected caveats in the experimental setup that can significantly affect the quality of AL research. We continue with an exploration of how the simulation setting can govern empirical findings, arguing that it might be one of the answers behind the ever posed question ``why do
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms sometimes fail to outperform random sampling?''. We argue that evaluating AL algorithms on available labeled datasets might provide a lower bound as to their effectiveness in real data. We believe it is essential to collectively shape the best practices for AL research, particularly as engineering advancements in LLMs push the research focus towards data-driven approaches (e.g., data efficiency, alignment, fairness). In light of this, we have developed guidelines for future work. Our aim is to draw attention to these limitations within the community, in the hope of finding ways to address them.
        <a class="is-size-7" onclick="document.getElementById('2305.13342v1-abstract-full').style.display = 'none'; document.getElementById('2305.13342v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        To appear at Findings of ACL 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.12737">
         arXiv:2305.12737
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.12737">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.12737">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       The Best of Both Worlds: Combining Human and Machine Translations for Multilingual Semantic Parsing with
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+Z">
        Zhuang Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Qu%2C+L">
        Lizhen Qu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cohen%2C+P+R">
        Philip R. Cohen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tumuluri%2C+R+V">
        Raj V. Tumuluri
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Haffari%2C+G">
        Gholamreza Haffari
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.12737v1-abstract-short" style="display: inline;">
        …or machines to alleviate such issues. However, human translations are expensive, while machine translations are cheap but prone to error and bias. In this work, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.12737v1-abstract-full').style.display = 'inline'; document.getElementById('2305.12737v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.12737v1-abstract-full" style="display: none;">
        Multilingual semantic parsing aims to leverage the knowledge from the high-resource languages to improve low-resource semantic parsing, yet commonly suffers from the data imbalance problem. Prior works propose to utilize the translations by either humans or machines to alleviate such issues. However, human translations are expensive, while machine translations are cheap but prone to error and bias. In this work, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach that exploits the strengths of both human and machine translations by iteratively adding small batches of human translations into the machine-translated training set. Besides, we propose novel aggregated acquisition criteria that help our
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method select utterances to be manually translated. Our experiments demonstrate that an ideal utterance selection can significantly reduce the error and bias in the translated data, resulting in higher parser accuracies than the parsers merely trained on the machine-translated data.
        <a class="is-size-7" onclick="document.getElementById('2305.12737v1-abstract-full').style.display = 'none'; document.getElementById('2305.12737v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       22 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        ACL 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.12710">
         arXiv:2305.12710
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.12710">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.12710">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel
       <span class="search-hit mathjax">
        Active
       </span>
       -
       <span class="search-hit mathjax">
        Learning
       </span>
       Architecture
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yao%2C+B">
        Bingsheng Yao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jindal%2C+I">
        Ishan Jindal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Popa%2C+L">
        Lucian Popa
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Katsis%2C+Y">
        Yannis Katsis
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ghosh%2C+S">
        Sayan Ghosh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=He%2C+L">
        Lihong He
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lu%2C+Y">
        Yuxuan Lu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Srivastava%2C+S">
        Shashank Srivastava
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Y">
        Yunyao Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hendler%2C+J">
        James Hendler
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+D">
        Dakuo Wang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.12710v2-abstract-short" style="display: inline;">
        …(e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data poin…
        <a class="is-size-7" onclick="document.getElementById('2305.12710v2-abstract-full').style.display = 'inline'; document.getElementById('2305.12710v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.12710v2-abstract-full" style="display: none;">
        Real-world domain experts (e.g., doctors) rarely annotate only a decision label in their day-to-day workflow without providing explanations. Yet, existing low-resource learning techniques, such as
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL), that aim to support human annotators mostly focus on the label while neglecting the natural language explanation of a data point. This work proposes a novel AL architecture to support experts' real-world need for label and explanation annotations in low-resource scenarios. Our AL architecture leverages an explanation-generation model to produce explanations guided by human explanations, a prediction model that utilizes generated explanations toward prediction faithfully, and a novel data diversity-based AL sampling strategy that benefits from the explanation annotations. Automated and human evaluations demonstrate the effectiveness of incorporating explanations into AL sampling and the improved human annotation efficiency and trustworthiness with our AL architecture. Additional ablation studies illustrate the potential of our AL architecture for transfer learning, generalizability, and integration with large language models (LLMs). While LLMs exhibit exceptional explanation-generation capabilities for relatively simple tasks, their effectiveness in complex real-world tasks warrants further in-depth study.
        <a class="is-size-7" onclick="document.getElementById('2305.12710v2-abstract-full').style.display = 'none'; document.getElementById('2305.12710v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 22 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to EMNLP 2023 Findings
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.12634">
         arXiv:2305.12634
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.12634">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.12634">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Data-efficient
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Structured Prediction with Partial Annotation and Self-Training
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">
        Zhisong Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Strubell%2C+E">
        Emma Strubell
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hovy%2C+E">
        Eduard Hovy
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.12634v2-abstract-short" style="display: inline;">
        In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-trainin…
        <a class="is-size-7" onclick="document.getElementById('2305.12634v2-abstract-full').style.display = 'inline'; document.getElementById('2305.12634v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.12634v2-abstract-full" style="display: none;">
        In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.
        <a class="is-size-7" onclick="document.getElementById('2305.12634v2-abstract-full').style.display = 'none'; document.getElementById('2305.12634v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       18 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 21 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Findings of EMNLP 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.11890">
         arXiv:2305.11890
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.11890">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">
         cs.CY
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Enhancing Chemistry Learning with ChatGPT and Bing Chat as Agents to Think With: A Comparative Case Study
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Santos%2C+R+P+d">
        Renato P. dos Santos
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.11890v1-abstract-short" style="display: inline;">
        …comprehension, creativity, and personalised learning experiences. By employing a Socratic-like questioning approach, GenAIbots nurture students' curiosity and promote
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . The study emphasises the significance of prompt crafting, a technique to elicit desired responses from GenAIbots, fostering iterativ…
        <a class="is-size-7" onclick="document.getElementById('2305.11890v1-abstract-full').style.display = 'inline'; document.getElementById('2305.11890v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.11890v1-abstract-full" style="display: none;">
        This study explores the potential of Generative AI chatbots (GenAIbots) such as ChatGPT and Bing Chat, in Chemistry education, within a constructionist theoretical framework. A single-case study methodology was used to analyse extensive interaction logs between students and both AI systems in simulated Chemistry learning experiences. The results highlight the ability of ChatGPT and Bing Chat to act as 'agents-to-think-with', fostering critical thinking, problem-solving, concept comprehension, creativity, and personalised learning experiences. By employing a Socratic-like questioning approach, GenAIbots nurture students' curiosity and promote
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . The study emphasises the significance of prompt crafting, a technique to elicit desired responses from GenAIbots, fostering iterative reflections and interactions. It underlines the need for comprehensive educator training to effectively integrate these tools into classrooms. The study concludes that while ChatGPT and Bing Chat as agents-to-think-with offer promising avenues to revolutionise STEM education through a constructionist lens, fostering a more interactive, inclusive learning environment and promoting deeper comprehension and critical thinking in students across diverse Chemistry topics, ChatGPT consistently outperformed Bing Chat, providing more comprehensive, detailed, and accurate responses and skillfully addressing nuances and context.
        <a class="is-size-7" onclick="document.getElementById('2305.11890v1-abstract-full').style.display = 'none'; document.getElementById('2305.11890v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        MSC Class:
       </span>
       cs.HC
       <span class="has-text-black-bis has-text-weight-semibold">
        ACM Class:
       </span>
       J.4; K.3
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.10655">
         arXiv:2305.10655
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.10655">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.10655">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1007/978-3-031-17027-0_2">
           10.1007/978-3-031-17027-0_2
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       DeepEdit: Deep Editable Learning for Interactive Segmentation of 3D Medical Images
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Diaz-Pinto%2C+A">
        Andres Diaz-Pinto
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mehta%2C+P">
        Pritesh Mehta
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Alle%2C+S">
        Sachidanand Alle
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Asad%2C+M">
        Muhammad Asad
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Brown%2C+R">
        Richard Brown
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nath%2C+V">
        Vishwesh Nath
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ihsani%2C+A">
        Alvin Ihsani
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Antonelli%2C+M">
        Michela Antonelli
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Palkovics%2C+D">
        Daniel Palkovics
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pinter%2C+C">
        Csaba Pinter
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Alkalay%2C+R">
        Ron Alkalay
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pieper%2C+S">
        Steve Pieper
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Roth%2C+H+R">
        Holger R. Roth
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+D">
        Daguang Xu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dogra%2C+P">
        Prerna Dogra
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Vercauteren%2C+T">
        Tom Vercauteren
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Feng%2C+A">
        Andrew Feng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Quraini%2C+A">
        Abood Quraini
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ourselin%2C+S">
        Sebastien Ourselin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cardoso%2C+M+J">
        M. Jorge Cardoso
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.10655v1-abstract-short" style="display: inline;">
        …e. DeepGrow), into a single deep learning model. It allows easy integration of uncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty computation) and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . We propose and implement a method for training DeepEdit by using standard training combined with user interaction simulation. On…
        <a class="is-size-7" onclick="document.getElementById('2305.10655v1-abstract-full').style.display = 'inline'; document.getElementById('2305.10655v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.10655v1-abstract-full" style="display: none;">
        Automatic segmentation of medical images is a key step for diagnostic and interventional tasks. However, achieving this requires large amounts of annotated volumes, which can be tedious and time-consuming task for expert annotators. In this paper, we introduce DeepEdit, a deep learning-based method for volumetric medical image annotation, that allows automatic and semi-automatic segmentation, and click-based refinement. DeepEdit combines the power of two methods: a non-interactive (i.e. automatic segmentation using nnU-Net, UNET or UNETR) and an interactive segmentation method (i.e. DeepGrow), into a single deep learning model. It allows easy integration of uncertainty-based ranking strategies (i.e. aleatoric and epistemic uncertainty computation) and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . We propose and implement a method for training DeepEdit by using standard training combined with user interaction simulation. Once trained, DeepEdit allows clinicians to quickly segment their datasets by using the algorithm in auto segmentation mode or by providing clicks via a user interface (i.e. 3D Slicer, OHIF). We show the value of DeepEdit through evaluation on the PROSTATEx dataset for prostate/prostatic lesions and the Multi-Atlas Labeling Beyond the Cranial Vault (BTCV) dataset for abdominal CT segmentation, using state-of-the-art network architectures as baseline for comparison. DeepEdit could reduce the time and effort annotating 3D medical images compared to DeepGrow alone. Source code is available at https://github.com/Project-MONAI/MONAILabel
        <a class="is-size-7" onclick="document.getElementById('2305.10655v1-abstract-full').style.display = 'none'; document.getElementById('2305.10655v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.10643">
         arXiv:2305.10643
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.10643">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.10643">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       STREAMLINE: Streaming
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Realistic Multi-Distributional Settings
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Beck%2C+N">
        Nathan Beck
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kothawade%2C+S">
        Suraj Kothawade
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shenoy%2C+P">
        Pradeep Shenoy
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Iyer%2C+R">
        Rishabh Iyer
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.10643v1-abstract-short" style="display: inline;">
        …data instances arrive in and are sampled from an episodic multi-distributional data stream. Using submodular information measures, we propose STREAMLINE, a novel streaming
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework that mitigates scenario-driven slice imbalance in the working labeled data via a three-step procedure of slice identificat…
        <a class="is-size-7" onclick="document.getElementById('2305.10643v1-abstract-full').style.display = 'inline'; document.getElementById('2305.10643v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.10643v1-abstract-full" style="display: none;">
        Deep neural networks have consistently shown great performance in several real-world use cases like autonomous vehicles, satellite imaging, etc., effectively leveraging large corpora of labeled training data. However, learning unbiased models depends on building a dataset that is representative of a diverse range of realistic scenarios for a given task. This is challenging in many settings where data comes from high-volume streams, with each scenario occurring in random interleaved episodes at varying frequencies. We study realistic streaming settings where data instances arrive in and are sampled from an episodic multi-distributional data stream. Using submodular information measures, we propose STREAMLINE, a novel streaming
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework that mitigates scenario-driven slice imbalance in the working labeled data via a three-step procedure of slice identification, slice-aware budgeting, and data selection. We extensively evaluate STREAMLINE on real-world streaming scenarios for image classification and object detection tasks. We observe that STREAMLINE improves the performance on infrequent yet critical slices of the data over current baselines by up to $5\%$ in terms of accuracy on our image classification tasks and by up to $8\%$ in terms of mAP on our object detection tasks.
        <a class="is-size-7" onclick="document.getElementById('2305.10643v1-abstract-full').style.display = 'none'; document.getElementById('2305.10643v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        20 pages, 14 figures, 2 tables
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.10379">
         arXiv:2305.10379
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.10379">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.10379">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">
         cs.NE
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in Symbolic Regression with Physical Constraints
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Medina%2C+J">
        Jorge Medina
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=White%2C+A+D">
        Andrew D. White
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.10379v2-abstract-short" style="display: inline;">
        …symbolic regression (SR) fits a symbolic equation to data, which gives a concise interpretable model. We explore using SR as a method to propose which data to gather in an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.10379v2-abstract-full').style.display = 'inline'; document.getElementById('2305.10379v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.10379v2-abstract-full" style="display: none;">
        Evolutionary symbolic regression (SR) fits a symbolic equation to data, which gives a concise interpretable model. We explore using SR as a method to propose which data to gather in an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        setting with physical constraints. SR with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        proposes which experiments to do next.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is done with query by committee, where the Pareto frontier of equations is the committee. The physical constraints improve proposed equations in very low data settings. These approaches reduce the data required for SR and achieves state of the art results in data required to rediscover known equations.
        <a class="is-size-7" onclick="document.getElementById('2305.10379v2-abstract-full').style.display = 'none'; document.getElementById('2305.10379v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       18 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 17 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.09807">
         arXiv:2305.09807
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.09807">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.09807">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       On Dataset Transferability in
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Transformers
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Jeleni%C4%87%2C+F">
        Fran Jelenić
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Juki%C4%87%2C+J">
        Josip Jukić
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Drobac%2C+N">
        Nina Drobac
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=%C5%A0najder%2C+J">
        Jan Šnajder
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.09807v2-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) aims to reduce labeling costs by querying the examples most beneficial for model learning. While the effectiveness of AL for fine-tuning transformer-based pre-trained language models (PLMs) has been demonstrated, it is less clear to what extent the AL gains obtained with one model transfer to other…
        <a class="is-size-7" onclick="document.getElementById('2305.09807v2-abstract-full').style.display = 'inline'; document.getElementById('2305.09807v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.09807v2-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) aims to reduce labeling costs by querying the examples most beneficial for model learning. While the effectiveness of AL for fine-tuning transformer-based pre-trained language models (PLMs) has been demonstrated, it is less clear to what extent the AL gains obtained with one model transfer to others. We consider the problem of transferability of actively acquired datasets in text classification and investigate whether AL gains persist when a dataset built using AL coupled with a specific PLM is used to train a different PLM. We link the AL dataset transferability to the similarity of instances queried by the different PLMs and show that AL methods with similar acquisition sequences produce highly transferable datasets regardless of the models used. Additionally, we show that the similarity of acquisition sequences is influenced more by the choice of the AL method than the choice of the model.
        <a class="is-size-7" onclick="document.getElementById('2305.09807v2-abstract-full').style.display = 'none'; document.getElementById('2305.09807v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 16 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Findings of the Association for Computational Linguistics: ACL 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.09666">
         arXiv:2305.09666
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.09666">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.09666">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       AbdomenAtlas-8K: Annotating 8,000 CT Volumes for Multi-Organ Segmentation in Three Weeks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Qu%2C+C">
        Chongyu Qu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+T">
        Tiezheng Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Qiao%2C+H">
        Hualin Qiao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+J">
        Jie Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">
        Yucheng Tang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yuille%2C+A">
        Alan Yuille
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhou%2C+Z">
        Zongwei Zhou
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.09666v2-abstract-short" style="display: inline;">
        …and complexity of the organ. Therefore, publicly available datasets for multi-organ segmentation are often limited in data size and organ diversity. This paper proposes an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method to expedite the annotation process for organ segmentation and creates the largest multi-organ dataset (by far) with the sple…
        <a class="is-size-7" onclick="document.getElementById('2305.09666v2-abstract-full').style.display = 'inline'; document.getElementById('2305.09666v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.09666v2-abstract-full" style="display: none;">
        Annotating medical images, particularly for organ segmentation, is laborious and time-consuming. For example, annotating an abdominal organ requires an estimated rate of 30-60 minutes per CT volume based on the expertise of an annotator and the size, visibility, and complexity of the organ. Therefore, publicly available datasets for multi-organ segmentation are often limited in data size and organ diversity. This paper proposes an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method to expedite the annotation process for organ segmentation and creates the largest multi-organ dataset (by far) with the spleen, liver, kidneys, stomach, gallbladder, pancreas, aorta, and IVC annotated in 8,448 CT volumes, equating to 3.2 million slices. The conventional annotation methods would take an experienced annotator up to 1,600 weeks (or roughly 30.8 years) to complete this task. In contrast, our annotation method has accomplished this task in three weeks (based on an 8-hour workday, five days a week) while maintaining a similar or even better annotation quality. This achievement is attributed to three unique properties of our method: (1) label bias reduction using multiple pre-trained segmentation models, (2) effective error detection in the model predictions, and (3) attention guidance for annotators to make corrections on the most salient errors. Furthermore, we summarize the taxonomy of common errors made by AI algorithms and annotators. This allows for continuous revision of both AI and annotations and significantly reduces the annotation costs required to create large-scale datasets for a wider variety of medical imaging tasks.
        <a class="is-size-7" onclick="document.getElementById('2305.09666v2-abstract-full').style.display = 'none'; document.getElementById('2305.09666v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 16 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Conference on Neural Information Processing Systems (NeurIPS 2023)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.08878">
         arXiv:2305.08878
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.08878">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.08878">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Learning to Learn Unlearned Feature for Brain Tumor Segmentation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Han%2C+S">
        Seungyub Han
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kim%2C+Y">
        Yeongmo Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ha%2C+S">
        Seokhyeon Ha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lee%2C+J">
        Jungwoo Lee
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Choi%2C+S">
        Seunghong Choi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.08878v1-abstract-short" style="display: inline;">
        We propose a fine-tuning algorithm for brain tumor segmentation that needs only a few data samples and helps networks not to forget the original tasks. Our approach is based on
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and meta-learning. One of the difficulties in medical image segmentation is the lack of datasets with proper annotations, becau…
        <a class="is-size-7" onclick="document.getElementById('2305.08878v1-abstract-full').style.display = 'inline'; document.getElementById('2305.08878v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.08878v1-abstract-full" style="display: none;">
        We propose a fine-tuning algorithm for brain tumor segmentation that needs only a few data samples and helps networks not to forget the original tasks. Our approach is based on
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and meta-learning. One of the difficulties in medical image segmentation is the lack of datasets with proper annotations, because it requires doctors to tag reliable annotation and there are many variants of a disease, such as glioma and brain metastasis, which are the different types of brain tumor and have different structural features in MR images. Therefore, it is impossible to produce the large-scale medical image datasets for all types of diseases. In this paper, we show a transfer learning method from high grade glioma to brain metastasis, and demonstrate that the proposed algorithm achieves balanced parameters for both glioma and brain metastasis domains within a few steps.
        <a class="is-size-7" onclick="document.getElementById('2305.08878v1-abstract-full').style.display = 'none'; document.getElementById('2305.08878v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       13 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Medical Imaging Meets NeurIPS 2018
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.07818">
         arXiv:2305.07818
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.07818">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.07818">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">
         eess.SY
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       An
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       -based Approach for Hosting Capacity Analysis in Distribution Systems
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Lee%2C+K">
        Kiyeob Lee
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhao%2C+P">
        Peng Zhao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bhattacharya%2C+A">
        Anirban Bhattacharya
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mallick%2C+B+K">
        Bani K. Mallick
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xie%2C+L">
        Le Xie
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.07818v1-abstract-short" style="display: inline;">
        …the two factors (a) and (b) in HCA and by identifying a few most insightful HC scenarios at the cost of domain knowledge. We propose a data-driven HCA framework and introduce
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.07818v1-abstract-full').style.display = 'inline'; document.getElementById('2305.07818v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.07818v1-abstract-full" style="display: none;">
        With the increasing amount of distributed energy resources (DERs) integration, there is a significant need to model and analyze hosting capacity (HC) for future electric distribution grids. Hosting capacity analysis (HCA) examines the amount of DERs that can be safely integrated into the grid and is a challenging task in full generality because there are many possible integration of DERs in foresight. That is, there are numerous extreme points between feasible and infeasible sets. Moreover, HC depends on multiple factors such as (a) adoption patterns of DERs that depend on socio-economic behaviors and (b) how DERs are controlled and managed. These two factors are intrinsic to the problem space because not all integration of DERs may be centrally planned, and could largely change our understanding about HC. This paper addresses the research gap by capturing the two factors (a) and (b) in HCA and by identifying a few most insightful HC scenarios at the cost of domain knowledge. We propose a data-driven HCA framework and introduce
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in HCA to effectively explore scenarios.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in HCA and characteristics of HC with respect to the two factors (a) and (b) are illustrated in a 3-bus example. Next, detailed large-scale studies are proposed to understand the significance of (a) and (b). Our findings suggest that HC and its interpretations significantly change subject to the two factors (a) and (b).
        <a class="is-size-7" onclick="document.getElementById('2305.07818v1-abstract-full').style.display = 'none'; document.getElementById('2305.07818v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.07251">
         arXiv:2305.07251
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.07251">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.07251">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1038/s43588-023-00571-7">
           10.1038/s43588-023-00571-7
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Machine-learning-accelerated simulations to enable automatic surface reconstruction
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Du%2C+X">
        Xiaochen Du
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Damewood%2C+J+K">
        James K. Damewood
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lunger%2C+J+R">
        Jaclyn R. Lunger
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Millan%2C+R">
        Reisel Millan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yildiz%2C+B">
        Bilge Yildiz
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+L">
        Lin Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=G%C3%B3mez-Bombarelli%2C+R">
        Rafael Gómez-Bombarelli
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.07251v2-abstract-short" style="display: inline;">
        …methods. Fast, scalable, and data-efficient machine learning interatomic potentials are trained on high-throughput density-functional theory calculations through closed-loop
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Markov-chain Monte Carlo sampling in the semi-grand canonical ensemble is enabled by using virtual surface sites. The predicted s…
        <a class="is-size-7" onclick="document.getElementById('2305.07251v2-abstract-full').style.display = 'inline'; document.getElementById('2305.07251v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.07251v2-abstract-full" style="display: none;">
        Understanding material surfaces and interfaces is vital in applications like catalysis or electronics. By combining energies from electronic structure with statistical mechanics, ab initio simulations can in principle predict the structure of material surfaces as a function of thermodynamic variables. However, accurate energy simulations are prohibitive when coupled to the vast phase space that must be statistically sampled. Here, we present a bi-faceted computational loop to predict surface phase diagrams of multi-component materials that accelerates both the energy scoring and statistical sampling methods. Fast, scalable, and data-efficient machine learning interatomic potentials are trained on high-throughput density-functional theory calculations through closed-loop
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Markov-chain Monte Carlo sampling in the semi-grand canonical ensemble is enabled by using virtual surface sites. The predicted surfaces for GaN(0001), Si(111), and SrTiO3(001) are in agreement with past work and suggest that the proposed strategy can model complex material surfaces and discover previously unreported surface terminations.
        <a class="is-size-7" onclick="document.getElementById('2305.07251v2-abstract-full').style.display = 'none'; document.getElementById('2305.07251v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 November, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 12 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        30 pages main, 15 figures/tables, 5 pages supplementary
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Nat Comput Sci 2023, 3, 1034
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.07040">
         arXiv:2305.07040
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.07040">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.07040">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Analysis, Statistics and Probability">
         physics.data-an
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Sequential Experimental Design for Spectral Measurement:
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Using a Parametric Model
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Nabika%2C+T">
        Tomohiro Nabika
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nagata%2C+K">
        Kenji Nagata
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Katakami%2C+S">
        Shun Katakami
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mizumaki%2C+M">
        Masaichiro Mizumaki
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Okada%2C+M">
        Masato Okada
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.07040v1-abstract-short" style="display: inline;">
        In this study, we demonstrate a sequential experimental design for spectral measurements by
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.07040v1-abstract-full').style.display = 'inline'; document.getElementById('2305.07040v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.07040v1-abstract-full" style="display: none;">
        In this study, we demonstrate a sequential experimental design for spectral measurements by
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        using parametric models as predictors. In spectral measurements, it is necessary to reduce the measurement time because of sample fragility and high energy costs. To improve the efficiency of experiments, sequential experimental designs are proposed, in which the subsequent measurement is designed by
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        using the data obtained before the measurement. Conventionally, parametric models are employed in data analysis; when employed for
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , they are expected to afford a sequential experimental design that improves the accuracy of data analysis. However, due to the complexity of the formulas, a sequential experimental design using general parametric models has not been realized. Therefore, we applied Bayesian inference-based data analysis using the exchange Monte Carlo method to realize a sequential experimental design with general parametric models. In this study, we evaluated the effectiveness of the proposed method by applying it to Bayesian spectral deconvolution and Bayesian Hamiltonian selection in X-ray photoelectron spectroscopy. Using numerical experiments with artificial data, we demonstrated that the proposed method improves the accuracy of model selection and parameter estimation while reducing the measurement time compared with the results achieved without
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        or with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        using the Gaussian process regression.
        <a class="is-size-7" onclick="document.getElementById('2305.07040v1-abstract-full').style.display = 'none'; document.getElementById('2305.07040v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       11 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.06584">
         arXiv:2305.06584
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.06584">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.06584">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">
         math.OC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in the Predict-then-Optimize Framework: A Margin-Based Approach
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Liu%2C+M">
        Mo Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Grigas%2C+P">
        Paul Grigas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+H">
        Heyuan Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shen%2C+Z+M">
        Zuo-Jun Max Shen
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.06584v1-abstract-short" style="display: inline;">
        We develop the first
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.06584v1-abstract-full').style.display = 'inline'; document.getElementById('2305.06584v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.06584v1-abstract-full" style="display: none;">
        We develop the first
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method in the predict-then-optimize framework. Specifically, we develop a learning method that sequentially decides whether to request the "labels" of feature samples from an unlabeled data stream, where the labels correspond to the parameters of an optimization model for decision-making. Our
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method is the first to be directly informed by the decision error induced by the predicted parameters, which is referred to as the Smart Predict-then-Optimize (SPO) loss. Motivated by the structure of the SPO loss, our algorithm adopts a margin-based criterion utilizing the concept of distance to degeneracy and minimizes a tractable surrogate of the SPO loss on the collected data. In particular, we develop an efficient
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm with both hard and soft rejection variants, each with theoretical excess risk (i.e., generalization) guarantees. We further derive bounds on the label complexity, which refers to the number of samples whose labels are acquired to achieve a desired small level of SPO risk. Under some natural low-noise conditions, we show that these bounds can be better than the naive supervised learning approach that labels all samples. Furthermore, when using the SPO+ loss function, a specialized surrogate of the SPO loss, we derive a significantly smaller label complexity under separability conditions. We also present numerical evidence showing the practical value of our proposed algorithms in the settings of personalized pricing and the shortest path problem.
        <a class="is-size-7" onclick="document.getElementById('2305.06584v1-abstract-full').style.display = 'none'; document.getElementById('2305.06584v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       11 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.06408">
         arXiv:2305.06408
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.06408">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.06408">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Accelerating Batch
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Using Continual Learning Techniques
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Das%2C+A">
        Arnav Das
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bhatt%2C+G">
        Gantavya Bhatt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bhalerao%2C+M">
        Megh Bhalerao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gao%2C+V">
        Vianne Gao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+R">
        Rui Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bilmes%2C+J">
        Jeff Bilmes
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.06408v2-abstract-short" style="display: inline;">
        A major problem with
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.06408v2-abstract-full').style.display = 'inline'; document.getElementById('2305.06408v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.06408v2-abstract-full" style="display: none;">
        A major problem with
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) is high training costs since models are typically retrained from scratch after every query round. We start by demonstrating that standard AL on neural networks with warm starting fails, both to accelerate training and to avoid catastrophic forgetting when using fine-tuning over AL query rounds. We then develop a new class of techniques, circumventing this problem, by biasing further training towards previously labeled sets. We accomplish this by employing existing, and developing novel, replay-based Continual Learning (CL) algorithms that are effective at quickly learning the new without forgetting the old, especially when data comes from an evolving distribution. We call this paradigm Continual
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (CAL). We show CAL achieves significant speedups using a plethora of replay schemes that use model distillation and that select diverse, uncertain points from the history. We conduct experiments across many data domains, including natural language, vision, medical imaging, and computational biology, each with different neural architectures and dataset sizes. CAL consistently provides a 3x reduction in training time, while retaining performance.
        <a class="is-size-7" onclick="document.getElementById('2305.06408v2-abstract-full').style.display = 'none'; document.getElementById('2305.06408v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 December, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 10 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Appeared in TMLR 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.06334">
         arXiv:2305.06334
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.06334">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Biomolecules">
         q-bio.BM
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Optimizing Drug Design by Merging Generative AI With
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Frameworks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Filella-Merce%2C+I">
        Isaac Filella-Merce
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Molina%2C+A">
        Alexis Molina
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Orzechowski%2C+M">
        Marek Orzechowski
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=D%C3%ADaz%2C+L">
        Lucía Díaz
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhu%2C+Y+M">
        Yang Ming Zhu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mor%2C+J+V">
        Julia Vilalta Mor
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Malo%2C+L">
        Laura Malo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yekkirala%2C+A+S">
        Ajay S Yekkirala
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ray%2C+S">
        Soumya Ray
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Guallar%2C+V">
        Victor Guallar
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.06334v1-abstract-short" style="display: inline;">
        …or the lack of synthetic tractability. To improve the applicability domain of GM methods, we have developed a workflow based on a variational autoencoder coupled with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        steps. The designed GM workflow iteratively learns from molecular metrics, including drug likeliness, synthesizability, similarity, and…
        <a class="is-size-7" onclick="document.getElementById('2305.06334v1-abstract-full').style.display = 'inline'; document.getElementById('2305.06334v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.06334v1-abstract-full" style="display: none;">
        Traditional drug discovery programs are being transformed by the advent of machine learning methods. Among these, Generative AI methods (GM) have gained attention due to their ability to design new molecules and enhance specific properties of existing ones. However, current GM methods have limitations, such as low affinity towards the target, unknown ADME/PK properties, or the lack of synthetic tractability. To improve the applicability domain of GM methods, we have developed a workflow based on a variational autoencoder coupled with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        steps. The designed GM workflow iteratively learns from molecular metrics, including drug likeliness, synthesizability, similarity, and docking scores. In addition, we also included a hierarchical set of criteria based on advanced molecular modeling simulations during a final selection step. We tested our GM workflow on two model systems, CDK2 and KRAS. In both cases, our model generated chemically viable molecules with a high predicted affinity toward the targets. Particularly, the proportion of high-affinity molecules inferred by our GM workflow was significantly greater than that in the training data. Notably, we also uncovered novel scaffolds significantly dissimilar to those known for each target. These results highlight the potential of our GM workflow to explore novel chemical space for specific targets, thereby opening up new possibilities for drug discovery endeavors.
        <a class="is-size-7" onclick="document.getElementById('2305.06334v1-abstract-full').style.display = 'none'; document.getElementById('2305.06334v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.04392">
         arXiv:2305.04392
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.04392">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.04392">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Disentangled Multi-Fidelity Deep Bayesian
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Wu%2C+D">
        Dongxia Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Niu%2C+R">
        Ruijia Niu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chinazzi%2C+M">
        Matteo Chinazzi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">
        Yian Ma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yu%2C+R">
        Rose Yu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.04392v3-abstract-short" style="display: inline;">
        To balance quality and cost, various domain areas of science and engineering run simulations at multiple levels of sophistication. Multi-fidelity
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.04392v3-abstract-full').style.display = 'inline'; document.getElementById('2305.04392v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.04392v3-abstract-full" style="display: none;">
        To balance quality and cost, various domain areas of science and engineering run simulations at multiple levels of sophistication. Multi-fidelity
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        aims to learn a direct mapping from input parameters to simulation outputs at the highest fidelity by actively acquiring data from multiple fidelity levels. However, existing approaches based on Gaussian processes are hardly scalable to high-dimensional data. Deep learning-based methods often impose a hierarchical structure in hidden representations, which only supports passing information from low-fidelity to high-fidelity. These approaches can lead to the undesirable propagation of errors from low-fidelity representations to high-fidelity ones. We propose a novel framework called Disentangled Multi-fidelity Deep Bayesian
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (D-MFDAL), which learns the surrogate models conditioned on the distribution of functions at multiple fidelities. On benchmark tasks of learning deep surrogates of partial differential equations including heat equation, Poisson's equation and fluid simulations, our approach significantly outperforms state-of-the-art in prediction accuracy and sample efficiency.
        <a class="is-size-7" onclick="document.getElementById('2305.04392v3-abstract-full').style.display = 'none'; document.getElementById('2305.04392v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 7 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.04049">
         arXiv:2305.04049
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.04049">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.04049">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Actively Discovering New Slots for Task-oriented Conversation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Wu%2C+Y">
        Yuxia Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dai%2C+T">
        Tianhao Dai
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zheng%2C+Z">
        Zhedong Zheng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liao%2C+L">
        Lizi Liao
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.04049v1-abstract-short" style="display: inline;">
        …the high requirement of utilizing such quota efficiently. Hence, we formulate a general new slot discovery task in an information extraction fashion and incorporate it into an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework to realize human-in-the-loop learning. Specifically, we leverage existing language tools to extract value candidates w…
        <a class="is-size-7" onclick="document.getElementById('2305.04049v1-abstract-full').style.display = 'inline'; document.getElementById('2305.04049v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.04049v1-abstract-full" style="display: none;">
        Existing task-oriented conversational search systems heavily rely on domain ontologies with pre-defined slots and candidate value sets. In practical applications, these prerequisites are hard to meet, due to the emerging new user requirements and ever-changing scenarios. To mitigate these issues for better interaction performance, there are efforts working towards detecting out-of-vocabulary values or discovering new slots under unsupervised or semi-supervised learning paradigm. However, overemphasizing on the conversation data patterns alone induces these methods to yield noisy and arbitrary slot results. To facilitate the pragmatic utility, real-world systems tend to provide a stringent amount of human labelling quota, which offers an authoritative way to obtain accurate and meaningful slot assignments. Nonetheless, it also brings forward the high requirement of utilizing such quota efficiently. Hence, we formulate a general new slot discovery task in an information extraction fashion and incorporate it into an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework to realize human-in-the-loop learning. Specifically, we leverage existing language tools to extract value candidates where the corresponding labels are further leveraged as weak supervision signals. Based on these, we propose a bi-criteria selection scheme which incorporates two major strategies, namely, uncertainty-based sampling and diversity-based sampling to efficiently identify terms of interest. We conduct extensive experiments on several public datasets and compare with a bunch of competitive baselines to demonstrate the effectiveness of our method. We have made the code and data used in this paper publicly available.
        <a class="is-size-7" onclick="document.getElementById('2305.04049v1-abstract-full').style.display = 'none'; document.getElementById('2305.04049v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       6 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        11 pages, 5 figures, 3 tables
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.03923">
         arXiv:2305.03923
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.03923">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.03923">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Continual Learning: On Balancing Knowledge Retention and Learnability
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Vu%2C+T">
        Thuy-Trang Vu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Khadivi%2C+S">
        Shahram Khadivi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ghorbanali%2C+M">
        Mahsa Ghorbanali
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Phung%2C+D">
        Dinh Phung
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Haffari%2C+G">
        Gholamreza Haffari
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.03923v2-abstract-short" style="display: inline;">
        …independently, leading to the CL of incoming supervised learning tasks. This paper considers the under-explored problem of active continual learning (ACL) for a sequence of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) tasks, where each incoming task includes a pool of unlabelled data and an annotation budget. We investigate the effectiveness…
        <a class="is-size-7" onclick="document.getElementById('2305.03923v2-abstract-full').style.display = 'inline'; document.getElementById('2305.03923v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.03923v2-abstract-full" style="display: none;">
        Acquiring new knowledge without forgetting what has been learned in a sequence of tasks is the central focus of continual learning (CL). While tasks arrive sequentially, the training data are often prepared and annotated independently, leading to the CL of incoming supervised learning tasks. This paper considers the under-explored problem of active continual learning (ACL) for a sequence of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) tasks, where each incoming task includes a pool of unlabelled data and an annotation budget. We investigate the effectiveness and interplay between several AL and CL algorithms in the domain, class and task-incremental scenarios. Our experiments reveal the trade-off between two contrasting goals of not forgetting the old knowledge and the ability to quickly learn new knowledge in CL and AL, respectively. While conditioning the AL query strategy on the annotations collected for the previous tasks leads to improved task performance on the domain and task incremental learning, our proposed forgetting-learning profile suggests a gap in balancing the effect of AL and CL for the class-incremental scenario.
        <a class="is-size-7" onclick="document.getElementById('2305.03923v2-abstract-full').style.display = 'none'; document.getElementById('2305.03923v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 January, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 6 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.02757">
         arXiv:2305.02757
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.02757">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.02757">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Multi-Domain Learning From Insufficient Annotations
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=He%2C+R">
        Rui He
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+S">
        Shengcai Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+J">
        Jiahao Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=He%2C+S">
        Shan He
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tang%2C+K">
        Ke Tang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.02757v3-abstract-short" style="display: inline;">
        …textual and image multi-domain datasets demonstrate that MDCL brings noticeable improvement over various SP models.Furthermore, MDCL can further be employed in multi-domain
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (MDAL) to achieve a superior initialization, eventually leading to better overall performance.
        <a class="is-size-7" onclick="document.getElementById('2305.02757v3-abstract-full').style.display = 'inline'; document.getElementById('2305.02757v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.02757v3-abstract-full" style="display: none;">
        Multi-domain learning (MDL) refers to simultaneously constructing a model or a set of models on datasets collected from different domains. Conventional approaches emphasize domain-shared information extraction and domain-private information preservation, following the shared-private framework (SP models), which offers significant advantages over single-domain learning. However, the limited availability of annotated data in each domain considerably hinders the effectiveness of conventional supervised MDL approaches in real-world applications. In this paper, we introduce a novel method called multi-domain contrastive learning (MDCL) to alleviate the impact of insufficient annotations by capturing both semantic and structural information from both labeled and unlabeled data.Specifically, MDCL comprises two modules: inter-domain semantic alignment and intra-domain contrast. The former aims to align annotated instances of the same semantic category from distinct domains within a shared hidden space, while the latter focuses on learning a cluster structure of unlabeled instances in a private hidden space for each domain. MDCL is readily compatible with many SP models, requiring no additional model parameters and allowing for end-to-end training. Experimental results across five textual and image multi-domain datasets demonstrate that MDCL brings noticeable improvement over various SP models.Furthermore, MDCL can further be employed in multi-domain
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (MDAL) to achieve a superior initialization, eventually leading to better overall performance.
        <a class="is-size-7" onclick="document.getElementById('2305.02757v3-abstract-full').style.display = 'none'; document.getElementById('2305.02757v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 4 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        This paper has been accepted to ECAI-23
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.02459">
         arXiv:2305.02459
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.02459">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.02459">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Transfer and
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Dissonance Detection: Addressing the Rare-Class Challenge
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Varadarajan%2C+V">
        Vasudha Varadarajan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Juhng%2C+S">
        Swanie Juhng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mahwish%2C+S">
        Syeda Mahwish
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+X">
        Xiaoran Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Luby%2C+J">
        Jonah Luby
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Luhmann%2C+C">
        Christian Luhmann
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schwartz%2C+H+A">
        H. Andrew Schwartz
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.02459v2-abstract-short" style="display: inline;">
        …accuracies with fewer training examples, data acquisition obstacles still persist for rare-class tasks -- when the class label is very infrequent (e.g. &lt; 5% of samples).
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.02459v2-abstract-full').style.display = 'inline'; document.getElementById('2305.02459v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.02459v2-abstract-full" style="display: none;">
        While transformer-based systems have enabled greater accuracies with fewer training examples, data acquisition obstacles still persist for rare-class tasks -- when the class label is very infrequent (e.g. &lt; 5% of samples).
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        has in general been proposed to alleviate such challenges, but choice of selection strategy, the criteria by which rare-class examples are chosen, has not been systematically evaluated. Further, transformers enable iterative transfer-learning approaches. We propose and investigate transfer- and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        solutions to the rare class problem of dissonance detection through utilizing models trained on closely related tasks and the evaluation of acquisition strategies, including a proposed probability-of-rare-class (PRC) approach. We perform these experiments for a specific rare class problem: collecting language samples of cognitive dissonance from social media. We find that PRC is a simple and effective strategy to guide annotations and ultimately improve model accuracy while transfer-learning in a specific order can improve the cold-start performance of the learner but does not benefit iterations of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        .
        <a class="is-size-7" onclick="document.getElementById('2305.02459v2-abstract-full').style.display = 'none'; document.getElementById('2305.02459v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 3 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.01754">
         arXiv:2305.01754
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.01754">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.01754">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1038/s41524-023-01180-8">
           10.1038/s41524-023-01180-8
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Single-model uncertainty quantification in neural network potentials does not consistently outperform model ensembles
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tan%2C+A+R">
        Aik Rui Tan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Urata%2C+S">
        Shingo Urata
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Goldman%2C+S">
        Samuel Goldman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dietschreit%2C+J+C+B">
        Johannes C. B. Dietschreit
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=G%C3%B3mez-Bombarelli%2C+R">
        Rafael Gómez-Bombarelli
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.01754v1-abstract-short" style="display: inline;">
        …that disrupt simulations, or to biased statistics and dynamics that do not reflect the true physics. Differentiable UQ techniques can find new informative data and drive
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.01754v1-abstract-full').style.display = 'inline'; document.getElementById('2305.01754v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.01754v1-abstract-full" style="display: none;">
        Neural networks (NNs) often assign high confidence to their predictions, even for points far out-of-distribution, making uncertainty quantification (UQ) a challenge. When they are employed to model interatomic potentials in materials systems, this problem leads to unphysical structures that disrupt simulations, or to biased statistics and dynamics that do not reflect the true physics. Differentiable UQ techniques can find new informative data and drive
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        loops for robust potentials. However, a variety of UQ techniques, including newly developed ones, exist for atomistic simulations and there are no clear guidelines for which are most effective or suitable for a given case. In this work, we examine multiple UQ schemes for improving the robustness of NN interatomic potentials (NNIPs) through
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . In particular, we compare incumbent ensemble-based methods against strategies that use single, deterministic NNs: mean-variance estimation, deep evidential regression, and Gaussian mixture models. We explore three datasets ranging from in-domain interpolative learning to more extrapolative out-of-domain generalization challenges: rMD17, ammonia inversion, and bulk silica glass. Performance is measured across multiple metrics relating model error to uncertainty. Our experiments show that none of the methods consistently outperformed each other across the various metrics. Ensembling remained better at generalization and for NNIP robustness; MVE only proved effective for in-domain interpolation, while GMM was better out-of-domain; and evidential regression, despite its promise, was not the preferable alternative in any of the cases. More broadly, cost-effective, single deterministic models cannot yet consistently match or outperform ensembling for uncertainty quantification in NNIPs.
        <a class="is-size-7" onclick="document.getElementById('2305.01754v1-abstract-full').style.display = 'none'; document.getElementById('2305.01754v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        27 pages, 4 figures, Supporting Information (22 pages)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.01503">
         arXiv:2305.01503
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.01503">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.01503">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">
         cs.IR
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">
         cs.CY
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       NewsPanda: Media Monitoring for Timely Conservation Action
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Keh%2C+S+S">
        Sedrick Scott Keh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shi%2C+Z+R">
        Zheyuan Ryan Shi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Patterson%2C+D+J">
        David J. Patterson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bhagabati%2C+N">
        Nirmal Bhagabati
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dewan%2C+K">
        Karun Dewan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gopala%2C+A">
        Areendran Gopala
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Izquierdo%2C+P">
        Pablo Izquierdo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mallick%2C+D">
        Debojyoti Mallick
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sharma%2C+A">
        Ambika Sharma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shrestha%2C+P">
        Pooja Shrestha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Fang%2C+F">
        Fei Fang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.01503v1-abstract-short" style="display: inline;">
        …a toolkit which automatically detects and analyzes online articles related to environmental conservation and infrastructure construction. We fine-tune a BERT-based model using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods and noise correction algorithms to identify articles that are relevant to conservation and infrastructure construction.…
        <a class="is-size-7" onclick="document.getElementById('2305.01503v1-abstract-full').style.display = 'inline'; document.getElementById('2305.01503v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.01503v1-abstract-full" style="display: none;">
        Non-governmental organizations for environmental conservation have a significant interest in monitoring conservation-related media and getting timely updates about infrastructure construction projects as they may cause massive impact to key conservation areas. Such monitoring, however, is difficult and time-consuming. We introduce NewsPanda, a toolkit which automatically detects and analyzes online articles related to environmental conservation and infrastructure construction. We fine-tune a BERT-based model using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods and noise correction algorithms to identify articles that are relevant to conservation and infrastructure construction. For the identified articles, we perform further analysis, extracting keywords and finding potentially related sources. NewsPanda has been successfully deployed by the World Wide Fund for Nature teams in the UK, India, and Nepal since February 2022. It currently monitors over 80,000 websites and 1,074 conservation sites across India and Nepal, saving more than 30 hours of human efforts weekly. We have now scaled it up to cover 60,000 conservation sites globally.
        <a class="is-size-7" onclick="document.getElementById('2305.01503v1-abstract-full').style.display = 'none'; document.getElementById('2305.01503v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to IAAI-23: 35th Annual Conference on Innovative Applications of Artificial Intelligence. Winner of IAAI Deployed Application Award. Code at https://github.com/NewsPanda-WWF-CMU/weekly-pipeline
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.01145">
         arXiv:2305.01145
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.01145">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.01145">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ADVISE: AI-accelerated Design of Evidence Synthesis for Global Development
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Edwards%2C+K+M">
        Kristen M. Edwards
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Song%2C+B">
        Binyang Song
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Porciello%2C+J">
        Jaron Porciello
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Engelbert%2C+M">
        Mark Engelbert
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Huang%2C+C">
        Carolyn Huang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ahmed%2C+F">
        Faez Ahmed
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.01145v1-abstract-short" style="display: inline;">
        …the effectiveness of the human-AI hybrid team in accelerating the evidence synthesis process. To further improve team efficiency, we enhance the human-AI hybrid team through
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL). Specifically, we explore different sampling strategies, including random sampling, least confidence (LC) sampling, and highe…
        <a class="is-size-7" onclick="document.getElementById('2305.01145v1-abstract-full').style.display = 'inline'; document.getElementById('2305.01145v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.01145v1-abstract-full" style="display: none;">
        When designing evidence-based policies and programs, decision-makers must distill key information from a vast and rapidly growing literature base. Identifying relevant literature from raw search results is time and resource intensive, and is often done by manual screening. In this study, we develop an AI agent based on a bidirectional encoder representations from transformers (BERT) model and incorporate it into a human team designing an evidence synthesis product for global development. We explore the effectiveness of the human-AI hybrid team in accelerating the evidence synthesis process. To further improve team efficiency, we enhance the human-AI hybrid team through
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL). Specifically, we explore different sampling strategies, including random sampling, least confidence (LC) sampling, and highest priority (HP) sampling, to study their influence on the collaborative screening process. Results show that incorporating the BERT-based AI agent into the human team can reduce the human screening effort by 68.5% compared to the case of no AI assistance and by 16.8% compared to the case of using a support vector machine (SVM)-based AI agent for identifying 80% of all relevant documents. When we apply the HP sampling strategy for AL, the human screening effort can be reduced even more: by 78.3% for identifying 80% of all relevant documents compared to no AI assistance. We apply the AL-enhanced human-AI hybrid teaming workflow in the design process of three evidence gap maps (EGMs) for USAID and find it to be highly effective. These findings demonstrate how AI can accelerate the development of evidence synthesis products and promote timely evidence-based decision making in global development in a human-AI hybrid teaming context.
        <a class="is-size-7" onclick="document.getElementById('2305.01145v1-abstract-full').style.display = 'none'; document.getElementById('2305.01145v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       1 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        14 pages, 11 figures, to be published in the proceedings of IDETC-CIE 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.00609">
         arXiv:2305.00609
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.00609">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.00609">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Physics Education">
         physics.ed-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Group Dynamics in Inquiry-based Labs: Gender Inequities and the Efficacy of Partner Agreements
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Dew%2C+M">
        Matthew Dew
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hunt%2C+E">
        Emma Hunt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Perera%2C+V">
        Viranga Perera
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Perry%2C+J">
        Jonathan Perry
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ponti%2C+G">
        Gregorio Ponti
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Loveridge%2C+A">
        Andrew Loveridge
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.00609v4-abstract-short" style="display: inline;">
        Recent studies provide evidence that social constructivist pedagogical methods such as
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , interactive engagement, and inquiry-based learning, while pedagogically more effective, can enable inequities in the classroom. By conducting a quantitative empirical examination of gender-inequitable group dynamics…
        <a class="is-size-7" onclick="document.getElementById('2305.00609v4-abstract-full').style.display = 'inline'; document.getElementById('2305.00609v4-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.00609v4-abstract-full" style="display: none;">
        Recent studies provide evidence that social constructivist pedagogical methods such as
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , interactive engagement, and inquiry-based learning, while pedagogically more effective, can enable inequities in the classroom. By conducting a quantitative empirical examination of gender-inequitable group dynamics in two inquiry-based physics labs, we extend results of previous work. Using a survey on group work preferences and video recordings of lab sessions, we find similar patterns of gendered role-taking noted in prior studies. These results are not reducible to differences in students' preferences. We find that an intervention which employed partner agreement forms, with the goal of reducing inequities, had a positive impact on students' engagement with equipment during a first-semester lab course. Our work will inform implementation of more effective interventions in the future and emphasizes challenges faced by instructors who are dedicated to both research-based pedagogical practices and efforts to promote diversity, equity, and inclusion in their classrooms.
        <a class="is-size-7" onclick="document.getElementById('2305.00609v4-abstract-full').style.display = 'none'; document.getElementById('2305.00609v4-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       10 January, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 30 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        21 pages, 8 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2305.00111">
         arXiv:2305.00111
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2305.00111">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2305.00111">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">
         eess.SP
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1145/3580252.3586979">
           10.1145/3580252.3586979
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Reinforcement Learning for Personalized Stress Monitoring in Everyday Settings
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tazarv%2C+A">
        Ali Tazarv
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Labbaf%2C+S">
        Sina Labbaf
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rahmani%2C+A">
        Amir Rahmani
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dutt%2C+N">
        Nikil Dutt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Levorato%2C+M">
        Marco Levorato
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2305.00111v1-abstract-short" style="display: inline;">
        …personal improvement. In this paper, we consider a fine-grain stress detection problem based on wearable sensors targeting everyday settings, and propose a novel context-aware
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2305.00111v1-abstract-full').style.display = 'inline'; document.getElementById('2305.00111v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2305.00111v1-abstract-full" style="display: none;">
        Most existing sensor-based monitoring frameworks presume that a large available labeled dataset is processed to train accurate detection models. However, in settings where personalization is necessary at deployment time to fine-tune the model, a person-specific dataset needs to be collected online by interacting with the users. Optimizing the collection of labels in such phase is instrumental to impose a tolerable burden on the users while maximizing personal improvement. In this paper, we consider a fine-grain stress detection problem based on wearable sensors targeting everyday settings, and propose a novel context-aware
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy capable of jointly maximizing the meaningfulness of the signal samples we request the user to label and the response rate. We develop a multilayered sensor-edge-cloud platform to periodically capture physiological signals and process them in real-time, as well as to collect labels and retrain the detection model. We collect a large dataset and show that the context-aware
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        technique we propose achieves a desirable detection performance using 88\% and 32\% fewer queries from users compared to a randomized strategy and a traditional
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy, respectively.
        <a class="is-size-7" onclick="document.getElementById('2305.00111v1-abstract-full').style.display = 'none'; document.getElementById('2305.00111v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       May 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted paper at CHASE '23
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.13144">
         arXiv:2304.13144
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.13144">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.13144">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Atomic Physics">
         physics.atom-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       MLIP-3:
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       on atomic environments with Moment Tensor Potentials
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Podryabinkin%2C+E">
        Evgeny Podryabinkin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Garifullin%2C+K">
        Kamil Garifullin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shapeev%2C+A">
        Alexander Shapeev
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Novikov%2C+I">
        Ivan Novikov
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.13144v3-abstract-short" style="display: inline;">
        …potentials and performing their active training. This package builds on the MLIP-2 package (Novikov et al. (2020), The MLIP package: moment tensor potentials with MPI and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.13144v3-abstract-full').style.display = 'inline'; document.getElementById('2304.13144v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.13144v3-abstract-full" style="display: none;">
        Nowadays, academic research relies not only on sharing with the academic community the scientific results obtained by research groups while studying certain phenomena, but also on sharing computer codes developed within the community. In the field of atomistic modeling these were software packages for classical atomistic modeling, later -- quantum-mechanical modeling, and now with the fast growth of the field of machine-learning potentials, the packages implementing such potentials. In this paper we present the MLIP-3 package for constructing moment tensor potentials and performing their active training. This package builds on the MLIP-2 package (Novikov et al. (2020), The MLIP package: moment tensor potentials with MPI and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Machine Learning: Science and Technology, 2(2), 025002.), however with a number of improvements, including
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        on atomic neighborhoods of a possibly large atomistic simulation.
        <a class="is-size-7" onclick="document.getElementById('2304.13144v3-abstract-full').style.display = 'none'; document.getElementById('2304.13144v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 25 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.13076">
         arXiv:2304.13076
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.13076">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.13076">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1038/s41467-023-42992-y">
           10.1038/s41467-023-42992-y
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       On the redundancy in large material datasets: efficient and robust learning with less data
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+K">
        Kangming Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Persaud%2C+D">
        Daniel Persaud
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Choudhary%2C+K">
        Kamal Choudhary
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=DeCost%2C+B">
        Brian DeCost
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Greenwood%2C+M">
        Michael Greenwood
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hattrick-Simpers%2C+J">
        Jason Hattrick-Simpers
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.13076v2-abstract-short" style="display: inline;">
        …related to over-represented material types and does not mitigate the severe performance degradation on out-of-distribution samples. In addition, we show that uncertainty-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms can construct much smaller but equally informative datasets. We discuss the effectiveness of informative data in impr…
        <a class="is-size-7" onclick="document.getElementById('2304.13076v2-abstract-full').style.display = 'inline'; document.getElementById('2304.13076v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.13076v2-abstract-full" style="display: none;">
        Extensive efforts to gather materials data have largely overlooked potential data redundancy. In this study, we present evidence of a significant degree of redundancy across multiple large datasets for various material properties, by revealing that up to 95 % of data can be safely removed from machine learning training with little impact on in-distribution prediction performance. The redundant data is related to over-represented material types and does not mitigate the severe performance degradation on out-of-distribution samples. In addition, we show that uncertainty-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithms can construct much smaller but equally informative datasets. We discuss the effectiveness of informative data in improving prediction performance and robustness and provide insights into efficient data acquisition and machine learning training. This work challenges the "bigger is better" mentality and calls for attention to the information richness of materials data rather than a narrow emphasis on data volume.
        <a class="is-size-7" onclick="document.getElementById('2304.13076v2-abstract-full').style.display = 'none'; document.getElementById('2304.13076v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       25 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 25 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Main text: 9 pages, 2 tables, 6 figures. Supplemental information: 31 pages, 1 table, 24 figures
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Nature Communications 14, 7283 (2023)
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.13032">
         arXiv:2304.13032
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.13032">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.13032">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">
         cs.SE
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A Unified
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Framework for Annotating Graph Data with Application to Software Source Code Performance Prediction
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Samoaa%2C+P">
        Peter Samoaa
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Aronsson%2C+L">
        Linus Aronsson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Longa%2C+A">
        Antonio Longa
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Leitner%2C+P">
        Philipp Leitner
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chehreghani%2C+M+H">
        Morteza Haghir Chehreghani
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.13032v2-abstract-short" style="display: inline;">
        …which might not be available in advance. Acquiring annotations often requires significant time, effort, and computational resources, making it challenging. We develop a unified
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.13032v2-abstract-full').style.display = 'inline'; document.getElementById('2304.13032v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.13032v2-abstract-full" style="display: none;">
        Most machine learning and data analytics applications, including performance engineering in software systems, require a large number of annotations and labelled data, which might not be available in advance. Acquiring annotations often requires significant time, effort, and computational resources, making it challenging. We develop a unified
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework specializing in software performance prediction to address this task. We begin by parsing the source code to an Abstract Syntax Tree (AST) and augmenting it with data and control flow edges. Then, we convert the tree representation of the source code to a Flow Augmented-AST graph (FA-AST) representation. Based on the graph representation, we construct various graph embeddings (unsupervised and supervised) into a latent space. Given such an embedding, the framework becomes task agnostic since
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can be performed using any regression method and query strategy suited for regression. Within this framework, we investigate the impact of using different levels of information for active and passive learning, e.g., partially available labels and unlabeled test data. Our approach aims to improve the investment in AI models for different software performance predictions (execution time) based on the structure of the source code. Our real-world experiments reveal that respectable performance can be achieved by querying labels for only a small subset of all the data.
        <a class="is-size-7" onclick="document.getElementById('2304.13032v2-abstract-full').style.display = 'none'; document.getElementById('2304.13032v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       20 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 6 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.12583">
         arXiv:2304.12583
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.12583">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.12583">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">
         eess.SY
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Real-time Safety Assessment of Dynamic Systems in Non-stationary Environments: A Review of Methods and Techniques
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">
        Zeyi Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hu%2C+S">
        Songqiao Hu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=He%2C+X">
        Xiao He
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.12583v2-abstract-short" style="display: inline;">
        …We then present a problem description that covers the definition, classification, and main challenges. We review recent developments in related technologies such as online
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , online semi-supervised learning, online transfer learning, and online anomaly detection. Finally, we discuss future outlooks and p…
        <a class="is-size-7" onclick="document.getElementById('2304.12583v2-abstract-full').style.display = 'inline'; document.getElementById('2304.12583v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.12583v2-abstract-full" style="display: none;">
        Real-time safety assessment (RTSA) of dynamic systems is a critical task that has significant implications for various fields such as industrial and transportation applications, especially in non-stationary environments. However, the absence of a comprehensive review of real-time safety assessment methods in non-stationary environments impedes the progress and refinement of related methods. In this paper, a review of methods and techniques for RTSA tasks in non-stationary environments is provided. Specifically, the background and significance of RTSA approaches in non-stationary environments are firstly highlighted. We then present a problem description that covers the definition, classification, and main challenges. We review recent developments in related technologies such as online
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , online semi-supervised learning, online transfer learning, and online anomaly detection. Finally, we discuss future outlooks and potential directions for further research. Our review aims to provide a comprehensive and up-to-date overview of real-time safety assessment methods in non-stationary environments, which can serve as a valuable resource for researchers and practitioners in this field.
        <a class="is-size-7" onclick="document.getElementById('2304.12583v2-abstract-full').style.display = 'none'; document.getElementById('2304.12583v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 25 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted by the 2023 CAA Symposium on Fault Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2023)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.11989">
         arXiv:2304.11989
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.11989">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.11989">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Generative Flow Networks for Precise Reward-Oriented
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       on Graphs
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+Y">
        Yinchuan Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Z">
        Zhigang Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+W">
        Wenqian Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shao%2C+Y">
        Yunfeng Shao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zheng%2C+Y">
        Yan Zheng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hao%2C+J">
        Jianye Hao
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.11989v1-abstract-short" style="display: inline;">
        Many score-based
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.11989v1-abstract-full').style.display = 'inline'; document.getElementById('2304.11989v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.11989v1-abstract-full" style="display: none;">
        Many score-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods have been successfully applied to graph-structured data, aiming to reduce the number of labels and achieve better performance of graph neural networks based on predefined score functions. However, these algorithms struggle to learn policy distributions that are proportional to rewards and have limited exploration capabilities. In this paper, we innovatively formulate the graph
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        problem as a generative process, named GFlowGNN, which generates various samples through sequential actions with probabilities precisely proportional to a predefined reward function. Furthermore, we propose the concept of flow nodes and flow features to efficiently model graphs as flows based on generative flow networks, where the policy network is trained with specially designed rewards. Extensive experiments on real datasets show that the proposed approach has good exploration capability and transferability, outperforming various state-of-the-art methods.
        <a class="is-size-7" onclick="document.getElementById('2304.11989v1-abstract-full').style.display = 'none'; document.getElementById('2304.11989v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       24 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.11762">
         arXiv:2304.11762
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.11762">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.11762">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       You Never Get a Second Chance To Make a Good First Impression: Seeding
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for 3D Semantic Segmentation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Samet%2C+N">
        Nermin Samet
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sim%C3%A9oni%2C+O">
        Oriane Siméoni
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Puy%2C+G">
        Gilles Puy
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ponimatkin%2C+G">
        Georgy Ponimatkin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Marlet%2C+R">
        Renaud Marlet
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lepetit%2C+V">
        Vincent Lepetit
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.11762v2-abstract-short" style="display: inline;">
        We propose SeedAL, a method to seed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for efficient annotation of 3D point clouds for semantic segmentation.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) iteratively selects relevant data fractions to annotate within a given budget, but requires a fi…
        <a class="is-size-7" onclick="document.getElementById('2304.11762v2-abstract-full').style.display = 'inline'; document.getElementById('2304.11762v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.11762v2-abstract-full" style="display: none;">
        We propose SeedAL, a method to seed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for efficient annotation of 3D point clouds for semantic segmentation.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) iteratively selects relevant data fractions to annotate within a given budget, but requires a first fraction of the dataset (a 'seed') to be already annotated to estimate the benefit of annotating other data fractions. We first show that the choice of the seed can significantly affect the performance of many AL methods. We then propose a method for automatically constructing a seed that will ensure good performance for AL. Assuming that images of the point clouds are available, which is common, our method relies on powerful unsupervised image features to measure the diversity of the point clouds. It selects the point clouds for the seed by optimizing the diversity under an annotation budget, which can be done by solving a linear optimization problem. Our experiments demonstrate the effectiveness of our approach compared to random seeding and existing methods on both the S3DIS and SemanticKitti datasets. Code is available at https://github.com/nerminsamet/seedal.
        <a class="is-size-7" onclick="document.getElementById('2304.11762v2-abstract-full').style.display = 'none'; document.getElementById('2304.11762v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 23 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        ICCV 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.11058">
         arXiv:2304.11058
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.11058">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/ps/2304.11058">
          ps
         </a>
         ,
         <a href="https://arxiv.org/format/2304.11058">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">
         cs.IR
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Novel Intent Detection and
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Based Classification (Student Abstract)
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Mullick%2C+A">
        Ankan Mullick
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.11058v1-abstract-short" style="display: inline;">
        …across various different languages with less human annotation effort for mis-classified and system rejected samples. This paper proposes NIDAL (Novel Intent Detection and
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        based classification), a semi-supervised framework to detect novel intents while reducing human annotation cost. Empirical results on…
        <a class="is-size-7" onclick="document.getElementById('2304.11058v1-abstract-full').style.display = 'inline'; document.getElementById('2304.11058v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.11058v1-abstract-full" style="display: none;">
        Novel intent class detection is an important problem in real world scenario for conversational agents for continuous interaction. Several research works have been done to detect novel intents in a mono-lingual (primarily English) texts and images. But, current systems lack an end-to-end universal framework to detect novel intents across various different languages with less human annotation effort for mis-classified and system rejected samples. This paper proposes NIDAL (Novel Intent Detection and
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        based classification), a semi-supervised framework to detect novel intents while reducing human annotation cost. Empirical results on various benchmark datasets demonstrate that this system outperforms the baseline methods by more than 10% margin for accuracy and macro-F1. The system achieves this while maintaining overall annotation cost to be just ~6-10% of the unlabeled data available to the system.
        <a class="is-size-7" onclick="document.getElementById('2304.11058v1-abstract-full').style.display = 'none'; document.getElementById('2304.11058v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       22 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        AAAI 2023 Student Abstract
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.11005">
         arXiv:2304.11005
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.11005">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.11005">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Self-Correcting Bayesian Optimization through Bayesian
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hvarfner%2C+C">
        Carl Hvarfner
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hellsten%2C+E">
        Erik Hellsten
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hutter%2C+F">
        Frank Hutter
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nardi%2C+L">
        Luigi Nardi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.11005v3-abstract-short" style="display: inline;">
        Gaussian processes are the model of choice in Bayesian optimization and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.11005v3-abstract-full').style.display = 'inline'; document.getElementById('2304.11005v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.11005v3-abstract-full" style="display: none;">
        Gaussian processes are the model of choice in Bayesian optimization and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Yet, they are highly dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding good hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize hyperparameter learning. Statistical distance-based
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (SAL) considers the average disagreement between samples from the posterior, as measured by a statistical distance. SAL outperforms the state-of-the-art in Bayesian
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        on several test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization methods on traditional benchmarks. Moreover, we demonstrate the importance of self-correction on atypical Bayesian optimization tasks.
        <a class="is-size-7" onclick="document.getElementById('2304.11005v3-abstract-full').style.display = 'none'; document.getElementById('2304.11005v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 February, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 21 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       37th International Conference on Neural Information Processing Systems (NeurIPS 2023)
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.09606">
         arXiv:2304.09606
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.09606">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.09606">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep Learning Illuminates Spin and Lattice Interaction in Magnetic Materials
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yang%2C+T">
        Teng Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cai%2C+Z">
        Zefeng Cai
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Huang%2C+Z">
        Zhengtao Huang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tang%2C+W">
        Wenlong Tang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shi%2C+R">
        Ruosong Shi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Godfrey%2C+A">
        Andy Godfrey
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+H">
        Hanxing Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lin%2C+Y">
        Yuanhua Lin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nan%2C+C">
        Ce-Wen Nan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ye%2C+M">
        Meng Ye
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">
        LinFeng Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+H">
        Han Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+B">
        Ben Xu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.09606v3-abstract-short" style="display: inline;">
        …forces, and magnetic torque in magnetic systems. This is achieved by integrating first-principles calculations of magnetic excited states with deep learning techniques via
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . We thoroughly explore the methodology, accuracy, and scalability of our proposed model in this paper. Our technique adeptly connect…
        <a class="is-size-7" onclick="document.getElementById('2304.09606v3-abstract-full').style.display = 'inline'; document.getElementById('2304.09606v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.09606v3-abstract-full" style="display: none;">
        Atomistic simulations hold significant value in clarifying crucial phenomena such as phase transitions and energy transport in materials science. Their success stems from the presence of potential energy functions capable of accurately depicting the relationship between system energy and lattice changes. In magnetic materials, two atomic scale degrees of freedom come into play: the lattice and the spin. However, accurately tracing the simultaneous evolution of both lattice and spin in magnetic materials at an atomic scale is a substantial challenge. This is largely due to the complexity involved in depicting the interaction energy precisely, and its influence on lattice and spin-driving forces, such as atomic force and magnetic torque, which continues to be a daunting task in computational science. Addressing this deficit, we present DeepSPIN, a versatile approach that generates high-precision predictive models of energy, atomic forces, and magnetic torque in magnetic systems. This is achieved by integrating first-principles calculations of magnetic excited states with deep learning techniques via
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . We thoroughly explore the methodology, accuracy, and scalability of our proposed model in this paper. Our technique adeptly connects first-principles computations and atomic-scale simulations of magnetic materials. This synergy presents opportunities to utilize these calculations in devising and tackling theoretical and practical obstacles concerning magnetic materials.
        <a class="is-size-7" onclick="document.getElementById('2304.09606v3-abstract-full').style.display = 'none'; document.getElementById('2304.09606v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       18 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 19 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.09530">
         arXiv:2304.09530
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.09530">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.09530">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">
         eess.SP
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       SelfAct: Personalized Activity Recognition based on Self-Supervised and
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Arrotta%2C+L">
        Luca Arrotta
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Civitarese%2C+G">
        Gabriele Civitarese
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Valente%2C+S">
        Samuele Valente
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bettini%2C+C">
        Claudio Bettini
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.09530v1-abstract-short" style="display: inline;">
        …of activity execution, activity models should be personalized for each user. In this work, we propose SelfAct: a novel framework for HAR combining self-supervised and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.09530v1-abstract-full').style.display = 'inline'; document.getElementById('2304.09530v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.09530v1-abstract-full" style="display: none;">
        Supervised Deep Learning (DL) models are currently the leading approach for sensor-based Human Activity Recognition (HAR) on wearable and mobile devices. However, training them requires large amounts of labeled data whose collection is often time-consuming, expensive, and error-prone. At the same time, due to the intra- and inter-variability of activity execution, activity models should be personalized for each user. In this work, we propose SelfAct: a novel framework for HAR combining self-supervised and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to mitigate these problems. SelfAct leverages a large pool of unlabeled data collected from many users to pre-train through self-supervision a DL model, with the goal of learning a meaningful and efficient latent representation of sensor data. The resulting pre-trained model can be locally used by new users, which will fine-tune it thanks to a novel unsupervised
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy. Our experiments on two publicly available HAR datasets demonstrate that SelfAct achieves results that are close to or even better than the ones of fully supervised approaches with a small number of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        queries.
        <a class="is-size-7" onclick="document.getElementById('2304.09530v1-abstract-full').style.display = 'none'; document.getElementById('2304.09530v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.09278">
         arXiv:2304.09278
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.09278">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">
         math.OC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A Data Driven Sequential Learning Framework to Accelerate and Optimize Multi-Objective Manufacturing Decisions
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Khosravi%2C+H">
        Hamed Khosravi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Olajire%2C+T">
        Taofeeq Olajire
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Raihan%2C+A+S">
        Ahmed Shoyeb Raihan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ahmed%2C+I">
        Imtiaz Ahmed
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="search-hit">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.09278v1-abstract-short" style="display: inline;">
        …critical to determine the optimal location for data collection to gain the most comprehensive understanding of the process. Sequential learning is a promising approach to
        <span class="search-hit mathjax">
         actively
        </span>
        <span class="search-hit mathjax">
         learn
        </span>
        from the ongoing experiments, iteratively update the underlying optimization routine, and adapt the data collection process on the go.…
        <a class="is-size-7" onclick="document.getElementById('2304.09278v1-abstract-full').style.display = 'inline'; document.getElementById('2304.09278v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.09278v1-abstract-full" style="display: none;">
        Manufacturing advanced materials and products with a specific property or combination of properties is often warranted. To achieve that it is crucial to find out the optimum recipe or processing conditions that can generate the ideal combination of these properties. Most of the time, a sufficient number of experiments are needed to generate a Pareto front. However, manufacturing experiments are usually costly and even conducting a single experiment can be a time-consuming process. So, it's critical to determine the optimal location for data collection to gain the most comprehensive understanding of the process. Sequential learning is a promising approach to
        <span class="search-hit mathjax">
         actively
        </span>
        <span class="search-hit mathjax">
         learn
        </span>
        from the ongoing experiments, iteratively update the underlying optimization routine, and adapt the data collection process on the go. This paper presents a novel data-driven Bayesian optimization framework that utilizes sequential learning to efficiently optimize complex systems with multiple conflicting objectives. Additionally, this paper proposes a novel metric for evaluating multi-objective data-driven optimization approaches. This metric considers both the quality of the Pareto front and the amount of data used to generate it. The proposed framework is particularly beneficial in practical applications where acquiring data can be expensive and resource intensive. To demonstrate the effectiveness of the proposed algorithm and metric, the algorithm is evaluated on a manufacturing dataset. The results indicate that the proposed algorithm can achieve the actual Pareto front while processing significantly less data. It implies that the proposed data-driven framework can lead to similar manufacturing decisions with reduced costs and time.
        <a class="is-size-7" onclick="document.getElementById('2304.09278v1-abstract-full').style.display = 'none'; document.getElementById('2304.09278v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       18 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.08958">
         arXiv:2304.08958
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.08958">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.08958">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Fluid Dynamics">
         physics.flu-dyn
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Prediction of equivalent sand-grain size and identification of drag-relevant scales of roughness -- a data driven approach
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yang%2C+J">
        Jiasheng Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Stroh%2C+A">
        Alexander Stroh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lee%2C+S">
        Sangseung Lee
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bagheri%2C+S">
        Shervin Bagheri
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Frohnapfel%2C+B">
        Bettina Frohnapfel
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Forooghi%2C+P">
        Pourya Forooghi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.08958v3-abstract-short" style="display: inline;">
        …. The 85 roughness samples are selected from a repository of 4200 samples, covering a wide parameter space, through an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) framework. The selection is made in several iterations, based on the informativeness of samples in the repository, quantified by the variance of ENN predictions. This AL framework…
        <a class="is-size-7" onclick="document.getElementById('2304.08958v3-abstract-full').style.display = 'inline'; document.getElementById('2304.08958v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.08958v3-abstract-full" style="display: none;">
        The purpose of the present work is to examine two possibilities; firstly, predicting equivalent sand-grain roughness size $k_s$ based on the roughness height probability density function and power spectrum leveraging machine learning as a regression tool, and secondly, extracting information about relevance of different roughness scales to skin-friction drag by interpreting the output of the trained data-driven model. The model is an ensemble neural network consisting of 50 deep neural networks. The data for the training of the model is obtained from direct numerical simulations (DNSs) of turbulent flow in plane channels over 85 irregular multi-scale roughness samples at friction Reynolds number Re$_τ=800$. The 85 roughness samples are selected from a repository of 4200 samples, covering a wide parameter space, through an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) framework. The selection is made in several iterations, based on the informativeness of samples in the repository, quantified by the variance of ENN predictions. This AL framework aims to maximize the generalizability of the predictions with a certain amount of data. This is examined using three different testing data sets with different types of roughness, including 21 surfaces from the literature. The model yields an overall mean error of 5\% to 10\% on different testing data sets. Subsequently, a data interpretation technique, known as layer-wise relevance propagation, is applied to measure the contributions of different roughness wave-lengths to the predicted $k_s$. High-pass filtering is then applied to the roughness PS to exclude the wave-numbers identified as drag-irrelevant. The filtered rough surfaces are investigated using DNS, and it is demonstrated that, despite significant impact of filtering on the roughness topographical appearance and statistics, the skin-friction coefficient of the original roughness is successfully preserved.
        <a class="is-size-7" onclick="document.getElementById('2304.08958v3-abstract-full').style.display = 'none'; document.getElementById('2304.08958v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 18 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        24 pages, 11 figures, submitted to JFM
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.08944">
         arXiv:2304.08944
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.08944">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/ps/2304.08944">
          ps
         </a>
         ,
         <a href="https://arxiv.org/format/2304.08944">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">
         math.OC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Provably Feedback-Efficient Reinforcement Learning via Active Reward Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kong%2C+D">
        Dingwen Kong
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+L+F">
        Lin F. Yang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.08944v1-abstract-short" style="display: inline;">
        …a theoretical perspective, aiming to provide provably feedback-efficient algorithmic frameworks that take human-in-the-loop to specify rewards of given tasks. We provide an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -based RL algorithm that first explores the environment without specifying a reward function and then asks a human teacher for only…
        <a class="is-size-7" onclick="document.getElementById('2304.08944v1-abstract-full').style.display = 'inline'; document.getElementById('2304.08944v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.08944v1-abstract-full" style="display: none;">
        An appropriate reward function is of paramount importance in specifying a task in reinforcement learning (RL). Yet, it is known to be extremely challenging in practice to design a correct reward function for even simple tasks. Human-in-the-loop (HiL) RL allows humans to communicate complex goals to the RL agent by providing various types of feedback. However, despite achieving great empirical successes, HiL RL usually requires too much feedback from a human teacher and also suffers from insufficient theoretical understanding. In this paper, we focus on addressing this issue from a theoretical perspective, aiming to provide provably feedback-efficient algorithmic frameworks that take human-in-the-loop to specify rewards of given tasks. We provide an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        -based RL algorithm that first explores the environment without specifying a reward function and then asks a human teacher for only a few queries about the rewards of a task at some state-action pairs. After that, the algorithm guarantees to provide a nearly optimal policy for the task with high probability. We show that, even with the presence of random noise in the feedback, the algorithm only takes $\widetilde{O}(H{{\dim_{R}^2}})$ queries on the reward function to provide an $ε$-optimal policy for any $ε&gt; 0$. Here $H$ is the horizon of the RL environment, and $\dim_{R}$ specifies the complexity of the function class representing the reward function. In contrast, standard RL algorithms require to query the reward function for at least $Ω(\operatorname{poly}(d, 1/ε))$ state-action pairs where $d$ depends on the complexity of the environmental transition.
        <a class="is-size-7" onclick="document.getElementById('2304.08944v1-abstract-full').style.display = 'none'; document.getElementById('2304.08944v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       18 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        36th Conference on Neural Information Processing Systems (NeurIPS 2022)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.08151">
         arXiv:2304.08151
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.08151">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.08151">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Prediction-Oriented Bayesian
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Smith%2C+F+B">
        Freddie Bickford Smith
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kirsch%2C+A">
        Andreas Kirsch
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Farquhar%2C+S">
        Sebastian Farquhar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gal%2C+Y">
        Yarin Gal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Foster%2C+A">
        Adam Foster
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rainforth%2C+T">
        Tom Rainforth
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.08151v1-abstract-short" style="display: inline;">
        Information-theoretic approaches to
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an in…
        <a class="is-size-7" onclick="document.getElementById('2304.08151v1-abstract-full').style.display = 'inline'; document.getElementById('2304.08151v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.08151v1-abstract-full" style="display: none;">
        Information-theoretic approaches to
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an input distribution and so is prone to prioritise data of limited relevance. To address this we propose the expected predictive information gain (EPIG), an acquisition function that measures information gain in the space of predictions rather than parameters. We find that using EPIG leads to stronger predictive performance compared with BALD across a range of datasets and models, and thus provides an appealing drop-in replacement.
        <a class="is-size-7" onclick="document.getElementById('2304.08151v1-abstract-full').style.display = 'none'; document.getElementById('2304.08151v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Published at AISTATS 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.07665">
         arXiv:2304.07665
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.07665">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.07665">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Dynamic Exploration-Exploitation Trade-Off in
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Regression with Bayesian Hierarchical Modeling
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Islam%2C+U+J">
        Upala Junaida Islam
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Paynabar%2C+K">
        Kamran Paynabar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Runger%2C+G">
        George Runger
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Iquebal%2C+A+S">
        Ashif Sikandar Iquebal
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.07665v2-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        provides a framework to adaptively query the most informative experiments towards learning an unknown black-box function. Various approaches of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        have been proposed in the literature, however, they either focus…
        <a class="is-size-7" onclick="document.getElementById('2304.07665v2-abstract-full').style.display = 'inline'; document.getElementById('2304.07665v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.07665v2-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        provides a framework to adaptively query the most informative experiments towards learning an unknown black-box function. Various approaches of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        have been proposed in the literature, however, they either focus on exploration or exploitation in the design space. Methods that do consider exploration-exploitation simultaneously employ fixed or ad-hoc measures to control the trade-off that may not be optimal. In this paper, we develop a Bayesian hierarchical approach, referred as BHEEM, to dynamically balance the exploration-exploitation trade-off as more data points are queried. To sample from the posterior distribution of the trade-off parameter, We subsequently formulate an approximate Bayesian computation approach based on the linear dependence of queried data in the feature space. Simulated and real-world examples show the proposed approach achieves at least 21% and 11% average improvement when compared to pure exploration and exploitation strategies respectively. More importantly, we note that by optimally balancing the trade-off between exploration and exploitation, BHEEM performs better or at least as well as either pure exploration or pure exploitation.
        <a class="is-size-7" onclick="document.getElementById('2304.07665v2-abstract-full').style.display = 'none'; document.getElementById('2304.07665v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 15 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        30 pages, 10 figures, 0 table, submitted to IISE Transaction
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.07445">
         arXiv:2304.07445
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.07445">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.07445">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A framework for fully autonomous design of materials via multiobjective optimization and
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       : challenges and next steps
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chang%2C+T+H">
        Tyler H. Chang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Elias%2C+J+R">
        Jakob R. Elias
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wild%2C+S+M">
        Stefan M. Wild
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chaudhuri%2C+S">
        Santanu Chaudhuri
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Libera%2C+J+A">
        Joseph A. Libera
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.07445v1-abstract-short" style="display: inline;">
        …are multiple competing design criteria, systems need to be able to intelligently sample while balancing performance trade-offs and constraints. For these reasons, we present an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        process based on multiobjective black-box optimization with continuously updated machine learning models. This workflow is buil…
        <a class="is-size-7" onclick="document.getElementById('2304.07445v1-abstract-full').style.display = 'inline'; document.getElementById('2304.07445v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.07445v1-abstract-full" style="display: none;">
        In order to deploy machine learning in a real-world self-driving laboratory where data acquisition is costly and there are multiple competing design criteria, systems need to be able to intelligently sample while balancing performance trade-offs and constraints. For these reasons, we present an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        process based on multiobjective black-box optimization with continuously updated machine learning models. This workflow is built on open-source technologies for real-time data streaming and modular multiobjective optimization software development. We demonstrate a proof of concept for this workflow through the autonomous operation of a continuous-flow chemistry laboratory, which identifies ideal manufacturing conditions for the electrolyte 2,2,2-trifluoroethyl methyl carbonate.
        <a class="is-size-7" onclick="document.getElementById('2304.07445v1-abstract-full').style.display = 'none'; document.getElementById('2304.07445v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       14 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.07010">
         arXiv:2304.07010
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.07010">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">
         cs.CE
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       CSP-free adaptive Kriging surrogate model method for reliability analysis with small failure probability
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+W">
        Wenxiong Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Geng%2C+R">
        Rong Geng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+S">
        Suiyin Chen
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.07010v3-abstract-short" style="display: inline;">
        In the field of reliability engineering, the
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        reliability method combining Kriging and Monte Carlo Simulation (AK-MCS) has been developed and demonstrated to be effective in reliability analysis. However, the performance of AK-MCS is sensitive to the size of Candidate Sample Pool (CSP), particularly for…
        <a class="is-size-7" onclick="document.getElementById('2304.07010v3-abstract-full').style.display = 'inline'; document.getElementById('2304.07010v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.07010v3-abstract-full" style="display: none;">
        In the field of reliability engineering, the
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        reliability method combining Kriging and Monte Carlo Simulation (AK-MCS) has been developed and demonstrated to be effective in reliability analysis. However, the performance of AK-MCS is sensitive to the size of Candidate Sample Pool (CSP), particularly for systems with small failure probabilities. To address the limitations of conventional AK-MCS that relies on CSP, this paper proposes a CSP-free AK-MCS. The proposed methodology consists of two stages: surrogate model construction and Monte Carlo simulation for estimating the failure probability. In the stage of surrogate model construction, the surrogate model is iteratively refined based on the representative samples selected by solving the optimization problem facilitated by Particle Swarm Optimization (PSO) algorithm. To achieve an optimal balance between solution accuracy and efficiency, the penalty intensity control and the density control for the experimental design points are introduced to modify the objective function in optimization. The performance of the proposed methodology is evaluated using numerical examples, and results indicate that by leveraging an optimization algorithm to select representative samples, the proposed CSP-free AK-MCS overcomes the limitations of conventional CSP-based AK-MCS and exhibits exceptional performance in addressing small failure probabilities.
        <a class="is-size-7" onclick="document.getElementById('2304.07010v3-abstract-full').style.display = 'none'; document.getElementById('2304.07010v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       1 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 14 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.06277">
         arXiv:2304.06277
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.06277">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Optimizing Multi-Domain Performance with
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       -based Improvement Strategies
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Mahalingam%2C+A+G">
        Anand Gokul Mahalingam
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shah%2C+A">
        Aayush Shah
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gulati%2C+A">
        Akshay Gulati
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mascarenhas%2C+R">
        Royston Mascarenhas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Panduranga%2C+R">
        Rakshitha Panduranga
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.06277v1-abstract-short" style="display: inline;">
        Improving performance in multiple domains is a challenging task, and often requires significant amounts of data to train and test models.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.06277v1-abstract-full').style.display = 'inline'; document.getElementById('2304.06277v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.06277v1-abstract-full" style="display: none;">
        Improving performance in multiple domains is a challenging task, and often requires significant amounts of data to train and test models.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        techniques provide a promising solution by enabling models to select the most informative samples for labeling, thus reducing the amount of labeled data required to achieve high performance. In this paper, we present an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        -based framework for improving performance across multiple domains. Our approach consists of two stages: first, we use an initial set of labeled data to train a base model, and then we iteratively select the most informative samples for labeling to refine the model. We evaluate our approach on several multi-domain datasets, including image classification, sentiment analysis, and object recognition. Our experiments demonstrate that our approach consistently outperforms baseline methods and achieves state-of-the-art performance on several datasets. We also show that our method is highly efficient, requiring significantly fewer labeled samples than other
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        -based methods. Overall, our approach provides a practical and effective solution for improving performance across multiple domains using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        techniques.
        <a class="is-size-7" onclick="document.getElementById('2304.06277v1-abstract-full').style.display = 'none'; document.getElementById('2304.06277v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       13 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        13 pages, 20 figures, draft work previously published as a medium story
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.06252">
         arXiv:2304.06252
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.06252">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.06252">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Applications">
         stat.AP
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Adaptive active subspace-based metamodeling for high-dimensional reliability analysis
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+J">
        Jungho Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">
        Ziqi Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Song%2C+J">
        Junho Song
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.06252v1-abstract-short" style="display: inline;">
        …reliability analysis in high-dimensional probability spaces, this paper proposes a new metamodeling method that couples active subspace, heteroscedastic Gaussian process, and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.06252v1-abstract-full').style.display = 'inline'; document.getElementById('2304.06252v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.06252v1-abstract-full" style="display: none;">
        To address the challenges of reliability analysis in high-dimensional probability spaces, this paper proposes a new metamodeling method that couples active subspace, heteroscedastic Gaussian process, and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . The active subspace is leveraged to identify low-dimensional salient features of a high-dimensional computational model. A surrogate computational model is built in the low-dimensional feature space by a heteroscedastic Gaussian process.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        adaptively guides the surrogate model training toward the critical region that significantly contributes to the failure probability. A critical trait of the proposed method is that the three main ingredients-active subspace, heteroscedastic Gaussian process, and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        -are coupled to adaptively optimize the feature space mapping in conjunction with the surrogate modeling. This coupling empowers the proposed method to accurately solve nontrivial high-dimensional reliability problems via low-dimensional surrogate modeling. Finally, numerical examples of a high-dimensional nonlinear function and structural engineering applications are investigated to verify the performance of the proposed method.
        <a class="is-size-7" onclick="document.getElementById('2304.06252v1-abstract-full').style.display = 'none'; document.getElementById('2304.06252v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       13 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.05578">
         arXiv:2304.05578
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.05578">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.05578">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Does Informativeness Matter?
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Educational Dialogue Act Classification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tan%2C+W">
        Wei Tan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lin%2C+J">
        Jionghao Lin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lang%2C+D">
        David Lang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+G">
        Guanliang Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gasevic%2C+D">
        Dragan Gasevic
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Du%2C+L">
        Lan Du
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Buntine%2C+W">
        Wray Buntine
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.05578v1-abstract-short" style="display: inline;">
        …which consumes human labelling costs and contributes less to training the classifiers. As an alternative, researchers suggest employing statistical sampling methods of
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) to identify the informative samples for training the classifiers. However, the use of AL methods in educational DA classification…
        <a class="is-size-7" onclick="document.getElementById('2304.05578v1-abstract-full').style.display = 'inline'; document.getElementById('2304.05578v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.05578v1-abstract-full" style="display: none;">
        Dialogue Acts (DAs) can be used to explain what expert tutors do and what students know during the tutoring process. Most empirical studies adopt the random sampling method to obtain sentence samples for manual annotation of DAs, which are then used to train DA classifiers. However, these studies have paid little attention to sample informativeness, which can reflect the information quantity of the selected samples and inform the extent to which a classifier can learn patterns. Notably, the informativeness level may vary among the samples and the classifier might only need a small amount of low informative samples to learn the patterns. Random sampling may overlook sample informativeness, which consumes human labelling costs and contributes less to training the classifiers. As an alternative, researchers suggest employing statistical sampling methods of
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) to identify the informative samples for training the classifiers. However, the use of AL methods in educational DA classification tasks is under-explored. In this paper, we examine the informativeness of annotated sentence samples. Then, the study investigates how the AL methods can select informative samples to support DA classifiers in the AL sampling process. The results reveal that most annotated sentences present low informativeness in the training dataset and the patterns of these sentences can be easily captured by the DA classifier. We also demonstrate how AL methods can reduce the cost of manual annotation in the AL sampling process.
        <a class="is-size-7" onclick="document.getElementById('2304.05578v1-abstract-full').style.display = 'none'; document.getElementById('2304.05578v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       11 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 pages full paper, The 24th International Conference on Artificial Intelligence in Education, AIED 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.05265">
         arXiv:2304.05265
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.05265">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.05265">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Controllable Textual Inversion for Personalized Text-to-Image Generation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yang%2C+J">
        Jianan Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+H">
        Haobo Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">
        Yanming Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xiao%2C+R">
        Ruixuan Xiao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+S">
        Sai Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+G">
        Gang Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhao%2C+J">
        Junbo Zhao
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.05265v3-abstract-short" style="display: inline;">
        …and easy-to-use framework. The core to COTI is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        paradigm. The extensive results show that COTI significantly outperforms the prior TI-related approaches with a 26.05 decrease i…
        <a class="is-size-7" onclick="document.getElementById('2304.05265v3-abstract-full').style.display = 'inline'; document.getElementById('2304.05265v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.05265v3-abstract-full" style="display: none;">
        The recent large-scale generative modeling has attained unprecedented performance especially in producing high-fidelity images driven by text prompts. Text inversion (TI), alongside the text-to-image model backbones, is proposed as an effective technique in personalizing the generation when the prompts contain user-defined, unseen or long-tail concept tokens. Despite that, we find and show that the deployment of TI remains full of "dark-magics" -- to name a few, the harsh requirement of additional datasets, arduous human efforts in the loop and lack of robustness. In this work, we propose a much-enhanced version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all the aforementioned problems and in turn delivering a robust, data-efficient and easy-to-use framework. The core to COTI is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        paradigm. The extensive results show that COTI significantly outperforms the prior TI-related approaches with a 26.05 decrease in the FID score and a 23.00% boost in the R-precision.
        <a class="is-size-7" onclick="document.getElementById('2304.05265v3-abstract-full').style.display = 'none'; document.getElementById('2304.05265v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       24 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 11 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        10 pages, 6 figures, 2 tables. Project Page: https://github.com/jnzju/COTI
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.05246">
         arXiv:2304.05246
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.05246">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.05246">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       OpenAL: Evaluation and Interpretation of
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Strategies
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Jonas%2C+W">
        W. Jonas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Abraham%2C+A">
        A. Abraham
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dreyfus-Schmidt%2C+L">
        L. Dreyfus-Schmidt
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.05246v1-abstract-short" style="display: inline;">
        Despite the vast body of literature on
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL), there is no comprehensive and open benchmark allowing for efficient and simple comparison of proposed samplers. Additionally, the variability in experimental settings across the literature makes it difficult to choose a sampling strategy, which is critical du…
        <a class="is-size-7" onclick="document.getElementById('2304.05246v1-abstract-full').style.display = 'inline'; document.getElementById('2304.05246v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.05246v1-abstract-full" style="display: none;">
        Despite the vast body of literature on
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL), there is no comprehensive and open benchmark allowing for efficient and simple comparison of proposed samplers. Additionally, the variability in experimental settings across the literature makes it difficult to choose a sampling strategy, which is critical due to the one-off nature of AL experiments. To address those limitations, we introduce OpenAL, a flexible and open-source framework to easily run and compare sampling AL strategies on a collection of realistic tasks. The proposed benchmark is augmented with interpretability metrics and statistical analysis methods to understand when and why some samplers outperform others. Last but not least, practitioners can easily extend the benchmark by submitting their own AL samplers.
        <a class="is-size-7" onclick="document.getElementById('2304.05246v1-abstract-full').style.display = 'none'; document.getElementById('2304.05246v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       11 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Published in NeurIPS 2022 Workshop on Human in the Loop Learning, 8 pages
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        ACM Class:
       </span>
       I.2.6
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.04389">
         arXiv:2304.04389
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.04389">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.04389">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Databases">
         cs.DB
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep Active Alignment of Knowledge Graph Entities and Schemata
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Huang%2C+J">
        Jiacheng Huang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sun%2C+Z">
        Zequn Sun
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+Q">
        Qijin Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+X">
        Xiaozhou Xu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ren%2C+W">
        Weijun Ren
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hu%2C+W">
        Wei Hu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.04389v3-abstract-short" style="display: inline;">
        …different KGs. Alignment at the entity level can cross-fertilize alignment at the schema level. We propose a new KG alignment approach, called DAAKG, based on deep learning and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.04389v3-abstract-full').style.display = 'inline'; document.getElementById('2304.04389v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.04389v3-abstract-full" style="display: none;">
        Knowledge graphs (KGs) store rich facts about the real world. In this paper, we study KG alignment, which aims to find alignment between not only entities but also relations and classes in different KGs. Alignment at the entity level can cross-fertilize alignment at the schema level. We propose a new KG alignment approach, called DAAKG, based on deep learning and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . With deep learning, it learns the embeddings of entities, relations and classes, and jointly aligns them in a semi-supervised manner. With
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , it estimates how likely an entity, relation or class pair can be inferred, and selects the best batch for human labeling. We design two approximation algorithms for efficient solution to batch selection. Our experiments on benchmark datasets show the superior accuracy and generalization of DAAKG and validate the effectiveness of all its modules.
        <a class="is-size-7" onclick="document.getElementById('2304.04389v3-abstract-full').style.display = 'none'; document.getElementById('2304.04389v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 10 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted in the ACM SIGMOD/PODS International Conference on Management of Data (SIGMOD 2023)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.04220">
         arXiv:2304.04220
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.04220">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.04220">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Towards
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Action Spotting in Association Football Videos
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Giancola%2C+S">
        Silvio Giancola
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cioppa%2C+A">
        Anthony Cioppa
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Georgieva%2C+J">
        Julia Georgieva
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Billingham%2C+J">
        Johsan Billingham
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Serner%2C+A">
        Andreas Serner
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Peek%2C+K">
        Kerry Peek
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ghanem%2C+B">
        Bernard Ghanem
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Van+Droogenbroeck%2C+M">
        Marc Van Droogenbroeck
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.04220v1-abstract-short" style="display: inline;">
        …algorithms still face significant challenges when learning from limited annotated data, lowering their performance in detecting these patterns. In this paper, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.04220v1-abstract-full').style.display = 'inline'; document.getElementById('2304.04220v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.04220v1-abstract-full" style="display: none;">
        Association football is a complex and dynamic sport, with numerous actions occurring simultaneously in each game. Analyzing football videos is challenging and requires identifying subtle and diverse spatio-temporal patterns. Despite recent advances in computer vision, current algorithms still face significant challenges when learning from limited annotated data, lowering their performance in detecting these patterns. In this paper, we propose an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework that selects the most informative video samples to be annotated next, thus drastically reducing the annotation effort and accelerating the training of action spotting models to reach the highest accuracy at a faster pace. Our approach leverages the notion of uncertainty sampling to select the most challenging video clips to train on next, hastening the learning process of the algorithm. We demonstrate that our proposed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework effectively reduces the required training data for accurate action spotting in football videos. We achieve similar performances for action spotting with NetVLAD++ on SoccerNet-v2, using only one-third of the dataset, indicating significant capabilities for reducing annotation time and improving data efficiency. We further validate our approach on two new datasets that focus on temporally localizing actions of headers and passes, proving its effectiveness across different action semantics in football. We believe our
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework for action spotting would support further applications of action spotting algorithms and accelerate annotation campaigns in the sports domain.
        <a class="is-size-7" onclick="document.getElementById('2304.04220v1-abstract-full').style.display = 'none'; document.getElementById('2304.04220v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       9 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at CVSports'23
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.04012">
         arXiv:2304.04012
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.04012">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.04012">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       PVD-AL: Progressive Volume Distillation with
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Efficient Conversion Between Different NeRF Architectures
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Fang%2C+S">
        Shuangkang Fang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">
        Yufeng Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+Y">
        Yi Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+W">
        Weixin Xu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+H">
        Heng Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ding%2C+W">
        Wenrui Ding
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhou%2C+S">
        Shuchang Zhou
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.04012v1-abstract-short" style="display: inline;">
        …making spatial-relation-aware editing challenging. To address this limitation and maximize the potential of each architecture, we propose Progressive Volume Distillation with
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.04012v1-abstract-full').style.display = 'inline'; document.getElementById('2304.04012v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.04012v1-abstract-full" style="display: none;">
        Neural Radiance Fields (NeRF) have been widely adopted as practical and versatile representations for 3D scenes, facilitating various downstream tasks. However, different architectures, including plain Multi-Layer Perceptron (MLP), Tensors, low-rank Tensors, Hashtables, and their compositions, have their trade-offs. For instance, Hashtables-based representations allow for faster rendering but lack clear geometric meaning, making spatial-relation-aware editing challenging. To address this limitation and maximize the potential of each architecture, we propose Progressive Volume Distillation with
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (PVD-AL), a systematic distillation method that enables any-to-any conversions between different architectures. PVD-AL decomposes each structure into two parts and progressively performs distillation from shallower to deeper volume representation, leveraging effective information retrieved from the rendering process. Additionally, a Three-Levels of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        technique provides continuous feedback during the distillation process, resulting in high-performance results. Empirical evidence is presented to validate our method on multiple benchmark datasets. For example, PVD-AL can distill an MLP-based model from a Hashtables-based model at a 10~20X faster speed and 0.8dB~2dB higher PSNR than training the NeRF model from scratch. Moreover, PVD-AL permits the fusion of diverse features among distinct structures, enabling models with multiple editing properties and providing a more efficient model to meet real-time requirements. Project website:http://sk-fun.fun/PVD-AL.
        <a class="is-size-7" onclick="document.getElementById('2304.04012v1-abstract-full').style.display = 'none'; document.getElementById('2304.04012v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       8 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Project website: http://sk-fun.fun/PVD-AL. arXiv admin note: substantial text overlap with arXiv:2211.15977
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.03870">
         arXiv:2304.03870
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.03870">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.03870">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ASPEST: Bridging the Gap Between
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       and Selective Prediction
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chen%2C+J">
        Jiefeng Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yoon%2C+J">
        Jinsung Yoon
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ebrahimi%2C+S">
        Sayna Ebrahimi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Arik%2C+S">
        Sercan Arik
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jha%2C+S">
        Somesh Jha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pfister%2C+T">
        Tomas Pfister
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.03870v3-abstract-short" style="display: inline;">
        …of test data is different from the training data. This results in more inaccurate predictions, and often increased dependence on humans, which can be difficult and expensive.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.03870v3-abstract-full').style.display = 'inline'; document.getElementById('2304.03870v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.03870v3-abstract-full" style="display: none;">
        Selective prediction aims to learn a reliable model that abstains from making predictions when uncertain. These predictions can then be deferred to humans for further evaluation. As an everlasting challenge for machine learning, in many real-world scenarios, the distribution of test data is different from the training data. This results in more inaccurate predictions, and often increased dependence on humans, which can be difficult and expensive.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        aims to lower the overall labeling effort, and hence human dependence, by querying the most informative examples. Selective prediction and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        have been approached from different angles, with the connection between them missing. In this work, we introduce a new learning paradigm, active selective prediction, which aims to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new paradigm, we propose a simple yet effective approach, ASPEST, that utilizes ensembles of model snapshots with self-training with their aggregated outputs as pseudo labels. Extensive experiments on numerous image, text and structured datasets, which suffer from domain shifts, demonstrate that ASPEST can significantly outperform prior work on selective prediction and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (e.g. on the MNIST$\to$SVHN benchmark with the labeling budget of 100, ASPEST improves the AUACC metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop.
        <a class="is-size-7" onclick="document.getElementById('2304.03870v3-abstract-full').style.display = 'none'; document.getElementById('2304.03870v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 February, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 7 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.03694">
         arXiv:2304.03694
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.03694">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.03694">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       High Accuracy Uncertainty-Aware Interatomic Force Modeling with Equivariant Bayesian Neural Networks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rensmeyer%2C+T">
        Tim Rensmeyer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Craig%2C+B">
        Benjamin Craig
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kramer%2C+D">
        Denis Kramer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Niggemann%2C+O">
        Oliver Niggemann
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.03694v1-abstract-short" style="display: inline;">
        Even though Bayesian neural networks offer a promising framework for modeling uncertainty,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and incorporating prior physical knowledge, few applications of them can be found in the context of interatomic force modeling. One of the main challenges in their application to learning interatomic forces is the…
        <a class="is-size-7" onclick="document.getElementById('2304.03694v1-abstract-full').style.display = 'inline'; document.getElementById('2304.03694v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.03694v1-abstract-full" style="display: none;">
        Even though Bayesian neural networks offer a promising framework for modeling uncertainty,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and incorporating prior physical knowledge, few applications of them can be found in the context of interatomic force modeling. One of the main challenges in their application to learning interatomic forces is the lack of suitable Monte Carlo Markov chain sampling algorithms for the posterior density, as the commonly used algorithms do not converge in a practical amount of time for many of the state-of-the-art architectures. As a response to this challenge, we introduce a new Monte Carlo Markov chain sampling algorithm in this paper which can circumvent the problems of the existing sampling methods. In addition, we introduce a new stochastic neural network model based on the NequIP architecture and demonstrate that, when combined with our novel sampling algorithm, we obtain predictions with state-of-the-art accuracy as well as a good measure of uncertainty.
        <a class="is-size-7" onclick="document.getElementById('2304.03694v1-abstract-full').style.display = 'none'; document.getElementById('2304.03694v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.02741">
         arXiv:2304.02741
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.02741">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.02741">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation">
         stat.CO
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Batch mode
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       for efficient parameter estimation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Zheng%2C+W">
        Wei Zheng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Tian%2C+T">
        Ting Tian
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+X">
        Xueqin Wang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.02741v1-abstract-short" style="display: inline;">
        For many tasks of data analysis, we may only have the information of the explanatory variable and the evaluation of the response values are quite expensive. While it is impractical or too costly to obtain the responses of all units, a natural remedy is to judiciously select a good sample of units, for which the responses are to be evaluated. In this paper, we adopt the classical criteria in design…
        <a class="is-size-7" onclick="document.getElementById('2304.02741v1-abstract-full').style.display = 'inline'; document.getElementById('2304.02741v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.02741v1-abstract-full" style="display: none;">
        For many tasks of data analysis, we may only have the information of the explanatory variable and the evaluation of the response values are quite expensive. While it is impractical or too costly to obtain the responses of all units, a natural remedy is to judiciously select a good sample of units, for which the responses are to be evaluated. In this paper, we adopt the classical criteria in design of experiments to quantify the information of a given sample regarding parameter estimation. Then, we provide a theoretical justification for approximating the optimal sample problem by a continuous problem, for which fast algorithms can be further developed with the guarantee of global convergence. Our results have the following novelties: (i) The statistical efficiency of any candidate sample can be evaluated without knowing the exact optimal sample; (ii) It can be applied to a very wide class of statistical models; (iii) It can be integrated with a broad class of information criteria; (iv) It is much faster than existing algorithms. $(v)$ A geometric interpretation is adopted to theoretically justify the relaxation of the original combinatorial problem to continuous optimization problem.
        <a class="is-size-7" onclick="document.getElementById('2304.02741v1-abstract-full').style.display = 'none'; document.getElementById('2304.02741v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.02484">
         arXiv:2304.02484
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.02484">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A dynamic Bayesian optimized active recommender system for curiosity-driven Human-in-the-loop automated experiments
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Biswas%2C+A">
        Arpan Biswas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">
        Yongtao Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Creange%2C+N">
        Nicole Creange
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">
        Yu-Chen Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jesse%2C+S">
        Stephen Jesse
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+J">
        Jan-Chi Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kalinin%2C+S+V">
        Sergei V. Kalinin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ziatdinov%2C+M+A">
        Maxim A. Ziatdinov
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Vasudevan%2C+R+K">
        Rama K. Vasudevan
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.02484v1-abstract-short" style="display: inline;">
        Optimization of experimental materials synthesis and characterization through
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites.…
        <a class="is-size-7" onclick="document.getElementById('2304.02484v1-abstract-full').style.display = 'inline'; document.getElementById('2304.02484v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.02484v1-abstract-full" style="display: none;">
        Optimization of experimental materials synthesis and characterization through
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods has been growing over the last decade, with examples ranging from measurements of diffraction on combinatorial alloys at synchrotrons, to searches through chemical space with automated synthesis robots for perovskites. In virtually all cases, the target property of interest for optimization is defined apriori with limited human feedback during operation. In contrast, here we present the development of a new type of human in the loop experimental workflow, via a Bayesian optimized active recommender system (BOARS), to shape targets on the fly, employing human feedback. We showcase examples of this framework applied to pre-acquired piezoresponse force spectroscopy of a ferroelectric thin film, and then implement this in real time on an atomic force microscope, where the optimization proceeds to find symmetric piezoresponse amplitude hysteresis loops. It is found that such features appear more affected by subsurface defects than the local domain structure. This work shows the utility of human-augmented machine learning approaches for curiosity-driven exploration of systems across experimental domains. The analysis reported here is summarized in Colab Notebook for the purpose of tutorial and application to other data: https://github.com/arpanbiswas52/varTBO
        <a class="is-size-7" onclick="document.getElementById('2304.02484v1-abstract-full').style.display = 'none'; document.getElementById('2304.02484v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        7 figures in main text, 3 figures in Supp Material
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.01404">
         arXiv:2304.01404
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.01404">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.01404">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">
         cs.CE
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Adaptive Defective Area Identification in Material Surface Using Active Transfer Learning-based Level Set Estimation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Hozumi%2C+S">
        Shota Hozumi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kutsukake%2C+K">
        Kentaro Kutsukake
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Matsui%2C+K">
        Kota Matsui
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kusakawa%2C+S">
        Syunya Kusakawa
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ujihara%2C+T">
        Toru Ujihara
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Takeuchi%2C+I">
        Ichiro Takeuchi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.01404v1-abstract-short" style="display: inline;">
        …we propose adaptive mapping methods in which measurement resources are used preferentially to detect the boundaries of defective areas. We interpret this problem as an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) of the level set estimation (LSE) problem. The goal of AL-based LSE is to determine the level set of the physical property functio…
        <a class="is-size-7" onclick="document.getElementById('2304.01404v1-abstract-full').style.display = 'inline'; document.getElementById('2304.01404v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.01404v1-abstract-full" style="display: none;">
        In material characterization, identifying defective areas on a material surface is fundamental. The conventional approach involves measuring the relevant physical properties point-by-point at the predetermined mesh grid points on the surface and determining the area at which the property does not reach the desired level. To identify defective areas more efficiently, we propose adaptive mapping methods in which measurement resources are used preferentially to detect the boundaries of defective areas. We interpret this problem as an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) of the level set estimation (LSE) problem. The goal of AL-based LSE is to determine the level set of the physical property function defined on the surface with as small number of measurements as possible. Furthermore, to handle the situations in which materials with similar specifications are repeatedly produced, we introduce a transfer learning approach so that the information of previously produced materials can be effectively utilized. As a proof-of-concept, we applied the proposed methods to the red-zone estimation problem of silicon wafers and demonstrated that we could identify the defective areas with significantly lower measurement costs than those of conventional methods.
        <a class="is-size-7" onclick="document.getElementById('2304.01404v1-abstract-full').style.display = 'none'; document.getElementById('2304.01404v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       3 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.01331">
         arXiv:2304.01331
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.01331">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.01331">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Creating Custom Event Data Without Dictionaries: A Bag-of-Tricks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Halterman%2C+A">
        Andrew Halterman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schrodt%2C+P+A">
        Philip A. Schrodt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Beger%2C+A">
        Andreas Beger
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bagozzi%2C+B+E">
        Benjamin E. Bagozzi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Scarborough%2C+G+I">
        Grace I. Scarborough
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.01331v1-abstract-short" style="display: inline;">
        …language processing (NLP) that allow researchers to rapidly produce customized event datasets. The paper introduces techniques for training an event category classifier with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , identifying actors and the recipients of actions in text using large language models and standard machine learning classifiers an…
        <a class="is-size-7" onclick="document.getElementById('2304.01331v1-abstract-full').style.display = 'inline'; document.getElementById('2304.01331v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.01331v1-abstract-full" style="display: none;">
        Event data, or structured records of ``who did what to whom'' that are automatically extracted from text, is an important source of data for scholars of international politics. The high cost of developing new event datasets, especially using automated systems that rely on hand-built dictionaries, means that most researchers draw on large, pre-existing datasets such as ICEWS rather than developing tailor-made event datasets optimized for their specific research question. This paper describes a ``bag of tricks'' for efficient, custom event data production, drawing on recent advances in natural language processing (NLP) that allow researchers to rapidly produce customized event datasets. The paper introduces techniques for training an event category classifier with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , identifying actors and the recipients of actions in text using large language models and standard machine learning classifiers and pretrained ``question-answering'' models from NLP, and resolving mentions of actors to their Wikipedia article to categorize them. We describe how these techniques produced the new POLECAT global event dataset that is intended to replace ICEWS, along with examples of how scholars can quickly produce smaller, custom event datasets. We publish example code and models to implement our new techniques.
        <a class="is-size-7" onclick="document.getElementById('2304.01331v1-abstract-full').style.display = 'none'; document.getElementById('2304.01331v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       3 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.01314">
         arXiv:2304.01314
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.01314">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2304.01314">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Accelerating Training of MLIPs Through Small-Cell Training
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Meziere%2C+J+A">
        Jason A. Meziere
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Luo%2C+Y">
        Yu Luo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zia%2C+Y">
        Yi Zia
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Beland%2C+L">
        LK Beland
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Daymond%2C+M">
        MR Daymond
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hart%2C+G+L+W">
        Gus L. W. Hart
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.01314v2-abstract-short" style="display: inline;">
        …interatomic potentials have become a mainstay for modeling materials, designing training sets that lead to robust potentials is challenging. Automated methods, such as
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and on-the-fly learning, construct reliable training sets, but these processes can be resource-intensive. Current training approaches of…
        <a class="is-size-7" onclick="document.getElementById('2304.01314v2-abstract-full').style.display = 'inline'; document.getElementById('2304.01314v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.01314v2-abstract-full" style="display: none;">
        While machine-learned interatomic potentials have become a mainstay for modeling materials, designing training sets that lead to robust potentials is challenging. Automated methods, such as
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and on-the-fly learning, construct reliable training sets, but these processes can be resource-intensive. Current training approaches often use density functional theory (DFT) calculations that have the same cell size as the simulations that the potential is explicitly trained to model. Here, we demonstrate an easy-to-implement small-cell training protocol and use it to model the Zr-H system. This training leads to a potential that accurately predicts known stable Zr-H phases and reproduces the $α$-$β$ pure zirconium phase transition in molecular dynamics simulations. Compared to traditional
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , small-cell training decreased the training time of the $α$-$β$ zirconium phase transition by approximately 20 times. The potential describes the phase transition with a degree of accuracy similar to that of the large-cell training method.
        <a class="is-size-7" onclick="document.getElementById('2304.01314v2-abstract-full').style.display = 'none'; document.getElementById('2304.01314v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 3 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        10 pages
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.00149">
         arXiv:2304.00149
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.00149">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Other Statistics">
         stat.OT
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Using online student focus groups in the development of new educational resources
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Diluvi%2C+G+C">
        Gian Carlo Diluvi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Isberg%2C+S">
        Sonja Isberg
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dunham%2C+B">
        Bruce Dunham
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Heckman%2C+N">
        Nancy Heckman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lee%2C+M">
        Melissa Lee
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.00149v1-abstract-short" style="display: inline;">
        Educational resources, such as web apps and self-directed tutorials, have become popular tools for teaching and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Ideally, students - the intended users of these resources - should be involved in the resource development stage. However, in practice students often only interact with fully developed resour…
        <a class="is-size-7" onclick="document.getElementById('2304.00149v1-abstract-full').style.display = 'inline'; document.getElementById('2304.00149v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.00149v1-abstract-full" style="display: none;">
        Educational resources, such as web apps and self-directed tutorials, have become popular tools for teaching and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Ideally, students - the intended users of these resources - should be involved in the resource development stage. However, in practice students often only interact with fully developed resources, when it might be too late to incorporate changes. Previous work has addressed this by involving students in the development of new resources via in-person focus groups and interviews. In these, the resource developers observe students interacting with the resource. This allows developers to incorporate their observations and students' direct feedback into further development of the resource. However, as a result of the COVID-19 pandemic, carrying out in-person focus groups became infeasible due to social distancing restrictions. Instead, online meetings and classes became ubiquitous. In this work, we describe a fully-online methodology to evaluate new resources in development. Specifically, our methodology consists of carrying out student focus groups via online video conferencing software. We assessed two educational resources for introductory statistics using our methodology and found that the online setting allowed us to obtain rich, detailed information from the students. We also found online focus groups to be more efficient: students and researchers did not need to travel and scheduling was not restricted by the availability of physical space. Our findings suggest that online focus groups are an attractive alternative to in-person focus groups for student assessment of resources in development, even now that pandemic restrictions are being eased.
        <a class="is-size-7" onclick="document.getElementById('2304.00149v1-abstract-full').style.display = 'none'; document.getElementById('2304.00149v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       31 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2304.00006">
         arXiv:2304.00006
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2304.00006">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">
         cs.IR
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Bi-directional personalization reinforcement learning-based architecture with
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       using a multi-model data service for the travel nursing industry
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Beyenne%2C+E+N">
        Ezana N. Beyenne
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2304.00006v1-abstract-short" style="display: inline;">
        …recruitment systems can be addressed with machine learning and software engineering techniques. Bi-directional personalization reinforcement learning-based architecture with
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2304.00006v1-abstract-full').style.display = 'inline'; document.getElementById('2304.00006v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2304.00006v1-abstract-full" style="display: none;">
        The challenges of using inadequate online recruitment systems can be addressed with machine learning and software engineering techniques. Bi-directional personalization reinforcement learning-based architecture with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can get recruiters to recommend qualified applicants and also enable applicants to receive personalized job recommendations. This paper focuses on how machine learning techniques can enhance the recruitment process in the travel nursing industry by helping speed up data acquisition using a multi-model data service and then providing personalized recommendations using bi-directional reinforcement learning with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . This need was especially evident when trying to respond to the overwhelming needs of healthcare facilities during the COVID-19 pandemic. The need for traveling nurses and other healthcare professionals was more evident during the lockdown period. A data service was architected for job feed processing using an orchestration of natural language processing (NLP) models that synthesize job-related data into a database efficiently and accurately. The multi-model data service provided the data necessary to develop a bi-directional personalization system using reinforcement learning with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        that could recommend travel nurses and healthcare professionals to recruiters and provide job recommendations to applicants using an internally developed smart match score as a basis. The bi-directional personalization reinforcement learning-based architecture with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        combines two personalization systems - one that runs forward to recommend qualified candidates for jobs and another that runs backward and recommends jobs for applicants.
        <a class="is-size-7" onclick="document.getElementById('2304.00006v1-abstract-full').style.display = 'none'; document.getElementById('2304.00006v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       14 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       April 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Masters thesis
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        ACM Class:
       </span>
       I.2
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.16963">
         arXiv:2303.16963
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.16963">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.16963">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">
         cs.CY
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Fairness-Aware Data Valuation for Supervised Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Pombal%2C+J">
        José Pombal
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Saleiro%2C+P">
        Pedro Saleiro
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Figueiredo%2C+M+A+T">
        Mário A. T. Figueiredo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bizarro%2C+P">
        Pedro Bizarro
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.16963v1-abstract-short" style="display: inline;">
        …(FADO), a data valuation framework that can be used to incorporate fairness concerns into a series of ML-related tasks (e.g., data pre-processing, exploratory data analysis,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        ). We propose an entropy-based data valuation metric suited to address our two-pronged goal of maximizing both performance and fair…
        <a class="is-size-7" onclick="document.getElementById('2303.16963v1-abstract-full').style.display = 'inline'; document.getElementById('2303.16963v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.16963v1-abstract-full" style="display: none;">
        Data valuation is a ML field that studies the value of training instances towards a given predictive task. Although data bias is one of the main sources of downstream model unfairness, previous work in data valuation does not consider how training instances may influence both performance and fairness of ML models. Thus, we propose Fairness-Aware Data vauatiOn (FADO), a data valuation framework that can be used to incorporate fairness concerns into a series of ML-related tasks (e.g., data pre-processing, exploratory data analysis,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        ). We propose an entropy-based data valuation metric suited to address our two-pronged goal of maximizing both performance and fairness, which is more computationally efficient than existing metrics. We then show how FADO can be applied as the basis for unfairness mitigation pre-processing techniques. Our methods achieve promising results -- up to a 40 p.p. improvement in fairness at a less than 1 p.p. loss in performance compared to a baseline -- and promote fairness in a data-centric way, where a deeper understanding of data quality takes center stage.
        <a class="is-size-7" onclick="document.getElementById('2303.16963v1-abstract-full').style.display = 'none'; document.getElementById('2303.16963v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        ICLR 2023 Workshop Trustworthy ML
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.16817">
         arXiv:2303.16817
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.16817">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.16817">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Adaptive Superpixel for
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in Semantic Segmentation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+H">
        Hoyoung Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Oh%2C+M">
        Minhyeon Oh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hwang%2C+S">
        Sehyun Hwang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kwak%2C+S">
        Suha Kwak
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ok%2C+J">
        Jungseul Ok
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.16817v2-abstract-short" style="display: inline;">
        Learning semantic segmentation requires pixel-wise annotations, which can be time-consuming and expensive. To reduce the annotation cost, we propose a superpixel-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) framework, which collects a dominant label per superpixel instead. To be specific, it consists of adaptive superpixel and sieving m…
        <a class="is-size-7" onclick="document.getElementById('2303.16817v2-abstract-full').style.display = 'inline'; document.getElementById('2303.16817v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.16817v2-abstract-full" style="display: none;">
        Learning semantic segmentation requires pixel-wise annotations, which can be time-consuming and expensive. To reduce the annotation cost, we propose a superpixel-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) framework, which collects a dominant label per superpixel instead. To be specific, it consists of adaptive superpixel and sieving mechanisms, fully dedicated to AL. At each round of AL, we adaptively merge neighboring pixels of similar learned features into superpixels. We then query a selected subset of these superpixels using an acquisition function assuming no uniform superpixel size. This approach is more efficient than existing methods, which rely only on innate features such as RGB color and assume uniform superpixel sizes. Obtaining a dominant label per superpixel drastically reduces annotators' burden as it requires fewer clicks. However, it inevitably introduces noisy annotations due to mismatches between superpixel and ground truth segmentation. To address this issue, we further devise a sieving mechanism that identifies and excludes potentially noisy annotations from learning. Our experiments on both Cityscapes and PASCAL VOC datasets demonstrate the efficacy of adaptive superpixel and sieving mechanisms.
        <a class="is-size-7" onclick="document.getElementById('2303.16817v2-abstract-full').style.display = 'none'; document.getElementById('2303.16817v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       20 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 29 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.16778">
         arXiv:2303.16778
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.16778">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.16778">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1007/978-3-031-34622-4_15">
           10.1007/978-3-031-34622-4_15
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Assorted, Archetypal and Annotated Two Million (3A2M) Cooking Recipes Dataset based on
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Sakib%2C+N">
        Nazmus Sakib
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shahariar%2C+G+M">
        G. M. Shahariar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kabir%2C+M+M">
        Md. Mohsinul Kabir
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hasan%2C+M+K">
        Md. Kamrul Hasan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mahmud%2C+H">
        Hasan Mahmud
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.16778v1-abstract-short" style="display: inline;">
        …could be a solution. In this study, we present a novel dataset of two million culinary recipes labeled in respective categories leveraging the knowledge of food experts and an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.16778v1-abstract-full').style.display = 'inline'; document.getElementById('2303.16778v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.16778v1-abstract-full" style="display: none;">
        Cooking recipes allow individuals to exchange culinary ideas and provide food preparation instructions. Due to a lack of adequate labeled data, categorizing raw recipes found online to the appropriate food genres is a challenging task in this domain. Utilizing the knowledge of domain experts to categorize recipes could be a solution. In this study, we present a novel dataset of two million culinary recipes labeled in respective categories leveraging the knowledge of food experts and an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        technique. To construct the dataset, we collect the recipes from the RecipeNLG dataset. Then, we employ three human experts whose trustworthiness score is higher than 86.667% to categorize 300K recipe by their Named Entity Recognition (NER) and assign it to one of the nine categories: bakery, drinks, non-veg, vegetables, fast food, cereals, meals, sides and fusion. Finally, we categorize the remaining 1900K recipes using
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        method with a blend of Query-by-Committee and Human In The Loop (HITL) approaches. There are more than two million recipes in our dataset, each of which is categorized and has a confidence score linked with it. For the 9 genres, the Fleiss Kappa score of this massive dataset is roughly 0.56026. We believe that the research community can use this dataset to perform various machine learning tasks such as recipe genre classification, recipe generation of a specific genre, new recipe creation, etc. The dataset can also be used to train and evaluate the performance of various NLP tasks such as named entity recognition, part-of-speech tagging, semantic role labeling, and so on. The dataset will be available upon publication: https://tinyurl.com/3zu4778y.
        <a class="is-size-7" onclick="document.getElementById('2303.16778v1-abstract-full').style.display = 'none'; document.getElementById('2303.16778v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       International Conference on Machine Intelligence and Emerging Technologies. MIET 2022. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, vol 491, pp 188-203, Springer, Cham
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.16698">
         arXiv:2303.16698
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.16698">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.16698">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">
         eess.SY
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">
         math.OC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neurons and Cognition">
         q-bio.NC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Probabilistic inverse optimal control for non-linear partially observable systems disentangles perceptual uncertainty and behavioral costs
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Straub%2C+D">
        Dominik Straub
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schultheis%2C+M">
        Matthias Schultheis
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Koeppl%2C+H">
        Heinz Koeppl
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rothkopf%2C+C+A">
        Constantin A. Rothkopf
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.16698v2-abstract-short" style="display: inline;">
        …and behavioral costs despite the fact that epistemic and pragmatic actions are intertwined in sequential decision-making under uncertainty, such as in active sensing and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . The proposed method has broad applicability, ranging from imitation learning to sensorimotor neuroscience.
        <a class="is-size-7" onclick="document.getElementById('2303.16698v2-abstract-full').style.display = 'inline'; document.getElementById('2303.16698v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.16698v2-abstract-full" style="display: none;">
        Inverse optimal control can be used to characterize behavior in sequential decision-making tasks. Most existing work, however, is limited to fully observable or linear systems, or requires the action signals to be known. Here, we introduce a probabilistic approach to inverse optimal control for partially observable stochastic non-linear systems with unobserved action signals, which unifies previous approaches to inverse optimal control with maximum causal entropy formulations. Using an explicit model of the noise characteristics of the sensory and motor systems of the agent in conjunction with local linearization techniques, we derive an approximate likelihood function for the model parameters, which can be computed within a single forward pass. We present quantitative evaluations on stochastic and partially observable versions of two classic control tasks and two human behavioral tasks. Importantly, we show that our method can disentangle perceptual factors and behavioral costs despite the fact that epistemic and pragmatic actions are intertwined in sequential decision-making under uncertainty, such as in active sensing and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . The proposed method has broad applicability, ranging from imitation learning to sensorimotor neuroscience.
        <a class="is-size-7" onclick="document.getElementById('2303.16698v2-abstract-full').style.display = 'none'; document.getElementById('2303.16698v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 October, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 29 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.16637">
         arXiv:2303.16637
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.16637">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.16637">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       MuRAL: Multi-Scale Region-based
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Object Detection
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Liou%2C+Y">
        Yi-Syuan Liou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+T">
        Tsung-Han Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yeh%2C+J">
        Jia-Fong Yeh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+W">
        Wen-Chin Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hsu%2C+W+H">
        Winston H. Hsu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.16637v1-abstract-short" style="display: inline;">
        …large-scale labeled object detection dataset can be costly and time-consuming, as it involves annotating images with bounding boxes and class labels. Thus, some specialized
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.16637v1-abstract-full').style.display = 'inline'; document.getElementById('2303.16637v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.16637v1-abstract-full" style="display: none;">
        Obtaining large-scale labeled object detection dataset can be costly and time-consuming, as it involves annotating images with bounding boxes and class labels. Thus, some specialized
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods have been proposed to reduce the cost by selecting either coarse-grained samples or fine-grained instances from unlabeled data for labeling. However, the former approaches suffer from redundant labeling, while the latter methods generally lead to training instability and sampling bias. To address these challenges, we propose a novel approach called Multi-scale Region-based
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (MuRAL) for object detection. MuRAL identifies informative regions of various scales to reduce annotation costs for well-learned objects and improve training performance. The informative region score is designed to consider both the predicted confidence of instances and the distribution of each object category, enabling our method to focus more on difficult-to-detect classes. Moreover, MuRAL employs a scale-aware selection strategy that ensures diverse regions are selected from different scales for labeling and downstream finetuning, which enhances training stability. Our proposed method surpasses all existing coarse-grained and fine-grained baselines on Cityscapes and MS COCO datasets, and demonstrates significant improvement in difficult category performance.
        <a class="is-size-7" onclick="document.getElementById('2303.16637v1-abstract-full').style.display = 'none'; document.getElementById('2303.16637v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.16538">
         arXiv:2303.16538
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.16538">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.16538">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1088/2632-2153/ace418">
           10.1088/2632-2153/ace418
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Efficient Generation of Stable Linear Machine-Learning Force Fields with Uncertainty-Aware
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Briganti%2C+V">
        Valerio Briganti
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lunghi%2C+A">
        Alessandro Lunghi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.16538v1-abstract-short" style="display: inline;">
        …However, large-scale applications of these methods rest on the possibility to train accurate machine learning models with a small number of ab initio data. In this respect,
        <span class="search-hit mathjax">
         active
        </span>
        -…
        <a class="is-size-7" onclick="document.getElementById('2303.16538v1-abstract-full').style.display = 'inline'; document.getElementById('2303.16538v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.16538v1-abstract-full" style="display: none;">
        Machine-learning force fields enable an accurate and universal description of the potential energy surface of molecules and materials on the basis of a training set of ab initio data. However, large-scale applications of these methods rest on the possibility to train accurate machine learning models with a small number of ab initio data. In this respect,
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        strategies, where the training set is self-generated by the model itself, combined with linear machine-learning models are particularly promising. In this work, we explore an
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        strategy based on linear regression and able to predict the model's uncertainty on predictions for molecular configurations not sampled by the training set, thus providing a straightforward recipe for the extension of the latter. We apply this strategy to the spectral neighbor analysis potential and show that only tens of ab initio simulations of atomic forces are required to generate stable force fields for room-temperature molecular dynamics at or close to chemical accuracy. Moreover, the method does not necessitate any conformational pre-sampling, thus requiring minimal user intervention and parametrization.
        <a class="is-size-7" onclick="document.getElementById('2303.16538v1-abstract-full').style.display = 'none'; document.getElementById('2303.16538v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.15823">
         arXiv:2303.15823
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.15823">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.15823">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applications">
         stat.AP
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1016/j.ecoinf.2023.102231">
           10.1016/j.ecoinf.2023.102231
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Automated wildlife image classification: An
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       tool for ecological applications
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Bothmann%2C+L">
        Ludwig Bothmann
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wimmer%2C+L">
        Lisa Wimmer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Charrakh%2C+O">
        Omid Charrakh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Weber%2C+T">
        Tobias Weber
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Edelhoff%2C+H">
        Hendrik Edelhoff
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Peters%2C+W">
        Wibke Peters
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nguyen%2C+H">
        Hien Nguyen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Benjamin%2C+C">
        Caryl Benjamin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Menzel%2C+A">
        Annette Menzel
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.15823v3-abstract-short" style="display: inline;">
        …proposal is two-fold: (1) We improve current strategies of combining object detection and image classification by tuning the hyperparameters of both models. (2) We provide an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) system that allows training deep learning models very efficiently in terms of required human-labeled training images. We sup…
        <a class="is-size-7" onclick="document.getElementById('2303.15823v3-abstract-full').style.display = 'inline'; document.getElementById('2303.15823v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.15823v3-abstract-full" style="display: none;">
        Wildlife camera trap images are being used extensively to investigate animal abundance, habitat associations, and behavior, which is complicated by the fact that experts must first classify the images manually. Artificial intelligence systems can take over this task but usually need a large number of already-labeled training images to achieve sufficient performance. This requirement necessitates human expert labor and poses a particular challenge for projects with few cameras or short durations. We propose a label-efficient learning strategy that enables researchers with small or medium-sized image databases to leverage the potential of modern machine learning, thus freeing crucial resources for subsequent analyses.
  Our methodological proposal is two-fold: (1) We improve current strategies of combining object detection and image classification by tuning the hyperparameters of both models. (2) We provide an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) system that allows training deep learning models very efficiently in terms of required human-labeled training images. We supply a software package that enables researchers to use these methods directly and thereby ensure the broad applicability of the proposed framework in ecological practice.
  We show that our tuning strategy improves predictive performance. We demonstrate how the AL pipeline reduces the amount of pre-labeled data needed to achieve a specific predictive performance and that it is especially valuable for improving out-of-sample predictive performance.
  We conclude that the combination of tuning and AL increases predictive performance substantially. Furthermore, we argue that our work can broadly impact the community through the ready-to-use software package provided. Finally, the publication of our models tailored to European wildlife data enriches existing model bases mostly trained on data from Africa and North America.
        <a class="is-size-7" onclick="document.getElementById('2303.15823v3-abstract-full').style.display = 'none'; document.getElementById('2303.15823v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 28 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Ecological Informatics (2023) 102231
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.15521">
         arXiv:2303.15521
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.15521">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.15521">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Chemical Physics">
         physics.chem-ph
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Reducing the cost of neural network potential generation for reactive molecular systems
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Brezina%2C+K">
        Krystof Brezina
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Beck%2C+H">
        Hubert Beck
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Marsalek%2C+O">
        Ondrej Marsalek
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.15521v1-abstract-short" style="display: inline;">
        …path describing a conformational change or a chemical reaction using only a sparse set of local normal mode expansions along this path and select from these geometries by an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        protocol. This yields a training set with geometries that characterize the whole transition without the need for a costly referenc…
        <a class="is-size-7" onclick="document.getElementById('2303.15521v1-abstract-full').style.display = 'inline'; document.getElementById('2303.15521v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.15521v1-abstract-full" style="display: none;">
        Although machine-learning potentials have recently had substantial impact on molecular simulations, the construction of a robust training set can still become a limiting factor, especially due to the requirement of a reference ab initio simulation that covers all the relevant geometries of the system. Recognizing that this can be prohibitive for certain systems, we develop the method of transition tube sampling that mitigates the computational cost of training set and model generation. In this approach, we generate classical or quantum thermal geometries around a transition path describing a conformational change or a chemical reaction using only a sparse set of local normal mode expansions along this path and select from these geometries by an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        protocol. This yields a training set with geometries that characterize the whole transition without the need for a costly reference trajectory. The performance of the method is evaluated on different molecular systems with the complexity of the potential energy landscape increasing from a single minimum to a double proton-transfer reaction with high barriers. Our results show that the method leads to training sets that give rise to models applicable in classical and path integral simulations alike that are on par with those based directly on ab initio calculations while providing the computational speed-up we have come to expect from machine-learning potentials.
        <a class="is-size-7" onclick="document.getElementById('2303.15521v1-abstract-full').style.display = 'none'; document.getElementById('2303.15521v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.15256">
         arXiv:2303.15256
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.15256">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.15256">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Self-Supervised Learning: A Few Low-Cost Relationships Are All You Need
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Cabannes%2C+V">
        Vivien Cabannes
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bottou%2C+L">
        Leon Bottou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lecun%2C+Y">
        Yann Lecun
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Balestriero%2C+R">
        Randall Balestriero
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.15256v2-abstract-short" style="display: inline;">
        …and is often tackled by ad-hoc strategies e.g. applying known data-augmentations to the same input. In this work, we formalize and generalize this principle through Positive
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.15256v2-abstract-full').style.display = 'inline'; document.getElementById('2303.15256v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.15256v2-abstract-full" style="display: none;">
        Self-Supervised Learning (SSL) has emerged as the solution of choice to learn transferable representations from unlabeled data. However, SSL requires to build samples that are known to be semantically akin, i.e. positive views. Requiring such knowledge is the main limitation of SSL and is often tackled by ad-hoc strategies e.g. applying known data-augmentations to the same input. In this work, we formalize and generalize this principle through Positive
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (PAL) where an oracle queries semantic relationships between samples. PAL achieves three main objectives. First, it unveils a theoretically grounded learning framework beyond SSL, based on similarity graphs, that can be extended to tackle supervised and semi-supervised learning depending on the employed oracle. Second, it provides a consistent algorithm to embed a priori knowledge, e.g. some observed labels, into any SSL losses without any change in the training pipeline. Third, it provides a proper
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework yielding low-cost solutions to annotate datasets, arguably bringing the gap between theory and practice of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        that is based on simple-to-answer-by-non-experts queries of semantic relationships between inputs.
        <a class="is-size-7" onclick="document.getElementById('2303.15256v2-abstract-full').style.display = 'none'; document.getElementById('2303.15256v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 27 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        8 main pages, 20 totals, 10 figures
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        ACM Class:
       </span>
       I.2.6
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.15107">
         arXiv:2303.15107
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.15107">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.15107">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ActiveSelfHAR: Incorporating Self Training into
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       to Improve Cross-Subject Human Activity Recognition
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Wei%2C+B">
        Baichun Wei
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yi%2C+C">
        Chunzhi Yi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+Q">
        Qi Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhu%2C+H">
        Haiqi Zhu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhu%2C+J">
        Jianfei Zhu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jiang%2C+F">
        Feng Jiang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.15107v1-abstract-short" style="display: inline;">
        …implementation of such methods is still hindered by the cross-subject issue when adapting to new users. To solve this issue, we propose ActiveSelfHAR, a framework that combines
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.15107v1-abstract-full').style.display = 'inline'; document.getElementById('2303.15107v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.15107v1-abstract-full" style="display: none;">
        Deep learning-based human activity recognition (HAR) methods have shown great promise in the applications of smart healthcare systems and wireless body sensor network (BSN). Despite their demonstrated performance in laboratory settings, the real-world implementation of such methods is still hindered by the cross-subject issue when adapting to new users. To solve this issue, we propose ActiveSelfHAR, a framework that combines
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning's
        </span>
        benefit of sparsely acquiring data with actual labels and self- training's benefit of effectively utilizing unlabeled data to enable the deep model to adapt to the target domain, i.e., the new users. In this framework, the model trained in the last iteration or the source domain is first utilized to generate pseudo labels of the target-domain samples and construct a self-training set based on the confidence score. Second, we propose to use the spatio-temporal relationships among the samples in the non-self-training set to augment the core set selected by
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Finally, we combine the self-training set and the augmented core set to fine-tune the model. We demonstrate our method by comparing it with state-of-the-art methods on two IMU-based datasets and an EMG-based dataset. Our method presents similar HAR accuracies with the upper bound, i.e. fully supervised fine-tuning with less than 1\% labeled data of the target dataset and significantly improves data efficiency and time cost. Our work highlights the potential of implementing user-independent HAR methods into smart healthcare systems and BSN.
        <a class="is-size-7" onclick="document.getElementById('2303.15107v1-abstract-full').style.display = 'none'; document.getElementById('2303.15107v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.14554">
         arXiv:2303.14554
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.14554">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Disordered Systems and Neural Networks">
         cond-mat.dis-nn
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Mesoscale and Nanoscale Physics">
         cond-mat.mes-hall
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep Kernel Methods Learn Better: From Cards to Process Optimization
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Valleti%2C+M">
        Mani Valleti
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Vasudevan%2C+R+K">
        Rama K. Vasudevan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ziatdinov%2C+M+A">
        Maxim A. Ziatdinov
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kalinin%2C+S+V">
        Sergei V. Kalinin
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.14554v2-abstract-short" style="display: inline;">
        …In the former case, the structure of the latent space is determined by the properties of the input data alone, while in the latter, the latent manifold forms as a result of an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.14554v2-abstract-full').style.display = 'inline'; document.getElementById('2303.14554v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.14554v2-abstract-full" style="display: none;">
        The ability of deep learning methods to perform classification and regression tasks relies heavily on their capacity to uncover manifolds in high-dimensional data spaces and project them into low-dimensional representation spaces. In this study, we investigate the structure and character of the manifolds generated by classical variational autoencoder (VAE) approaches and deep kernel learning (DKL). In the former case, the structure of the latent space is determined by the properties of the input data alone, while in the latter, the latent manifold forms as a result of an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        process that balances the data distribution and target functionalities. We show that DKL with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        can produce a more compact and smooth latent space which is more conducive to optimization compared to previously reported methods, such as the VAE. We demonstrate this behavior using a simple cards data set and extend it to the optimization of domain-generated trajectories in physical systems. Our findings suggest that latent manifolds constructed through
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        have a more beneficial structure for optimization problems, especially in feature-rich target-poor scenarios that are common in domain sciences, such as materials synthesis, energy storage, and molecular discovery. The jupyter notebooks that encapsulate the complete analysis accompany the article.
        <a class="is-size-7" onclick="document.getElementById('2303.14554v2-abstract-full').style.display = 'none'; document.getElementById('2303.14554v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 25 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        8 Figures, 26 pages
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.14433">
         arXiv:2303.14433
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.14433">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.14433">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with Contrastive Learning Under Realistic Data Pool Assumptions
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+J">
        Jihyo Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kim%2C+J">
        Jeonghyeon Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hwang%2C+S">
        Sangheum Hwang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.14433v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.14433v1-abstract-full').style.display = 'inline'; document.getElementById('2303.14433v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.14433v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        aims to identify the most informative data from an unlabeled data pool that enables a model to reach the desired accuracy rapidly. This benefits especially deep neural networks which generally require a huge number of labeled samples to achieve high performance. Most existing
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods have been evaluated in an ideal setting where only samples relevant to the target task, i.e., in-distribution samples, exist in an unlabeled data pool. A data pool gathered from the wild, however, is likely to include samples that are irrelevant to the target task at all and/or too ambiguous to assign a single class label even for the oracle. We argue that assuming an unlabeled data pool consisting of samples from various distributions is more realistic. In this work, we introduce new
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        benchmarks that include ambiguous, task-irrelevant out-of-distribution as well as in-distribution samples. We also propose an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        method designed to acquire informative in-distribution samples in priority. The proposed method leverages both labeled and unlabeled data pools and selects samples from clusters on the feature space constructed via contrastive learning. Experimental results demonstrate that the proposed method requires a lower annotation budget than existing
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods to reach the same level of accuracy.
        <a class="is-size-7" onclick="document.getElementById('2303.14433v1-abstract-full').style.display = 'none'; document.getElementById('2303.14433v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       25 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        AAAI 2023 Workshop on Practical Deep Learning in the Wild
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.13754">
         arXiv:2303.13754
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.13754">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Statistical Mechanics">
         cond-mat.stat-mech
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1063/5.0150137">
           10.1063/5.0150137
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Bayesian Optimization of Metastable Nickel Formation During the Spontaneous Crystallization under Extreme Conditions
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Estalaki%2C+S+M">
        Sina Malakpour Estalaki
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Luo%2C+T">
        Tengfei Luo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Manukyan%2C+K+V">
        Khachatur V. Manukyan
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.13754v1-abstract-short" style="display: inline;">
        …and pressure are control variables. MD simulations provide data for training the GP model, which is then used with BO to predict the next simulation condition. Such a BO-guided
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        leads to a maximum hcp-Ni fraction of 43.38% in the final crystalized phase within 40 iterations when a face-centered cubic (fc…
        <a class="is-size-7" onclick="document.getElementById('2303.13754v1-abstract-full').style.display = 'inline'; document.getElementById('2303.13754v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.13754v1-abstract-full" style="display: none;">
        Spontaneous crystallization of metals under extreme conditions is a unique phenomenon occurring under far-from-equilibrium conditions that could enable the development of revolutionary and disruptive metastable metals with unusual properties. In this work, the formation of the hexagonal close-packed Nickel (hcp-Ni) metastable phase during spontaneous crystallization is studied using non-equilibrium molecular dynamics (MD) simulations, with the goal of maximizing the fraction of this metastable phase in the final state. We employ Bayesian Optimization (BO) with the Gaussian Processes (GP) regression as the surrogate model to maximize the hcp-Ni phase fraction, where temperature and pressure are control variables. MD simulations provide data for training the GP model, which is then used with BO to predict the next simulation condition. Such a BO-guided
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        leads to a maximum hcp-Ni fraction of 43.38% in the final crystalized phase within 40 iterations when a face-centered cubic (fcc) crystallite serves as the seed for crystallization from the amorphous phase. When an hcp seed is used, the maximum hcp-Ni fraction in the final crystal increases to 58.25% with 13 iterations. This study shows the promise of using BO to identify the process conditions that can maximize the rare phases. This method can also be generally applicable to process optimization to achieve target material properties.
        <a class="is-size-7" onclick="document.getElementById('2303.13754v1-abstract-full').style.display = 'none'; document.getElementById('2303.13754v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.13089">
         arXiv:2303.13089
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.13089">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.13089">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Box-Level Active Detection
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Lyu%2C+M">
        Mengyao Lyu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhou%2C+J">
        Jundong Zhou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+H">
        Hui Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">
        Yijie Huang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yu%2C+D">
        Dongdong Yu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Y">
        Yaqian Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Guo%2C+Y">
        Yandong Guo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Guo%2C+Y">
        Yuchen Guo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xiang%2C+L">
        Liuyu Xiang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ding%2C+G">
        Guiguang Ding
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.13089v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        selects informative samples for annotation within budget, which has proven efficient recently on object detection. However, the widely used active detection benchmarks conduct image-level evaluation, which is unrealistic in human workload estimation and biased towards crowded images. Furthermore, existi…
        <a class="is-size-7" onclick="document.getElementById('2303.13089v1-abstract-full').style.display = 'inline'; document.getElementById('2303.13089v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.13089v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        selects informative samples for annotation within budget, which has proven efficient recently on object detection. However, the widely used active detection benchmarks conduct image-level evaluation, which is unrealistic in human workload estimation and biased towards crowded images. Furthermore, existing methods still perform image-level annotation, but equally scoring all targets within the same image incurs waste of budget and redundant labels. Having revealed above problems and limitations, we introduce a box-level active detection framework that controls a box-based budget per cycle, prioritizes informative targets and avoids redundancy for fair comparison and efficient application.
  Under the proposed box-level setting, we devise a novel pipeline, namely Complementary Pseudo Active Strategy (ComPAS). It exploits both human annotations and the model intelligence in a complementary fashion: an efficient input-end committee queries labels for informative objects only; meantime well-learned targets are identified by the model and compensated with pseudo-labels. ComPAS consistently outperforms 10 competitors under 4 settings in a unified codebase. With supervision from labeled data only, it achieves 100% supervised performance of VOC0712 with merely 19% box annotations. On the COCO dataset, it yields up to 4.3% mAP improvement over the second-best method. ComPAS also supports training with the unlabeled pool, where it surpasses 90% COCO supervised performance with 85% label reduction. Our source code is publicly available at https://github.com/lyumengyao/blad.
        <a class="is-size-7" onclick="document.getElementById('2303.13089v1-abstract-full').style.display = 'none'; document.getElementById('2303.13089v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        CVPR 2023 highlight
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.12924">
         arXiv:2303.12924
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.12924">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.12924">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Sensitivity Analysis of $γ^\prime$(L1$_2$) Precipitate Morphology of Ternary Co-Based Superalloys
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tso%2C+W">
        Whitney Tso
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+W">
        Wenkun Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Seidman%2C+D+N">
        David N. Seidman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Heinonen%2C+O+G">
        Olle G. Heinonen
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.12924v1-abstract-short" style="display: inline;">
        …size and morphology. Gaussian Process Regression (GPR) models are used to fit the sample points and to generate surrogate models for both precipitate size and morphology. In an
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        approach, a Bayesian Optimization algorithm is coupled with the GPR models to suggest new sample points to calculate and effici…
        <a class="is-size-7" onclick="document.getElementById('2303.12924v1-abstract-full').style.display = 'inline'; document.getElementById('2303.12924v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.12924v1-abstract-full" style="display: none;">
        To better understand the equilibrium $γ^\prime$(L1$_2$) precipitate morphology in Co-based superalloys, a phase field modeling sensitivity analysis is conducted to examine how four phase-field parameters [initial Co concentration ($c_0$), double-well barrier height ($ω$), gradient energy density coefficient ($κ$), and lattice misfit strain ($ε_{\rm misfit}$)] influence the $γ^\prime$(L1$_2$) precipitate size and morphology. Gaussian Process Regression (GPR) models are used to fit the sample points and to generate surrogate models for both precipitate size and morphology. In an
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        approach, a Bayesian Optimization algorithm is coupled with the GPR models to suggest new sample points to calculate and efficiently update the models based on a reduction of uncertainty. The algorithm has a user-defined objective, which controls the balance between exploration and exploitation for new suggested points. Our methodology provides a qualitative and quantitative relationship between the $γ^\prime$(L1$_2$) precipitate size and morphology and the four phase-field parameters, and concludes that the most sensitive phase-field parameter for precipitate size and morphology is the initial Co concentration ($c_0$) and the double-well barrier height ($ω$), respectively. We note that the GPR model for precipitate morphology required adding a noise tolerance in order to avoid overfitting due to irregularities in some of the simulated equilibrium $γ^\prime$(L1$_2$) precipitate morphology.
        <a class="is-size-7" onclick="document.getElementById('2303.12924v1-abstract-full').style.display = 'none'; document.getElementById('2303.12924v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       22 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        24 pages, 10 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.12760">
         arXiv:2303.12760
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.12760">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Uncertainty Aware
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Reconfiguration of Pre-trained Deep Object-Detection Networks for New Target Domains
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Na%2C+J">
        Jiaming Na
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=De-Silva%2C+V">
        Varuna De-Silva
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.12760v1-abstract-short" style="display: inline;">
        …the most informative frames from a video to annotate has become a highly practical task to solve but attracted little attention in research. In this paper, we proposed a novel
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.12760v1-abstract-full').style.display = 'inline'; document.getElementById('2303.12760v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.12760v1-abstract-full" style="display: none;">
        Object detection is one of the most important and fundamental aspects of computer vision tasks, which has been broadly utilized in pose estimation, object tracking and instance segmentation models. To obtain training data for object detection model efficiently, many datasets opt to obtain their unannotated data in video format and the annotator needs to draw a bounding box around each object in the images. Annotating every frame from a video is costly and inefficient since many frames contain very similar information for the model to learn from. How to select the most informative frames from a video to annotate has become a highly practical task to solve but attracted little attention in research. In this paper, we proposed a novel
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm for object detection models to tackle this problem. In the proposed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm, both classification and localization informativeness of unlabelled data are measured and aggregated. Utilizing the temporal information from video frames, two novel localization informativeness measurements are proposed. Furthermore, a weight curve is proposed to avoid querying adjacent frames. Proposed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        algorithm with multiple configurations was evaluated on the MuPoTS dataset and FootballPD dataset.
        <a class="is-size-7" onclick="document.getElementById('2303.12760v1-abstract-full').style.display = 'none'; document.getElementById('2303.12760v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       22 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.12317">
         arXiv:2303.12317
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.12317">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.12317">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Re-thinking Federated
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       based on Inter-class Diversity
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+S">
        SangMook Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bae%2C+S">
        Sangmin Bae
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Song%2C+H">
        Hwanjun Song
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yun%2C+S">
        Se-Young Yun
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.12317v1-abstract-short" style="display: inline;">
        …However, in a real-world scenario, every client may have a significant amount of unlabeled instances. Among the various approaches to utilizing unlabeled data, a federated
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.12317v1-abstract-full').style.display = 'inline'; document.getElementById('2303.12317v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.12317v1-abstract-full" style="display: none;">
        Although federated learning has made awe-inspiring advances, most studies have assumed that the client's data are fully labeled. However, in a real-world scenario, every client may have a significant amount of unlabeled instances. Among the various approaches to utilizing unlabeled data, a federated
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework has emerged as a promising solution. In the decentralized setting, there are two types of available query selector models, namely 'global' and 'local-only' models, but little literature discusses their performance dominance and its causes. In this work, we first demonstrate that the superiority of two selector models depends on the global and local inter-class diversity. Furthermore, we observe that the global and local-only models are the keys to resolving the imbalance of each side. Based on our findings, we propose LoGo, a FAL sampling strategy robust to varying local heterogeneity levels and global imbalance ratio, that integrates both models by two steps of active selection scheme. LoGo consistently outperforms six
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies in the total number of 38 experimental settings.
        <a class="is-size-7" onclick="document.getElementById('2303.12317v1-abstract-full').style.display = 'none'; document.getElementById('2303.12317v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       22 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        CVPR 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.11564">
         arXiv:2303.11564
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.11564">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.11564">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Agave crop segmentation and maturity classification with deep learning data-centric strategies using very high-resolution satellite imagery
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=S%C3%A1nchez%2C+A">
        Abraham Sánchez
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nanclares%2C+R">
        Raúl Nanclares
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Quevedo%2C+A">
        Alexander Quevedo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pelagio%2C+U">
        Ulises Pelagio
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Aguilar%2C+A">
        Alejandra Aguilar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Calvario%2C+G">
        Gabriela Calvario
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Moya-S%C3%A1nchez%2C+E+U">
        E. Ulises Moya-Sánchez
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.11564v2-abstract-short" style="display: inline;">
        …such as lack of data, low quality labels, highly imbalanced data, and low model performance. The proposed strategies go beyond data augmentation and data transfer combining
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and the creation of synthetic images with human supervision. As a result, the segmentation performance evaluated with Intersection…
        <a class="is-size-7" onclick="document.getElementById('2303.11564v2-abstract-full').style.display = 'inline'; document.getElementById('2303.11564v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.11564v2-abstract-full" style="display: none;">
        The responsible and sustainable agave-tequila production chain is fundamental for the social, environment and economic development of Mexico's agave regions. It is therefore relevant to develop new tools for large scale automatic agave region monitoring. In this work, we present an Agave tequilana Weber azul crop segmentation and maturity classification using very high resolution satellite imagery, which could be useful for this task. To achieve this, we solve real-world deep learning problems in the very specific context of agave crop segmentation such as lack of data, low quality labels, highly imbalanced data, and low model performance. The proposed strategies go beyond data augmentation and data transfer combining
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and the creation of synthetic images with human supervision. As a result, the segmentation performance evaluated with Intersection over Union (IoU) value increased from 0.72 to 0.90 in the test set. We also propose a method for classifying agave crop maturity with 95% accuracy. With the resulting accurate models, agave production forecasting can be made available for large regions. In addition, some supply-demand problems such excessive supplies of agave or, deforestation, could be detected early.
        <a class="is-size-7" onclick="document.getElementById('2303.11564v2-abstract-full').style.display = 'none'; document.getElementById('2303.11564v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 20 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 pages, 8 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.11530">
         arXiv:2303.11530
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.11530">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.11530">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Coarse-to-Fine Segmentation of Moveable Parts from Real Images
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Wang%2C+R">
        Ruiqi Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Patil%2C+A+G">
        Akshay Gadi Patil
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yu%2C+F">
        Fenggen Yu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">
        Hao Zhang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.11530v2-abstract-short" style="display: inline;">
        We introduce the first
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) framework for high-accuracy instance segmentation of moveable parts from RGB images of real indoor scenes. As with most human-in-the-loop approaches, the key criterion for success in AL is to minimize human effort while still attaining high performance. To this end, we employ…
        <a class="is-size-7" onclick="document.getElementById('2303.11530v2-abstract-full').style.display = 'inline'; document.getElementById('2303.11530v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.11530v2-abstract-full" style="display: none;">
        We introduce the first
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) framework for high-accuracy instance segmentation of moveable parts from RGB images of real indoor scenes. As with most human-in-the-loop approaches, the key criterion for success in AL is to minimize human effort while still attaining high performance. To this end, we employ a transformer that utilizes a masked-attention mechanism to supervise the active segmentation. To enhance the network tailored to moveable parts, we introduce a coarse-to-fine AL approach which first uses an object-aware masked attention and then a pose-aware one, leveraging the hierarchical nature of the problem and a correlation between moveable parts and object poses and interaction directions. Our method achieves close to fully accurate (96% and higher) segmentation results, with semantic labels, on real images, with 82% time saving over manual effort, where the training data consists of only 11.45% annotated real photographs. At last, we contribute a dataset of 2,550 real photographs with annotated moveable parts, demonstrating its superior quality and diversity over the current best alternatives.
        <a class="is-size-7" onclick="document.getElementById('2303.11530v2-abstract-full').style.display = 'none'; document.getElementById('2303.11530v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 November, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 20 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.11295">
         arXiv:2303.11295
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.11295">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.11295">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Soft Condensed Matter">
         cond-mat.soft
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">
         cs.RO
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Rapid design of fully soft deployable structures via kirigami cuts and
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Ma%2C+L">
        Leixin Ma
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mungekar%2C+M">
        Mrunmayi Mungekar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Roychowdhury%2C+V">
        Vwani Roychowdhury
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jawed%2C+M+K">
        M. Khalid Jawed
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.11295v1-abstract-short" style="display: inline;">
        …framework that reduces the dimensionality of the inverse design problem using autoencoders and efficiently searches through the ``latent" parameter space in an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach. We demonstrate the effectiveness of the rapid design procedure via a range of target shapes, such as peanuts, pringles, flowers, a…
        <a class="is-size-7" onclick="document.getElementById('2303.11295v1-abstract-full').style.display = 'inline'; document.getElementById('2303.11295v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.11295v1-abstract-full" style="display: none;">
        Soft deployable structures - unlike conventional piecewise rigid deployables based on hinges and springs - can assume intricate 3-D shapes, thereby enabling transformative technologies in soft robotics, shape-morphing architecture, and pop-up manufacturing. Their virtually infinite degrees of freedom allow precise control over the final shape. The same enabling high dimensionality, however, poses a challenge for solving the inverse design problem involving this class of structures: to achieve desired 3D structures it typically requires manufacturing technologies with extensive local actuation and control during fabrication, and a trial and error search over a large design space. We address both of these shortcomings by first developing a simplified planar fabrication approach that combines two ingredients: strain mismatch between two layers of a composite shell and kirigami cuts that relieves localized stress. In principle, it is possible to generate targeted 3-D shapes by designing the appropriate kirigami cuts and selecting the right amount of prestretch, thereby eliminating the need for local control. Second, we formulate a data-driven physics-guided framework that reduces the dimensionality of the inverse design problem using autoencoders and efficiently searches through the ``latent" parameter space in an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach. We demonstrate the effectiveness of the rapid design procedure via a range of target shapes, such as peanuts, pringles, flowers, and pyramids. Tabletop experiments are conducted to fabricate the target shapes. Experimental results and numerical predictions from our framework are found to be in good agreement.
        <a class="is-size-7" onclick="document.getElementById('2303.11295v1-abstract-full').style.display = 'none'; document.getElementById('2303.11295v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.10338">
         arXiv:2303.10338
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.10338">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A general-purpose AI assistant embedded in an open-source radiology information system
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Purkayastha%2C+S">
        Saptarshi Purkayastha
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Isaac%2C+R">
        Rohan Isaac
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Anthony%2C+S">
        Sharon Anthony
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shukla%2C+S">
        Shikhar Shukla
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Krupinski%2C+E+A">
        Elizabeth A. Krupinski
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Danish%2C+J+A">
        Joshua A. Danish
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gichoya%2C+J+W">
        Judy W. Gichoya
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.10338v1-abstract-short" style="display: inline;">
        …of the platform, including few-shot learning and swarm learning approaches to retrain the AI models continuously. Building on the concept of machine teaching, we developed an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy within the RIS, so that the human radiologist can enable/disable AI annotations as well as "fix"/relabel the AI…
        <a class="is-size-7" onclick="document.getElementById('2303.10338v1-abstract-full').style.display = 'inline'; document.getElementById('2303.10338v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.10338v1-abstract-full" style="display: none;">
        Radiology AI models have made significant progress in near-human performance or surpassing it. However, AI model's partnership with human radiologist remains an unexplored challenge due to the lack of health information standards, contextual and workflow differences, and data labeling variations. To overcome these challenges, we integrated an AI model service that uses DICOM standard SR annotations into the OHIF viewer in the open-source LibreHealth Radiology Information Systems (RIS). In this paper, we describe the novel Human-AI partnership capabilities of the platform, including few-shot learning and swarm learning approaches to retrain the AI models continuously. Building on the concept of machine teaching, we developed an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategy within the RIS, so that the human radiologist can enable/disable AI annotations as well as "fix"/relabel the AI annotations. These annotations are then used to retrain the models. This helps establish a partnership between the radiologist user and a user-specific AI model. The weights of these user-specific models are then finally shared between multiple models in a swarm learning approach.
        <a class="is-size-7" onclick="document.getElementById('2303.10338v1-abstract-full').style.display = 'none'; document.getElementById('2303.10338v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       18 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Full research paper version of the demo paper accepted at the AIME 2023 - 21st International Conference of Artificial Intelligence in Medicine
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.10022">
         arXiv:2303.10022
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.10022">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.10022">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Hierarchical-Hyperplane Kernels for
       <span class="search-hit mathjax">
        Actively
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Gaussian Process Models of Nonstationary Systems
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Bitzer%2C+M">
        Matthias Bitzer
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Meister%2C+M">
        Mona Meister
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zimmer%2C+C">
        Christoph Zimmer
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.10022v1-abstract-short" style="display: inline;">
        …learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.10022v1-abstract-full').style.display = 'inline'; document.getElementById('2303.10022v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.10022v1-abstract-full" style="display: none;">
        Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible than previous ones, while still being applicable in the low data regime. Thus, it provides a good prior for
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        procedures. We empirically demonstrate excellent performance on various
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        tasks.
        <a class="is-size-7" onclick="document.getElementById('2303.10022v1-abstract-full').style.display = 'none'; document.getElementById('2303.10022v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at AISTATS 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.09960">
         arXiv:2303.09960
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.09960">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/ps/2303.09960">
          ps
         </a>
         ,
         <a href="https://arxiv.org/format/2303.09960">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">
         math.OC
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Stochastic Submodular Maximization via Polynomial Estimators
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=%C3%96zcan%2C+G">
        Gözde Özcan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ioannidis%2C+S">
        Stratis Ioannidis
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.09960v1-abstract-short" style="display: inline;">
        …submodular maximization problems with general matroid constraints, that naturally arise in online learning, team formation, facility location, influence maximization,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a clas…
        <a class="is-size-7" onclick="document.getElementById('2303.09960v1-abstract-full').style.display = 'inline'; document.getElementById('2303.09960v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.09960v1-abstract-full" style="display: none;">
        In this paper, we study stochastic submodular maximization problems with general matroid constraints, that naturally arise in online learning, team formation, facility location, influence maximization,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approximation ratio (in expectation) arbitrarily close to $(1-1/e) \approx 63\%$ using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time.
        <a class="is-size-7" onclick="document.getElementById('2303.09960v1-abstract-full').style.display = 'none'; document.getElementById('2303.09960v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        23 pages, accepted to 27th Pasific-Asian Conference on Knowledge Discovery and Data Mining
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.09910">
         arXiv:2303.09910
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.09910">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.09910">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">
         eess.SY
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       -based Model Predictive Coverage Control
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rickenbach%2C+R">
        Rahel Rickenbach
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=K%C3%B6hler%2C+J">
        Johannes Köhler
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Scampicchio%2C+A">
        Anna Scampicchio
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zeilinger%2C+M+N">
        Melanie N. Zeilinger
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Carron%2C+A">
        Andrea Carron
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.09910v1-abstract-short" style="display: inline;">
        …explored by the agents. In addition, we derive a control framework that avoids the hierarchical structure by integrating the reference optimization in the MPC formulation.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is then performed drawing inspiration from Upper Confidence Bound (UCB) approaches. We guarantee recursive feasibility and convergen…
        <a class="is-size-7" onclick="document.getElementById('2303.09910v1-abstract-full').style.display = 'inline'; document.getElementById('2303.09910v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.09910v1-abstract-full" style="display: none;">
        The problem of coverage control, i.e., of coordinating multiple agents to optimally cover an area, arises in various applications. However, existing coverage algorithms face two major challenges: (1) dealing with nonlinear dynamics while respecting system and safety critical constraints, and (2) performing the task in an initially unknown environment. We solve the coverage problem by using a hierarchical framework, where references are calculated at a central server and passed to the agents' local model predictive control (MPC) tracking schemes. Furthermore, a probabilistic exploration-exploitation trade-off is deployed to ensure that the environment is actively explored by the agents. In addition, we derive a control framework that avoids the hierarchical structure by integrating the reference optimization in the MPC formulation.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is then performed drawing inspiration from Upper Confidence Bound (UCB) approaches. We guarantee recursive feasibility and convergence to an optimal configuration for all developed control architectures. Furthermore, all methods are tested and compared on hardware using a miniature car platform.
        <a class="is-size-7" onclick="document.getElementById('2303.09910v1-abstract-full').style.display = 'none'; document.getElementById('2303.09910v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.08978">
         arXiv:2303.08978
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.08978">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.08978">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Semi-Supervised Learning by Exploring Per-Sample Uncertainty and Consistency
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Lim%2C+J">
        Jaeseung Lim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Na%2C+J">
        Jongkeun Na
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kwak%2C+N">
        Nojun Kwak
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.08978v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) and Semi-supervised Learning are two techniques that have been studied to reduce the high cost of deep learning by using a small amount of labeled data and a large amount of unlabeled data. To improve the accuracy of models at a lower cost, we propose a method called Active Semi-supervised Learning…
        <a class="is-size-7" onclick="document.getElementById('2303.08978v1-abstract-full').style.display = 'inline'; document.getElementById('2303.08978v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.08978v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) and Semi-supervised Learning are two techniques that have been studied to reduce the high cost of deep learning by using a small amount of labeled data and a large amount of unlabeled data. To improve the accuracy of models at a lower cost, we propose a method called Active Semi-supervised Learning (ASSL), which combines AL and SSL. To maximize the synergy between AL and SSL, we focused on the differences between ASSL and AL. ASSL involves more dynamic model updates than AL due to the use of unlabeled data in the training process, resulting in the temporal instability of the predicted probabilities of the unlabeled data. This makes it difficult to determine the true uncertainty of the unlabeled data in ASSL. To address this, we adopted techniques such as exponential moving average (EMA) and upper confidence bound (UCB) used in reinforcement learning. Additionally, we analyzed the effect of label noise on unsupervised learning by using weak and strong augmentation pairs to address datainconsistency. By considering both uncertainty and datainconsistency, we acquired data samples that were used in the proposed ASSL method. Our experiments showed that ASSL achieved about 5.3 times higher computational efficiency than SSL while achieving the same performance, and it outperformed the state-of-the-art AL method.
        <a class="is-size-7" onclick="document.getElementById('2303.08978v1-abstract-full').style.display = 'none'; document.getElementById('2303.08978v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.08915">
         arXiv:2303.08915
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.08915">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.08915">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Genomics">
         q-bio.GN
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       LRDB: LSTM Raw data DNA Base-caller based on long-short term models in an
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       environment
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rezaei%2C+A">
        Ahmad Rezaei
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Taheri%2C+M">
        Mahdi Taheri
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mahani%2C+A">
        Ali Mahani
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Magierowski%2C+S">
        Sebastian Magierowski
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.08915v1-abstract-short" style="display: inline;">
        The first important step in extracting DNA characters is using the output data of MinION devices in the form of electrical current signals. Various cutting-edge base callers use this data to detect the DNA characters based on the input. In this paper, we discuss several shortcomings of prior base callers in the case of time-critical applications, privacy-aware design, and the problem of catastroph…
        <a class="is-size-7" onclick="document.getElementById('2303.08915v1-abstract-full').style.display = 'inline'; document.getElementById('2303.08915v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.08915v1-abstract-full" style="display: none;">
        The first important step in extracting DNA characters is using the output data of MinION devices in the form of electrical current signals. Various cutting-edge base callers use this data to detect the DNA characters based on the input. In this paper, we discuss several shortcomings of prior base callers in the case of time-critical applications, privacy-aware design, and the problem of catastrophic forgetting. Next, we propose the LRDB model, a lightweight open-source model for private developments with a better read-identity (0.35% increase) for the target bacterial samples in the paper. We have limited the extent of training data and benefited from the transfer learning algorithm to make the active usage of the LRDB viable in critical applications. Henceforth, less training time for adapting to new DNA samples (in our case, Bacterial samples) is needed. Furthermore, LRDB can be modified concerning the user constraints as the results show a negligible accuracy loss in case of using fewer parameters. We have also assessed the noise-tolerance property, which offers about a 1.439% decline in accuracy for a 15dB noise injection, and the performance metrics show that the model executes in a medium speed range compared with current cutting-edge models.
        <a class="is-size-7" onclick="document.getElementById('2303.08915v1-abstract-full').style.display = 'none'; document.getElementById('2303.08915v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 figures, 6 table
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.08426">
         arXiv:2303.08426
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.08426">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.08426">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Structural disorder by octahedral tilting in inorganic halide perovskites: New insight with Bayesian optimization
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+J">
        Jingrui Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pan%2C+F">
        Fang Pan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+G">
        Guo-Xu Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">
        Zenghui Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Dong%2C+H">
        Hua Dong
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+D">
        Dawei Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jiang%2C+Z">
        Zhuangde Jiang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ren%2C+W">
        Wei Ren
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ye%2C+Z">
        Zuo-Guang Ye
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Todorovi%C4%87%2C+M">
        Milica Todorović
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rinke%2C+P">
        Patrick Rinke
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.08426v1-abstract-short" style="display: inline;">
        …integrated density-functional-theory (DFT) calculations. The rapid convergence of the PES with about 200 DFT data points in three-dimensional searches demonstrates the power of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and strategic sampling with Bayesian optimization. Further analysis indicates that disorder grows with increasing temperature,…
        <a class="is-size-7" onclick="document.getElementById('2303.08426v1-abstract-full').style.display = 'inline'; document.getElementById('2303.08426v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.08426v1-abstract-full" style="display: none;">
        Structural disorder is common in metal-halide perovskites and important for understanding the functional properties of these materials. First-principles methods can address structure variation on the atomistic scale, but they are often limited by the lack of structure-sampling schemes required to characterize the disorder. In this work, structural disorder in the benchmark inorganic halide perovskites CsPbI$_3^{}$ and CsPbBr$_3^{}$ is computationally studied in terms of the three octahedral-tilting angles. The consequent variation in energetics and properties are described by three-dimensional potential-energy surfaces (PESs) and property landscapes, delivered by Bayesian Optimization Structure Search method with integrated density-functional-theory (DFT) calculations. The rapid convergence of the PES with about 200 DFT data points in three-dimensional searches demonstrates the power of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and strategic sampling with Bayesian optimization. Further analysis indicates that disorder grows with increasing temperature, and reveals that the materials band gap at finite temperatures is a statistical mean over disordered structures.
        <a class="is-size-7" onclick="document.getElementById('2303.08426v1-abstract-full').style.display = 'none'; document.getElementById('2303.08426v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.08054">
         arXiv:2303.08054
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.08054">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.08054">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Hardware Architecture">
         cs.AR
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Statistical Hardware Design With Multi-model
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Ghaffari%2C+A">
        Alireza Ghaffari
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Asgharian%2C+M">
        Masoud Asgharian
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Savaria%2C+Y">
        Yvon Savaria
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.08054v5-abstract-short" style="display: inline;">
        …method to find the optimal solution. One promising approach to tackle this problem is statistical modeling of a desired hardware performance. Here, we propose a model-based
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.08054v5-abstract-full').style.display = 'inline'; document.getElementById('2303.08054v5-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.08054v5-abstract-full" style="display: none;">
        With the rising complexity of numerous novel applications that serve our modern society comes the strong need to design efficient computing platforms. Designing efficient hardware is, however, a complex multi-objective problem that deals with multiple parameters and their interactions. Given that there are a large number of parameters and objectives involved in hardware design, synthesizing all possible combinations is not a feasible method to find the optimal solution. One promising approach to tackle this problem is statistical modeling of a desired hardware performance. Here, we propose a model-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach to solve this problem. Our proposed method uses Bayesian models to characterize various aspects of hardware performance. We also use transfer learning and Gaussian regression bootstrapping techniques in conjunction with
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to create more accurate models. Our proposed statistical modeling method provides hardware models that are sufficiently accurate to perform design space exploration as well as performance prediction simultaneously. We use our proposed method to perform design space exploration and performance prediction for various hardware setups, such as micro-architecture design and OpenCL kernels for FPGA targets. Our experiments show that the number of samples required to create performance models significantly reduces while maintaining the predictive power of our proposed statistical models. For instance, in our performance prediction setting, the proposed method needs 65% fewer samples to create the model, and in the design space exploration setting, our proposed method can find the best parameter settings by exploring less than 50 samples.
        <a class="is-size-7" onclick="document.getElementById('2303.08054v5-abstract-full').style.display = 'none'; document.getElementById('2303.08054v5-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       9 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 14 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        added a reference for GRP subsampling and corrected typos
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.07465">
         arXiv:2303.07465
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.07465">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.07465">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Materials Science">
         cond-mat.mtrl-sci
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1557/s43578-023-01123-5">
           10.1557/s43578-023-01123-5
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Atomic cluster expansion for Pt-Rh catalysts: From ab initio to the simulation of nanoclusters in few steps
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Liang%2C+Y">
        Yanyan Liang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mrovec%2C+M">
        Matous Mrovec
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lysogorskiy%2C+Y">
        Yury Lysogorskiy
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Vega-Paredes%2C+M">
        Miquel Vega-Paredes
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Scheu%2C+C">
        Christina Scheu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Drautz%2C+R">
        Ralf Drautz
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.07465v1-abstract-short" style="display: inline;">
        …ab initio data. The main steps of the workflow are the generation of training data from accurate electronic structure calculations, an efficient fitting procedure supported by
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and uncertainty indication, and a thorough validation. We apply the workflow to the simulation of binary Pt-Rh nanoparticles tha…
        <a class="is-size-7" onclick="document.getElementById('2303.07465v1-abstract-full').style.display = 'inline'; document.getElementById('2303.07465v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.07465v1-abstract-full" style="display: none;">
        Insight into structural and thermodynamic properties of nanoparticles is crucial for designing optimal catalysts with enhanced activity and stability. We present a semi-automated workflow for parameterizing the atomic cluster expansion (ACE) from ab initio data. The main steps of the workflow are the generation of training data from accurate electronic structure calculations, an efficient fitting procedure supported by
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        and uncertainty indication, and a thorough validation. We apply the workflow to the simulation of binary Pt-Rh nanoparticles that are important for catalytic applications. We demonstrate that the Pt-Rh ACE is able to reproduce accurately a broad range of fundamental properties of the elemental metals as well as their compounds while retaining an outstanding computational efficiency. This enables a direct comparison of simulations to high resolution experiments.
        <a class="is-size-7" onclick="document.getElementById('2303.07465v1-abstract-full').style.display = 'none'; document.getElementById('2303.07465v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       13 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Journal of Materials Research (2023)
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.06250">
         arXiv:2303.06250
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.06250">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.06250">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       ReBound: An Open-Source 3D Bounding Box Annotation Tool for
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chen%2C+W">
        Wesley Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Edgley%2C+A">
        Andrew Edgley
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hota%2C+R">
        Raunak Hota
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+J">
        Joshua Liu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Schwartz%2C+E">
        Ezra Schwartz
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yizar%2C+A">
        Aminah Yizar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Peri%2C+N">
        Neehar Peri
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Purtilo%2C+J">
        James Purtilo
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.06250v1-abstract-short" style="display: inline;">
        …of our tool and present survey results that highlight the usability of our software. Further, we show that ReBound is effective for exploratory data analysis and can facilitate
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        . Our code and documentation is available at https://github.com/ajedgley/ReBound
        <a class="is-size-7" onclick="document.getElementById('2303.06250v1-abstract-full').style.display = 'inline'; document.getElementById('2303.06250v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.06250v1-abstract-full" style="display: none;">
        In recent years, supervised learning has become the dominant paradigm for training deep-learning based methods for 3D object detection. Lately, the academic community has studied 3D object detection in the context of autonomous vehicles (AVs) using publicly available datasets such as nuScenes and Argoverse 2.0. However, these datasets may have incomplete annotations, often only labeling a small subset of objects in a scene. Although commercial services exists for 3D bounding box annotation, these are often prohibitively expensive. To address these limitations, we propose ReBound, an open-source 3D visualization and dataset re-annotation tool that works across different datasets. In this paper, we detail the design of our tool and present survey results that highlight the usability of our software. Further, we show that ReBound is effective for exploratory data analysis and can facilitate
        <span class="search-hit mathjax">
         active
        </span>
        -
        <span class="search-hit mathjax">
         learning
        </span>
        . Our code and documentation is available at https://github.com/ajedgley/ReBound
        <a class="is-size-7" onclick="document.getElementById('2303.06250v1-abstract-full').style.display = 'none'; document.getElementById('2303.06250v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       10 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted to CHI 2023 Workshop - Intervening, Teaming, Delegating: Creating Engaging Automation Experiences (AutomationXP)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.05886">
         arXiv:2303.05886
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.05886">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.05886">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Bi3D: Bi-domain
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Cross-domain 3D Object Detection
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Yuan%2C+J">
        Jiakang Yuan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+B">
        Bo Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yan%2C+X">
        Xiangchao Yan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chen%2C+T">
        Tao Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shi%2C+B">
        Botian Shi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+Y">
        Yikang Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Qiao%2C+Y">
        Yu Qiao
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.05886v1-abstract-short" style="display: inline;">
        …target data and labeling them at a minimum cost, to achieve a good trade-off between high performance and low annotation cost. To this end, we propose a Bi-domain
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach, namely Bi3D, to solve the cross-domain 3D object detection task. The Bi3D first develops a domainness-aware source sampling strateg…
        <a class="is-size-7" onclick="document.getElementById('2303.05886v1-abstract-full').style.display = 'inline'; document.getElementById('2303.05886v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.05886v1-abstract-full" style="display: none;">
        Unsupervised Domain Adaptation (UDA) technique has been explored in 3D cross-domain tasks recently. Though preliminary progress has been made, the performance gap between the UDA-based 3D model and the supervised one trained with fully annotated target domain is still large. This motivates us to consider selecting partial-yet-important target data and labeling them at a minimum cost, to achieve a good trade-off between high performance and low annotation cost. To this end, we propose a Bi-domain
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach, namely Bi3D, to solve the cross-domain 3D object detection task. The Bi3D first develops a domainness-aware source sampling strategy, which identifies target-domain-like samples from the source domain to avoid the model being interfered by irrelevant source data. Then a diversity-based target sampling strategy is developed, which selects the most informative subset of target domain to improve the model adaptability to the target domain using as little annotation budget as possible. Experiments are conducted on typical cross-domain adaptation scenarios including cross-LiDAR-beam, cross-country, and cross-sensor, where Bi3D achieves a promising target-domain detection accuracy (89.63% on KITTI) compared with UDAbased work (84.29%), even surpassing the detector trained on the full set of the labeled target domain (88.98%). Our code is available at: https://github.com/PJLabADG/3DTrans.
        <a class="is-size-7" onclick="document.getElementById('2303.05886v1-abstract-full').style.display = 'none'; document.getElementById('2303.05886v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       10 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted by CVPR2023; Code is available at https://github.com/PJLabADG/3DTrans
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.05391">
         arXiv:2303.05391
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.05391">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.05391">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">
         cs.DB
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1016/j.eswa.2023.122035">
           10.1016/j.eswa.2023.122035
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Disambiguation of Company names via Deep Recurrent Networks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Basile%2C+A">
        Alessandro Basile
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Crupi%2C+R">
        Riccardo Crupi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Grasso%2C+M">
        Michele Grasso
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mercanti%2C+A">
        Alessandro Mercanti
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Regoli%2C+D">
        Daniele Regoli
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Scarsi%2C+S">
        Simone Scarsi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+S">
        Shuyi Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cosentini%2C+A">
        Andrea Cosentini
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.05391v2-abstract-short" style="display: inline;">
        …of company names that actually represent the same company (i.e. the same Entity).
  Given that the manual labelling of string pairs is a rather onerous task, we analyse how an
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.05391v2-abstract-full').style.display = 'inline'; document.getElementById('2303.05391v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.05391v2-abstract-full" style="display: none;">
        Name Entity Disambiguation is the Natural Language Processing task of identifying textual records corresponding to the same Named Entity, i.e. real-world entities represented as a list of attributes (names, places, organisations, etc.). In this work, we face the task of disambiguating companies on the basis of their written names. We propose a Siamese LSTM Network approach to extract -- via supervised learning -- an embedding of company name strings in a (relatively) low dimensional vector space and use this representation to identify pairs of company names that actually represent the same company (i.e. the same Entity).
  Given that the manual labelling of string pairs is a rather onerous task, we analyse how an
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        approach to prioritise the samples to be labelled leads to a more efficient overall learning pipeline.
  With empirical investigations, we show that our proposed Siamese Network outperforms several benchmark approaches based on standard string matching algorithms when enough labelled data are available. Moreover, we show that
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        prioritisation is indeed helpful when labelling resources are limited, and let the learning models reach the out-of-sample performance saturation with less labelled data with respect to standard (random) data labelling approaches.
        <a class="is-size-7" onclick="document.getElementById('2303.05391v2-abstract-full').style.display = 'none'; document.getElementById('2303.05391v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       15 April, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 7 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        submitted to Elsevier. 26 pages, 6 figures, 4 tables
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       updated version is published by Expert Systems with Applications, Volume 238, Part C, 2024, 122035, ISSN 0957-4174
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.05263">
         arXiv:2303.05263
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.05263">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.05263">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation">
         stat.CO
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">
         stat.ME
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Fast post-process Bayesian inference with Sparse Variational Bayesian Monte Carlo
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+C">
        Chengkun Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Clart%C3%A9%2C+G">
        Grégoire Clarté
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Acerbi%2C+L">
        Luigi Acerbi
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.05263v1-abstract-short" style="display: inline;">
        …Markov Chain Monte Carlo runs -- to build a sparse Gaussian process (GP) surrogate model of the log posterior density. Uncertain regions of the surrogate are then refined via
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.05263v1-abstract-full').style.display = 'inline'; document.getElementById('2303.05263v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.05263v1-abstract-full" style="display: none;">
        We introduce Sparse Variational Bayesian Monte Carlo (SVBMC), a method for fast "post-process" Bayesian inference for models with black-box and potentially noisy likelihoods. SVBMC reuses all existing target density evaluations -- for example, from previous optimizations or partial Markov Chain Monte Carlo runs -- to build a sparse Gaussian process (GP) surrogate model of the log posterior density. Uncertain regions of the surrogate are then refined via
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        as needed. Our work builds on the Variational Bayesian Monte Carlo (VBMC) framework for sample-efficient inference, with several novel contributions. First, we make VBMC scalable to a large number of pre-existing evaluations via sparse GP regression, deriving novel Bayesian quadrature formulae and acquisition functions for
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        with sparse GPs. Second, we introduce noise shaping, a general technique to induce the sparse GP approximation to focus on high posterior density regions. Third, we prove theoretical results in support of the SVBMC refinement procedure. We validate our method on a variety of challenging synthetic scenarios and real-world applications. We find that SVBMC consistently builds good posterior approximations by post-processing of existing model evaluations from different sources, often requiring only a small number of additional density evaluations.
        <a class="is-size-7" onclick="document.getElementById('2303.05263v1-abstract-full').style.display = 'none'; document.getElementById('2303.05263v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       9 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        41 pages, 17 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.05225">
         arXiv:2303.05225
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.05225">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.05225">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Based Domain Adaptation for Tissue Segmentation of Histopathological Images
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Fuster%2C+S">
        Saul Fuster
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Khoraminia%2C+F">
        Farbod Khoraminia
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Eftest%C3%B8l%2C+T">
        Trygve Eftestøl
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zuiverloon%2C+T+C+M">
        Tahlita C. M. Zuiverloon
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Engan%2C+K">
        Kjersti Engan
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.05225v1-abstract-short" style="display: inline;">
        …across datasets. Yet, acquiring sufficient annotated data in the medical domain is cumbersome and time-consuming. The labeling effort can be significantly reduced by leveraging
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , which enables the selective annotation of the most informative samples. Our proposed method allows for fine-tuning a pre-train…
        <a class="is-size-7" onclick="document.getElementById('2303.05225v1-abstract-full').style.display = 'inline'; document.getElementById('2303.05225v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.05225v1-abstract-full" style="display: none;">
        Accurate segmentation of tissue in histopathological images can be very beneficial for defining regions of interest (ROI) for streamline of diagnostic and prognostic tasks. Still, adapting to different domains is essential for histopathology image analysis, as the visual characteristics of tissues can vary significantly across datasets. Yet, acquiring sufficient annotated data in the medical domain is cumbersome and time-consuming. The labeling effort can be significantly reduced by leveraging
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , which enables the selective annotation of the most informative samples. Our proposed method allows for fine-tuning a pre-trained deep neural network using a small set of labeled data from the target domain, while also actively selecting the most informative samples to label next. We demonstrate that our approach performs with significantly fewer labeled samples compared to traditional supervised learning approaches for similar F1-scores, using barely a 59\% of the training set. We also investigate the distribution of class balance to establish annotation guidelines.
        <a class="is-size-7" onclick="document.getElementById('2303.05225v1-abstract-full').style.display = 'none'; document.getElementById('2303.05225v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       9 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.04912">
         arXiv:2303.04912
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.04912">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.04912">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">
         cs.RO
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Embodied
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       of Relational State Abstractions for Bilevel Planning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+A">
        Amber Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Silver%2C+T">
        Tom Silver
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.04912v2-abstract-short" style="display: inline;">
        …states (i.e., ground the symbols). Manually programming predicate interpretations can be difficult, so we would instead like to learn them from data. We propose an embodied
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        paradigm where the agent learns predicate interpretations through online interaction with an expert. For example, after taking acti…
        <a class="is-size-7" onclick="document.getElementById('2303.04912v2-abstract-full').style.display = 'inline'; document.getElementById('2303.04912v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.04912v2-abstract-full" style="display: none;">
        State abstraction is an effective technique for planning in robotics environments with continuous states and actions, long task horizons, and sparse feedback. In object-oriented environments, predicates are a particularly useful form of state abstraction because of their compatibility with symbolic planners and their capacity for relational generalization. However, to plan with predicates, the agent must be able to interpret them in continuous environment states (i.e., ground the symbols). Manually programming predicate interpretations can be difficult, so we would instead like to learn them from data. We propose an embodied
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        paradigm where the agent learns predicate interpretations through online interaction with an expert. For example, after taking actions in a block stacking environment, the agent may ask the expert: "Is On(block1, block2) true?" From this experience, the agent learns to plan: it learns neural predicate interpretations, symbolic planning operators, and neural samplers that can be used for bilevel planning. During exploration, the agent plans to learn: it uses its current models to select actions towards generating informative expert queries. We learn predicate interpretations as ensembles of neural networks and use their entropy to measure the informativeness of potential queries. We evaluate this approach in three robotic environments and find that it consistently outperforms six baselines while exhibiting sample efficiency in two key metrics: number of environment interactions, and number of queries to the expert. Code: https://tinyurl.com/active-predicates
        <a class="is-size-7" onclick="document.getElementById('2303.04912v2-abstract-full').style.display = 'none'; document.getElementById('2303.04912v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 8 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Conference on Lifelong Learning Agents (CoLLAs) 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.04340">
         arXiv:2303.04340
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.04340">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.04340">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">
         cs.DC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">
         cs.RO
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Privacy-preserving and Uncertainty-aware Federated Trajectory Prediction for Connected Autonomous Vehicles
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Peng%2C+M">
        Muzi Peng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+J">
        Jiangwei Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Song%2C+D">
        Dongjin Song
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Miao%2C+F">
        Fei Miao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Su%2C+L">
        Lili Su
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.04340v1-abstract-short" style="display: inline;">
        …Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        techniques in adaptatively selecting participating clients. We consider both negative log-likelihood (NLL) and aleatoric uncertaint…
        <a class="is-size-7" onclick="document.getElementById('2303.04340v1-abstract-full').style.display = 'inline'; document.getElementById('2303.04340v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.04340v1-abstract-full" style="display: none;">
        Deep learning is the method of choice for trajectory prediction for autonomous vehicles. Unfortunately, its data-hungry nature implicitly requires the availability of sufficiently rich and high-quality centralized datasets, which easily leads to privacy leakage. Besides, uncertainty-awareness becomes increasingly important for safety-crucial cyber physical systems whose prediction module heavily relies on machine learning tools. In this paper, we relax the data collection requirement and enhance uncertainty-awareness by using Federated Learning on Connected Autonomous Vehicles with an uncertainty-aware global objective. We name our algorithm as FLTP. We further introduce ALFLTP which boosts FLTP via using
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        techniques in adaptatively selecting participating clients. We consider both negative log-likelihood (NLL) and aleatoric uncertainty (AU) as client selection metrics. Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data. In addition, ALFLTP-AU converges faster in training regression loss and performs better in terms of NLL, minADE and MR than FLTP in most rounds, and has more stable round-wise performance than ALFLTP-NLL.
        <a class="is-size-7" onclick="document.getElementById('2303.04340v1-abstract-full').style.display = 'none'; document.getElementById('2303.04340v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.03666">
         arXiv:2303.03666
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.03666">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.03666">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Sound">
         cs.SD
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">
         eess.AS
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Face: Fast, Accurate and Context-Aware Audio Annotation and Classification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Morsali%2C+M+M">
        M. Mehrdad Morsali
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mohammadzade%2C+H">
        Hoda Mohammadzade
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shouraki%2C+S+B">
        Saeed Bagheri Shouraki
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.03666v1-abstract-short" style="display: inline;">
        …in the environmental audio classification research scope. The proposed annotation method considers outlier, inlier, and hard-to-predict data samples to realize context-aware
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        , leading to the average accuracy of 90% when only 15% of data possess initial annotation. Our proposed algorithm for sound classif…
        <a class="is-size-7" onclick="document.getElementById('2303.03666v1-abstract-full').style.display = 'inline'; document.getElementById('2303.03666v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.03666v1-abstract-full" style="display: none;">
        This paper presents a context-aware framework for feature selection and classification procedures to realize a fast and accurate audio event annotation and classification. The context-aware design starts with exploring feature extraction techniques to find an appropriate combination to select a set resulting in remarkable classification accuracy with minimal computational effort. The exploration for feature selection also embraces an investigation of audio Tempo representation, an advantageous feature extraction method missed by previous works in the environmental audio classification research scope. The proposed annotation method considers outlier, inlier, and hard-to-predict data samples to realize context-aware
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        , leading to the average accuracy of 90% when only 15% of data possess initial annotation. Our proposed algorithm for sound classification obtained average prediction accuracy of 98.05% on the UrbanSound8K dataset. The notebooks containing our source codes and implementation results are available at https://github.com/gitmehrdad/FACE.
        <a class="is-size-7" onclick="document.getElementById('2303.03666v1-abstract-full').style.display = 'none'; document.getElementById('2303.03666v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        9 pages, 4 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.03658">
         arXiv:2303.03658
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.03658">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/ps/2303.03658">
          ps
         </a>
         ,
         <a href="https://arxiv.org/format/2303.03658">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">
         cs.RO
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       An
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Based Robot Kinematic Calibration Framework Using Gaussian Processes
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Da%C5%9F%2C+E">
        Ersin Daş
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Burdick%2C+J+W">
        Joel W. Burdick
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.03658v1-abstract-short" style="display: inline;">
        Future NASA lander missions to icy moons will require completely automated, accurate, and data efficient calibration methods for the robot manipulator arms that sample icy terrains in the lander's vicinity. To support this need, this paper presents a Gaussian Process (GP) approach to the classical manipulator kinematic calibration process. Instead of identifying a corrected set of Denavit-Hartenbe…
        <a class="is-size-7" onclick="document.getElementById('2303.03658v1-abstract-full').style.display = 'inline'; document.getElementById('2303.03658v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.03658v1-abstract-full" style="display: none;">
        Future NASA lander missions to icy moons will require completely automated, accurate, and data efficient calibration methods for the robot manipulator arms that sample icy terrains in the lander's vicinity. To support this need, this paper presents a Gaussian Process (GP) approach to the classical manipulator kinematic calibration process. Instead of identifying a corrected set of Denavit-Hartenberg kinematic parameters, a set of GPs models the residual kinematic error of the arm over the workspace. More importantly, this modeling framework allows a Gaussian Process Upper Confident Bound (GP-UCB) algorithm to efficiently and adaptively select the calibration's measurement points so as to minimize the number of experiments, and therefore minimize the time needed for recalibration. The method is demonstrated in simulation on a simple 2-DOF arm, a 6 DOF arm whose geometry is a candidate for a future NASA mission, and a 7 DOF Barrett WAM arm.
        <a class="is-size-7" onclick="document.getElementById('2303.03658v1-abstract-full').style.display = 'none'; document.getElementById('2303.03658v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.02721">
         arXiv:2303.02721
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.02721">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.02721">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       using region-based sampling
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Dasgupta%2C+S">
        Sanjoy Dasgupta
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Freund%2C+Y">
        Yoav Freund
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.02721v1-abstract-short" style="display: inline;">
        We present a general-purpose
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        scheme for data in metric spaces. The algorithm maintains a collection of neighborhoods of different sizes and uses label queries to identify those that have a strong bias towards one particular label; when two such neighborhoods intersect and have different labels, the regi…
        <a class="is-size-7" onclick="document.getElementById('2303.02721v1-abstract-full').style.display = 'inline'; document.getElementById('2303.02721v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.02721v1-abstract-full" style="display: none;">
        We present a general-purpose
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        scheme for data in metric spaces. The algorithm maintains a collection of neighborhoods of different sizes and uses label queries to identify those that have a strong bias towards one particular label; when two such neighborhoods intersect and have different labels, the region of overlap is treated as a ``known unknown'' and is a target of future active queries. We give label complexity bounds for this method that do not rely on assumptions about the data and we instantiate them in several cases of interest.
        <a class="is-size-7" onclick="document.getElementById('2303.02721v1-abstract-full').style.display = 'none'; document.getElementById('2303.02721v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       5 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.02535">
         arXiv:2303.02535
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.02535">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.02535">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Streaming
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with Deep Neural Networks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Saran%2C+A">
        Akanksha Saran
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yousefi%2C+S">
        Safoora Yousefi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Krishnamurthy%2C+A">
        Akshay Krishnamurthy
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Langford%2C+J">
        John Langford
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Ash%2C+J+T">
        Jordan T. Ash
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.02535v2-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.02535v2-abstract-full').style.display = 'inline'; document.getElementById('2303.02535v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.02535v2-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is perhaps most naturally posed as an online learning problem. However, prior
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approaches with deep neural networks assume offline access to the entire dataset ahead of time. This paper proposes VeSSAL, a new algorithm for batch
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        with deep neural networks in streaming settings, which samples groups of points to query for labels at the moment they are encountered. Our approach trades off between uncertainty and diversity of queried samples to match a desired query rate without requiring any hand-tuned hyperparameters. Altogether, we expand the applicability of deep neural networks to realistic
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        scenarios, such as applications relevant to HCI and large, fractured datasets.
        <a class="is-size-7" onclick="document.getElementById('2303.02535v2-abstract-full').style.display = 'none'; document.getElementById('2303.02535v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       6 June, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 4 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        ICML 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.02430">
         arXiv:2303.02430
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.02430">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.02430">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       CFlowNets: Continuous Control with Generative Flow Networks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Li%2C+Y">
        Yinchuan Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Luo%2C+S">
        Shuang Luo
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+H">
        Haozhi Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hao%2C+J">
        Jianye Hao
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.02430v1-abstract-short" style="display: inline;">
        …learning for exploratory control tasks. GFlowNet aims to generate distribution proportional to the rewards over terminating states, and to sample different candidates in an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        fashion. GFlowNets need to form a DAG and compute the flow matching loss by traversing the inflows and outflows of each node in the…
        <a class="is-size-7" onclick="document.getElementById('2303.02430v1-abstract-full').style.display = 'inline'; document.getElementById('2303.02430v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.02430v1-abstract-full" style="display: none;">
        Generative flow networks (GFlowNets), as an emerging technique, can be used as an alternative to reinforcement learning for exploratory control tasks. GFlowNet aims to generate distribution proportional to the rewards over terminating states, and to sample different candidates in an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        fashion. GFlowNets need to form a DAG and compute the flow matching loss by traversing the inflows and outflows of each node in the trajectory. No experiments have yet concluded that GFlowNets can be used to handle continuous tasks. In this paper, we propose generative continuous flow networks (CFlowNets) that can be applied to continuous control tasks. First, we present the theoretical formulation of CFlowNets. Then, a training framework for CFlowNets is proposed, including the action selection process, the flow approximation algorithm, and the continuous flow matching loss function. Afterward, we theoretically prove the error bound of the flow approximation. The error decreases rapidly as the number of flow samples increases. Finally, experimental results on continuous control tasks demonstrate the performance advantages of CFlowNets compared to many reinforcement learning methods, especially regarding exploration ability.
        <a class="is-size-7" onclick="document.getElementById('2303.02430v1-abstract-full').style.display = 'none'; document.getElementById('2303.02430v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.01560">
         arXiv:2303.01560
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.01560">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.01560">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       and Bayesian Optimization: a Unified Perspective to Learn with a Goal
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Di+Fiore%2C+F">
        Francesco Di Fiore
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nardelli%2C+M">
        Michela Nardelli
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mainini%2C+L">
        Laura Mainini
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.01560v3-abstract-short" style="display: inline;">
        …applications are typically associated with expensive optimization problem to identify optimal design solutions and states of the system of interest. Bayesian optimization and
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.01560v3-abstract-full').style.display = 'inline'; document.getElementById('2303.01560v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.01560v3-abstract-full" style="display: none;">
        Science and Engineering applications are typically associated with expensive optimization problem to identify optimal design solutions and states of the system of interest. Bayesian optimization and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        compute surrogate models through efficient adaptive sampling schemes to assist and accelerate this search task toward a given optimization goal. Both those methodologies are driven by specific infill/learning criteria which quantify the utility with respect to the set goal of evaluating the objective function for unknown combinations of optimization variables. While the two fields have seen an exponential growth in popularity in the past decades, their dualism and synergy have received relatively little attention to date. This paper discusses and formalizes the synergy between Bayesian optimization and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        as symbiotic adaptive sampling methodologies driven by common principles. In particular, we demonstrate this unified perspective through the formalization of the analogy between the Bayesian infill criteria and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        criteria as driving principles of both the goal-driven procedures. To support our original perspective, we propose a general classification of adaptive sampling techniques to highlight similarities and differences between the vast families of adaptive sampling,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , and Bayesian optimization. Accordingly, the synergy is demonstrated mapping the Bayesian infill criteria with the
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        criteria, and is formalized for searches informed by both a single information source and multiple levels of fidelity. In addition, we provide guidelines to apply those learning criteria investigating the performance of different Bayesian schemes for a variety of benchmark problems to highlight benefits and limitations over mathematical properties that characterize real-world applications.
        <a class="is-size-7" onclick="document.getElementById('2303.01560v3-abstract-full').style.display = 'none'; document.getElementById('2303.01560v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       30 November, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 2 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.01557">
         arXiv:2303.01557
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.01557">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.01557">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       BenchDirect: A Directed Language Model for Compiler Benchmarks
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Tsimpourlas%2C+F">
        Foivos Tsimpourlas
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Petoumenos%2C+P">
        Pavlos Petoumenos
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+M">
        Min Xu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cummins%2C+C">
        Chris Cummins
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hazelwood%2C+K">
        Kim Hazelwood
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rajan%2C+A">
        Ajitha Rajan
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Leather%2C+H">
        Hugh Leather
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.01557v1-abstract-short" style="display: inline;">
        …source code feature representations. BenchPress synthesizes executable functions by infilling code that conditions on the program's left and right context. BenchPress uses
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to introduce new benchmarks with unseen features into the dataset of Grewe's et al. CPU vs GPU heuristic, improving its acqu…
        <a class="is-size-7" onclick="document.getElementById('2303.01557v1-abstract-full').style.display = 'inline'; document.getElementById('2303.01557v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.01557v1-abstract-full" style="display: none;">
        The exponential increase of hardware-software complexity has made it impossible for compiler engineers to find the right optimization heuristics manually. Predictive models have been shown to find near optimal heuristics with little human effort but they are limited by a severe lack of diverse benchmarks to train on. Generative AI has been used by researchers to synthesize benchmarks into existing datasets. However, the synthetic programs are short, exceedingly simple and lacking diversity in their features.
  We develop BenchPress, the first ML compiler benchmark generator that can be directed within source code feature representations. BenchPress synthesizes executable functions by infilling code that conditions on the program's left and right context. BenchPress uses
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to introduce new benchmarks with unseen features into the dataset of Grewe's et al. CPU vs GPU heuristic, improving its acquired performance by 50%. BenchPress targets features that has been impossible for other synthesizers to reach. In 3 feature spaces, we outperform human-written code from GitHub, CLgen, CLSmith and the SRCIROR mutator in targeting the features of Rodinia benchmarks.
  BenchPress steers generation with beam search over a feature-agnostic language model. We improve this with BenchDirect which utilizes a directed LM that infills programs by jointly observing source code context and the compiler features that are targeted. BenchDirect achieves up to 36% better accuracy in targeting the features of Rodinia benchmarks, it is 1.8x more likely to give an exact match and it speeds up execution time by up to 72% compared to BenchPress. Both our models produce code that is difficult to distinguish from human-written code. We conduct a Turing test which shows our models' synthetic benchmarks are labelled as 'human-written' as often as human-written code from GitHub.
        <a class="is-size-7" onclick="document.getElementById('2303.01557v1-abstract-full').style.display = 'none'; document.getElementById('2303.01557v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        arXiv admin note: substantial text overlap with arXiv:2208.06555
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.01342">
         arXiv:2303.01342
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.01342">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.01342">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Image and Video Processing">
         eess.IV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       Enhances Classification of Histopathology Whole Slide Images with Attention-based Multiple Instance Learning
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Sadafi%2C+A">
        Ario Sadafi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Navab%2C+N">
        Nassir Navab
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Marr%2C+C">
        Carsten Marr
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.01342v1-abstract-short" style="display: inline;">
        …manner, has been successfully applied in computational histopathology, but it is challenged by large numbers of irrelevant patches, reducing its accuracy. Here, we present an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.01342v1-abstract-full').style.display = 'inline'; document.getElementById('2303.01342v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.01342v1-abstract-full" style="display: none;">
        In many histopathology tasks, sample classification depends on morphological details in tissue or single cells that are only visible at the highest magnification. For a pathologist, this implies tedious zooming in and out, while for a computational decision support algorithm, it leads to the analysis of a huge number of small image patches per whole slide image (WSI). Attention-based multiple instance learning (MIL), where attention estimation is learned in a weakly supervised manner, has been successfully applied in computational histopathology, but it is challenged by large numbers of irrelevant patches, reducing its accuracy. Here, we present an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach to the problem. Querying the expert to annotate regions of interest in a WSI guides the formation of high-attention regions for MIL. We train an attention-based MIL and calculate a confidence metric for every image in the dataset to select the most uncertain WSIs for expert annotation. We test our approach on the CAMELYON17 dataset classifying metastatic lymph node sections in breast cancer. With a novel attention guiding loss, this leads to an accuracy boost of the trained models with few regions annotated for each class.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        thus improves WSIs classification accuracy, leads to faster and more robust convergence, and speeds up the annotation process. It may in the future serve as an important contribution to train MIL models in the clinically relevant context of cancer classification in histopathology.
        <a class="is-size-7" onclick="document.getElementById('2303.01342v1-abstract-full').style.display = 'none'; document.getElementById('2303.01342v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted for publication at the 2023 IEEE International Symposium on Biomedical Imaging (ISBI 2023)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.00870">
         arXiv:2303.00870
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.00870">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.00870">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">
         cs.HC
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">
         cs.CR
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Implementing
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in Cybersecurity: Detecting Anomalies in Redacted Emails
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chung%2C+M">
        Mu-Huan Chung
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+L">
        Lu Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+S">
        Sharon Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+Y">
        Yuhong Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Giang%2C+C">
        Calvin Giang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jerath%2C+K">
        Khilan Jerath
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Raman%2C+A">
        Abhay Raman
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lie%2C+D">
        David Lie
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chignell%2C+M">
        Mark Chignell
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.00870v2-abstract-short" style="display: inline;">
        …high volume of emails combined with the scarcity of resources making machine learning (ML) a necessity, but also creating a need for more efficient human training of ML models.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2303.00870v2-abstract-full').style.display = 'inline'; document.getElementById('2303.00870v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.00870v2-abstract-full" style="display: none;">
        Research on email anomaly detection has typically relied on specially prepared datasets that may not adequately reflect the type of data that occurs in industry settings. In our research, at a major financial services company, privacy concerns prevented inspection of the bodies of emails and attachment details (although subject headings and attachment filenames were available). This made labeling possible anomalies in the resulting redacted emails more difficult. Another source of difficulty is the high volume of emails combined with the scarcity of resources making machine learning (ML) a necessity, but also creating a need for more efficient human training of ML models.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) has been proposed as a way to make human training of ML models more efficient. However, the implementation of
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        methods is a human-centered AI challenge due to potential human analyst uncertainty, and the labeling task can be further complicated in domains such as the cybersecurity domain (or healthcare, aviation, etc.) where mistakes in labeling can have highly adverse consequences. In this paper we present research results concerning the application of
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        to anomaly detection in redacted emails, comparing the utility of different methods for implementing
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in this context. We evaluate different AL strategies and their impact on resulting model performance. We also examine how ratings of confidence that experts have in their labels can inform AL. The results obtained are discussed in terms of their implications for AL methodology and for the role of experts in model-assisted email anomaly screening.
        <a class="is-size-7" onclick="document.getElementById('2303.00870v2-abstract-full').style.display = 'none'; document.getElementById('2303.00870v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       2 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 1 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2303.00141">
         arXiv:2303.00141
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2303.00141">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2303.00141">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Social and Information Networks">
         cs.SI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">
         eess.SY
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Containing a spread through sequential learning: to exploit or to explore?
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Chen%2C+X">
        Xingran Chen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nikpey%2C+H">
        Hesam Nikpey
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kim%2C+J">
        Jungyeol Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sarkar%2C+S">
        Saswati Sarkar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Saeedi-Bidokhti%2C+S">
        Shirin Saeedi-Bidokhti
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2303.00141v2-abstract-short" style="display: inline;">
        …of the process (along with containment through isolation) render such detection as fundamentally different from active search detection strategies. In this work, through an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach, we design testing and isolation strategies to contain the spread and minimize the cumulative infections under a given tes…
        <a class="is-size-7" onclick="document.getElementById('2303.00141v2-abstract-full').style.display = 'inline'; document.getElementById('2303.00141v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2303.00141v2-abstract-full" style="display: none;">
        The spread of an undesirable contact process, such as an infectious disease (e.g. COVID-19), is contained through testing and isolation of infected nodes. The temporal and spatial evolution of the process (along with containment through isolation) render such detection as fundamentally different from active search detection strategies. In this work, through an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approach, we design testing and isolation strategies to contain the spread and minimize the cumulative infections under a given test budget. We prove that the objective can be optimized, with performance guarantees, by greedily selecting the nodes to test. We further design reward-based methodologies that effectively minimize an upper bound on the cumulative infections and are computationally more tractable in large networks. These policies, however, need knowledge about the nodes' infection probabilities which are dynamically changing and have to be learned by sequential testing. We develop a message-passing framework for this purpose and, building on that, show novel tradeoffs between exploitation of knowledge through reward-based heuristics and exploration of the unknown through a carefully designed probabilistic testing. The tradeoffs are fundamentally distinct from the classical counterparts under active search or multi-armed bandit problems (MABs). We provably show the necessity of exploration in a stylized network and show through simulations that exploration can outperform exploitation in various synthetic and real-data networks depending on the parameters of the network and the spread.
        <a class="is-size-7" onclick="document.getElementById('2303.00141v2-abstract-full').style.display = 'none'; document.getElementById('2303.00141v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 28 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       March 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.14567">
         arXiv:2302.14567
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.14567">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.14567">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       with Combinatorial Coverage
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Katragadda%2C+S+P">
        Sai Prathyush Katragadda
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Cody%2C+T">
        Tyler Cody
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Beling%2C+P">
        Peter Beling
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Freeman%2C+L">
        Laura Freeman
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.14567v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.14567v1-abstract-full').style.display = 'inline'; document.getElementById('2302.14567v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.14567v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is a practical field of machine learning that automates the process of selecting which data to label. Current methods are effective in reducing the burden of data labeling but are heavily model-reliant. This has led to the inability of sampled data to be transferred to new models as well as issues with sampling bias. Both issues are of crucial concern in machine learning deployment. We propose
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods utilizing combinatorial coverage to overcome these issues. The proposed methods are data-centric, as opposed to model-centric, and through our experiments we show that the inclusion of coverage in
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        leads to sampling data that tends to be the best in transferring to better performing models and has a competitive sampling bias compared to benchmark methods.
        <a class="is-size-7" onclick="document.getElementById('2302.14567v1-abstract-full').style.display = 'none'; document.getElementById('2302.14567v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       28 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted 2022 IEEE International Conference on Machine Learning and Applications (IEEE ICMLA)
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.14130">
         arXiv:2302.14130
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.14130">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.14130">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1016/j.neucom.2022.11.029">
           10.1016/j.neucom.2022.11.029
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Leveraging Angular Distributions for Improved Knowledge Distillation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Jeon%2C+E+S">
        Eun Som Jeon
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Choi%2C+H">
        Hongjun Choi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shukla%2C+A">
        Ankita Shukla
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Turaga%2C+P">
        Pavan Turaga
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="search-hit">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.14130v1-abstract-short" style="display: inline;">
        …utilizing activation maps of intermediate layers as the source of knowledge, have been studied. Generally, in computer vision applications, it is seen that the feature
        <span class="search-hit mathjax">
         activation
        </span>
        <span class="search-hit mathjax">
         learned
        </span>
        by a higher capacity model contains richer knowledge, highlighting complete objects while focusing less on the background. Based on…
        <a class="is-size-7" onclick="document.getElementById('2302.14130v1-abstract-full').style.display = 'inline'; document.getElementById('2302.14130v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.14130v1-abstract-full" style="display: none;">
        Knowledge distillation as a broad class of methods has led to the development of lightweight and memory efficient models, using a pre-trained model with a large capacity (teacher network) to train a smaller model (student network). Recently, additional variations for knowledge distillation, utilizing activation maps of intermediate layers as the source of knowledge, have been studied. Generally, in computer vision applications, it is seen that the feature
        <span class="search-hit mathjax">
         activation
        </span>
        <span class="search-hit mathjax">
         learned
        </span>
        by a higher capacity model contains richer knowledge, highlighting complete objects while focusing less on the background. Based on this observation, we leverage the dual ability of the teacher to accurately distinguish between positive (relevant to the target object) and negative (irrelevant) areas. We propose a new loss function for distillation, called angular margin-based distillation (AMD) loss. AMD loss uses the angular distance between positive and negative features by projecting them onto a hypersphere, motivated by the near angular distributions seen in many feature extractors. Then, we create a more attentive feature that is angularly distributed on the hypersphere by introducing an angular margin to the positive feature. Transferring such knowledge from the teacher network enables the student model to harness the higher discrimination of positive and negative features for the teacher, thus distilling superior student models. The proposed method is evaluated for various student-teacher network pairs on four public datasets. Furthermore, we show that the proposed method has advantages in compatibility with other learning techniques, such as using fine-grained features, augmentation, and other distillation methods.
        <a class="is-size-7" onclick="document.getElementById('2302.14130v1-abstract-full').style.display = 'none'; document.getElementById('2302.14130v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Neurocomputing, Volume 518, 21 January 2023, Pages 466-481
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Neurocomputing, Volume 518, 2023, Pages 466-481
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.13824">
         arXiv:2302.13824
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.13824">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.13824">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Dirichlet-based Uncertainty Calibration for Active Domain Adaptation
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Xie%2C+M">
        Mixue Xie
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Li%2C+S">
        Shuang Li
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+R">
        Rui Zhang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liu%2C+C+H">
        Chi Harold Liu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.13824v1-abstract-short" style="display: inline;">
        Active domain adaptation (DA) aims to maximally boost the model adaptation on a new target domain by actively selecting limited target data to annotate, whereas traditional
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods may be less effective since they do not consider the domain shift issue. Despite active DA methods address this by further…
        <a class="is-size-7" onclick="document.getElementById('2302.13824v1-abstract-full').style.display = 'inline'; document.getElementById('2302.13824v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.13824v1-abstract-full" style="display: none;">
        Active domain adaptation (DA) aims to maximally boost the model adaptation on a new target domain by actively selecting limited target data to annotate, whereas traditional
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods may be less effective since they do not consider the domain shift issue. Despite active DA methods address this by further proposing targetness to measure the representativeness of target domain characteristics, their predictive uncertainty is usually based on the prediction of deterministic models, which can easily be miscalibrated on data with distribution shift. Considering this, we propose a \textit{Dirichlet-based Uncertainty Calibration} (DUC) approach for active DA, which simultaneously achieves the mitigation of miscalibration and the selection of informative target samples. Specifically, we place a Dirichlet prior on the prediction and interpret the prediction as a distribution on the probability simplex, rather than a point estimate like deterministic models. This manner enables us to consider all possible predictions, mitigating the miscalibration of unilateral prediction. Then a two-round selection strategy based on different uncertainty origins is designed to select target samples that are both representative of target domain and conducive to discriminability. Extensive experiments on cross-domain image classification and semantic segmentation validate the superiority of DUC.
        <a class="is-size-7" onclick="document.getElementById('2302.13824v1-abstract-full').style.display = 'none'; document.getElementById('2302.13824v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       27 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Accepted at ICLR 2023 as Spotlight
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.13425">
         arXiv:2302.13425
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.13425">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.13425">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       A Survey on Uncertainty Quantification Methods for Deep Neural Networks: An Uncertainty Source Perspective
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=He%2C+W">
        Wenchong He
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jiang%2C+Z">
        Zhe Jiang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.13425v2-abstract-short" style="display: inline;">
        …of methods in each category. We show how our taxonomy of UQ methodologies can potentially help guide the choice of UQ method in different machine learning problems (e.g.,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , robustness, and reinforcement learning). We also identify current research gaps and propose several future research directions.
        <a class="is-size-7" onclick="document.getElementById('2302.13425v2-abstract-full').style.display = 'inline'; document.getElementById('2302.13425v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.13425v2-abstract-full" style="display: none;">
        Deep neural networks (DNNs) have achieved tremendous success in making accurate predictions for computer vision, natural language processing, as well as science and engineering domains. However, it is also well-recognized that DNNs sometimes make unexpected, incorrect, but overconfident predictions. This can cause serious consequences in high-stake applications, such as autonomous driving, medical diagnosis, and disaster response. Uncertainty quantification (UQ) aims to estimate the confidence of DNN predictions beyond prediction accuracy. In recent years, many UQ methods have been developed for DNNs. It is of great practical value to systematically categorize these UQ methods and compare their advantages and disadvantages. However, existing surveys mostly focus on categorizing UQ methodologies from a neural network architecture perspective or a Bayesian perspective and ignore the source of uncertainty that each methodology can incorporate, making it difficult to select an appropriate UQ method in practice. To fill the gap, this paper presents a systematic taxonomy of UQ methods for DNNs based on the types of uncertainty sources (data uncertainty versus model uncertainty). We summarize the advantages and disadvantages of methods in each category. We show how our taxonomy of UQ methodologies can potentially help guide the choice of UQ method in different machine learning problems (e.g.,
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , robustness, and reinforcement learning). We also identify current research gaps and propose several future research directions.
        <a class="is-size-7" onclick="document.getElementById('2302.13425v2-abstract-full').style.display = 'none'; document.getElementById('2302.13425v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       3 March, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 26 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        39 pages, 14 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.12941">
         arXiv:2302.12941
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.12941">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Formal Languages and Automata Theory">
         cs.FL
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">
         cs.SE
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       An Educational Tool for Exploring the Pumping Lemma Property for Regular Languages
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Rivera%2C+J+N">
        Josue N. Rivera
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Xu%2C+H">
        Haiping Xu
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.12941v1-abstract-short" style="display: inline;">
        Pumping lemma has been a very difficult topic for students to understand in a theoretical computer science course due to a lack of tool support. In this paper, we present an
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.12941v1-abstract-full').style.display = 'inline'; document.getElementById('2302.12941v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.12941v1-abstract-full" style="display: none;">
        Pumping lemma has been a very difficult topic for students to understand in a theoretical computer science course due to a lack of tool support. In this paper, we present an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        tool called MInimum PUmping length (MIPU) educational software to explore the pumping lemma property for regular languages. For a given regular language, MIPU offers three major functionalities: determining the membership of an input string, generating a list of short strings that belong to the language, and automatically calculating the minimal pumping length of the language. The software tool has been developed to provide educational assistance to students to better understand the concepts of pumping lemma and minimum pumping length, and promote
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        through hand-on practice.
        <a class="is-size-7" onclick="document.getElementById('2302.12941v1-abstract-full').style.display = 'none'; document.getElementById('2302.12941v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       24 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        8 pages, 10 figures, 16th International Conference on Frontiers in Education: Computer Science and Computer Engineering
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.12667">
         arXiv:2302.12667
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.12667">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.12667">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Theory">
         cs.IT
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">
         eess.SY
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep
       <span class="search-hit mathjax">
        active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       for nonlinear system identification
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Lundby%2C+E+T+B">
        Erlend Torje Berg Lundby
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rasheed%2C+A">
        Adil Rasheed
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Halvorsen%2C+I+J">
        Ivar Johan Halvorsen
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Reinhardt%2C+D">
        Dirk Reinhardt
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gros%2C+S">
        Sebastien Gros
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gravdahl%2C+J+T">
        Jan Tommy Gravdahl
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.12667v1-abstract-short" style="display: inline;">
        …vast training data before they can be put to any good use. The data generation process for dynamical systems can be an expensive endeavor both in terms of time and resources.
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.12667v1-abstract-full').style.display = 'inline'; document.getElementById('2302.12667v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.12667v1-abstract-full" style="display: none;">
        The exploding research interest for neural networks in modeling nonlinear dynamical systems is largely explained by the networks' capacity to model complex input-output relations directly from data. However, they typically need vast training data before they can be put to any good use. The data generation process for dynamical systems can be an expensive endeavor both in terms of time and resources.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        addresses this shortcoming by acquiring the most informative data, thereby reducing the need to collect enormous datasets. What makes the current work unique is integrating the deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework into nonlinear system identification. We formulate a general static deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        acquisition problem for nonlinear system identification. This is enabled by exploring system dynamics locally in different regions of the input space to obtain a simulated dataset covering the broader input space. This simulated dataset can be used in a static deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        acquisition scheme referred to as global explorations. The global exploration acquires a batch of initial states corresponding to the most informative state-action trajectories according to a batch acquisition function. The local exploration solves an optimal control problem, finding the control trajectory that maximizes some measure of information. After a batch of informative initial states is acquired, a new round of local explorations from the initial states in the batch is conducted to obtain a set of corresponding control trajectories that are to be applied on the system dynamics to get data from the system. Information measures used in the acquisition scheme are derived from the predictive variance of an ensemble of neural networks. The novel method outperforms standard data acquisition methods used for system identification of nonlinear dynamical systems in the case study performed on simulated data.
        <a class="is-size-7" onclick="document.getElementById('2302.12667v1-abstract-full').style.display = 'none'; document.getElementById('2302.12667v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       24 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.12246">
         arXiv:2302.12246
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.12246">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.12246">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">
         cs.CL
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Active Prompting with Chain-of-Thought for Large Language Models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Diao%2C+S">
        Shizhe Diao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wang%2C+P">
        Pengcheng Wang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lin%2C+Y">
        Yong Lin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhang%2C+T">
        Tong Zhang
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.12246v3-abstract-short" style="display: inline;">
        …which questions are the most important and helpful ones to annotate from a pool of task-specific queries. By borrowing ideas from the related problem of uncertainty-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , we introduce several metrics to characterize the uncertainty so as to select the most uncertain questions for annotation. Experiment…
        <a class="is-size-7" onclick="document.getElementById('2302.12246v3-abstract-full').style.display = 'inline'; document.getElementById('2302.12246v3-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.12246v3-abstract-full" style="display: none;">
        The increasing scale of large language models (LLMs) brings emergent abilities to various complex tasks requiring reasoning, such as arithmetic and commonsense reasoning. It is known that the effective design of task-specific prompts is critical for LLMs' ability to produce high-quality answers. In particular, an effective approach for complex question-and-answer tasks is example-based prompting with chain-of-thought (CoT) reasoning, which significantly improves the performance of LLMs. However, current CoT methods rely on a fixed set of human-annotated exemplars, which are not necessarily the most effective examples for different tasks. This paper proposes a new method, Active-Prompt, to adapt LLMs to different tasks with task-specific example prompts (annotated with human-designed CoT reasoning). For this purpose, we propose a solution to the key problem of determining which questions are the most important and helpful ones to annotate from a pool of task-specific queries. By borrowing ideas from the related problem of uncertainty-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , we introduce several metrics to characterize the uncertainty so as to select the most uncertain questions for annotation. Experimental results demonstrate the superiority of our proposed method, achieving state-of-the-art on eight complex reasoning tasks. Further analyses of different uncertainty metrics, pool sizes, zero-shot learning, and accuracy-uncertainty relationship demonstrate the effectiveness of our method. Our code will be available at https://github.com/shizhediao/active-prompt.
        <a class="is-size-7" onclick="document.getElementById('2302.12246v3-abstract-full').style.display = 'none'; document.getElementById('2302.12246v3-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 May, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 23 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        20 pages, 3 figures, 11 tables
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.12074">
         arXiv:2302.12074
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.12074">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.12074">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Applications">
         stat.AP
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation">
         stat.CO
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       for structural reliability analysis with multiple limit state functions through variance-enhanced PC-Kriging surrogate models
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=A.%2C+J+M">
        J. Moran A.
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Morato%2C+P+G">
        P. G. Morato
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Rigo%2C+P">
        P. Rigo
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.12074v1-abstract-short" style="display: inline;">
        …e.g. repair, failure, should be probabilistically characterized, thus demanding the estimation of multiple performance functions. In this work, we investigate the capability of
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.12074v1-abstract-full').style.display = 'inline'; document.getElementById('2302.12074v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.12074v1-abstract-full" style="display: none;">
        Existing active strategies for training surrogate models yield accurate structural reliability estimates by aiming at design space regions in the vicinity of a specified limit state function. In many practical engineering applications, various damage conditions, e.g. repair, failure, should be probabilistically characterized, thus demanding the estimation of multiple performance functions. In this work, we investigate the capability of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approaches for efficiently selecting training samples under a limited computational budget while still preserving the accuracy associated with multiple surrogated limit states. Specifically, PC-Kriging-based surrogate models are actively trained considering a variance correction derived from leave-one-out cross-validation error information, whereas the sequential learning scheme relies on U-function-derived metrics. The proposed
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        approaches are tested in a highly nonlinear structural reliability setting, whereas in a more practical application, failure and repair events are stochastically predicted in the aftermath of a ship collision against an offshore wind substructure. The results show that a balanced computational budget administration can be effectively achieved by successively targeting the specified multiple limit state functions within a unified
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        scheme.
        <a class="is-size-7" onclick="document.getElementById('2302.12074v1-abstract-full').style.display = 'none'; document.getElementById('2302.12074v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       23 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Report number:
       </span>
       http://hdl.handle.net/2262/103392
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.12018">
         arXiv:2302.12018
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.12018">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.12018">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Gaussian Switch Sampling: A Second Order Approach to
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Benkert%2C+R">
        Ryan Benkert
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Prabhushankar%2C+M">
        Mohit Prabhushankar
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=AlRegib%2C+G">
        Ghassan AlRegib
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Pacharmi%2C+A">
        Armin Pacharmi
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Corona%2C+E">
        Enrique Corona
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.12018v1-abstract-short" style="display: inline;">
        In
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.12018v1-abstract-full').style.display = 'inline'; document.getElementById('2302.12018v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.12018v1-abstract-full" style="display: none;">
        In
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , acquisition functions define informativeness directly on the representation position within the model manifold. However, for most machine learning models (in particular neural networks) this representation is not fixed due to the training pool fluctuations in between
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        rounds. Therefore, several popular strategies are sensitive to experiment parameters (e.g. architecture) and do not consider model robustness to out-of-distribution settings. To alleviate this issue, we propose a grounded second-order definition of information content and sample importance within the context of
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Specifically, we define importance by how often a neural network "forgets" a sample during training - artifacts of second order representation shifts. We show that our definition produces highly accurate importance scores even when the model representations are constrained by the lack of training data. Motivated by our analysis, we develop Gaussian Switch Sampling (GauSS). We show that GauSS is setup agnostic and robust to anomalous distributions with exhaustive experiments on three in-distribution benchmarks, three out-of-distribution benchmarks, and three different architectures. We report an improvement of up to 5% when compared against four popular query strategies.
        <a class="is-size-7" onclick="document.getElementById('2302.12018v1-abstract-full').style.display = 'none'; document.getElementById('2302.12018v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       16 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.11075">
         arXiv:2302.11075
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.11075">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.11075">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in the Presence of Label Noise: A Survey
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Mots%27oehli%2C+M">
        Moseli Mots'oehli
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Baek%2C+K">
        Kyungim Baek
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.11075v2-abstract-short" style="display: inline;">
        Deep
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.11075v2-abstract-full').style.display = 'inline'; document.getElementById('2302.11075v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.11075v2-abstract-full" style="display: none;">
        Deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        has emerged as a powerful tool for training deep learning models within a predefined labeling budget. These models have achieved performances comparable to those trained in an offline setting. However, deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        faces substantial issues when dealing with classification datasets containing noisy labels. In this literature review, we discuss the current state of deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in the presence of label noise, highlighting unique approaches, their strengths, and weaknesses. With the recent success of vision transformers in image classification tasks, we provide a brief overview and consider how the transformer layers and attention mechanisms can be used to enhance diversity, importance, and uncertainty-based selection in queries sent to an oracle for labeling. We further propose exploring contrastive learning methods to derive good image representations that can aid in selecting high-value samples for labeling in an
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        setting. We also highlight the need for creating unified benchmarks and standardized datasets for deep
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        in the presence of label noise for image classification to promote the reproducibility of research. The review concludes by suggesting avenues for future research in this area.
        <a class="is-size-7" onclick="document.getElementById('2302.11075v2-abstract-full').style.display = 'none'; document.getElementById('2302.11075v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       19 September, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 21 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        20 pages, PhD literature review
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.10679">
         arXiv:2302.10679
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.10679">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.10679">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Evaluating the effect of data augmentation and BALD heuristics on distillation of Semantic-KITTI dataset
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Duong%2C+A">
        Anh Duong
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Almin%2C+A">
        Alexandre Almin
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Lemari%C3%A9%2C+L">
        Léo Lemarié
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kiran%2C+B+R">
        B Ravi Kiran
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.10679v1-abstract-short" style="display: inline;">
        <span class="search-hit mathjax">
         Active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.10679v1-abstract-full').style.display = 'inline'; document.getElementById('2302.10679v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.10679v1-abstract-full" style="display: none;">
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         Learning
        </span>
        (AL) has remained relatively unexplored for LiDAR perception tasks in autonomous driving datasets. In this study we evaluate Bayesian
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods applied to the task of dataset distillation or core subset selection (subset with near equivalent performance as full dataset). We also study the effect of application of data augmentation (DA) within Bayesian AL based dataset distillation. We perform these experiments on the full Semantic-KITTI dataset. We extend our study over our existing work only on 1/4th of the same dataset. Addition of DA and BALD have a negative impact over the labeling efficiency and thus the capacity to distill datasets. We demonstrate key issues in designing a functional AL framework and finally conclude with a review of challenges in real world
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        .
        <a class="is-size-7" onclick="document.getElementById('2302.10679v1-abstract-full').style.display = 'none'; document.getElementById('2302.10679v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       21 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Submitted to VISAPP Springer book extension. arXiv admin note: substantial text overlap with arXiv:2202.02661
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.10295">
         arXiv:2302.10295
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.10295">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.10295">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Correlation Clustering with
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       of Pairwise Similarities
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Aronsson%2C+L">
        Linus Aronsson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chehreghani%2C+M+H">
        Morteza Haghir Chehreghani
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.10295v4-abstract-short" style="display: inline;">
        …In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide…
        <a class="is-size-7" onclick="document.getElementById('2302.10295v4-abstract-full').style.display = 'inline'; document.getElementById('2302.10295v4-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.10295v4-abstract-full" style="display: none;">
        Correlation clustering is a well-known unsupervised learning setting that deals with positive and negative pairwise similarities. In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide, adaptation to any correlation clustering algorithm and query strategy, and robustness to noise. In addition, we propose and analyze a number of novel query strategies suited to this setting. We demonstrate the effectiveness of our framework and the proposed query strategies via several experimental studies.
        <a class="is-size-7" onclick="document.getElementById('2302.10295v4-abstract-full').style.display = 'none'; document.getElementById('2302.10295v4-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       12 February, 2024;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 20 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Transactions on Machine Learning Research (TMLR) (2024). https://openreview.net/forum?id=Ryf1TVCjBz
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.10185">
         arXiv:2302.10185
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.10185">
          pdf
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">
         cs.CV
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">
         cs.AI
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       in Brain Tumor Segmentation with Uncertainty Sampling, Annotation Redundancy Restriction, and Data Initialization
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kim%2C+D+D">
        Daniel D Kim
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Chandra%2C+R+S">
        Rajat S Chandra
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Peng%2C+J">
        Jian Peng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wu%2C+J">
        Jing Wu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Feng%2C+X">
        Xue Feng
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Atalay%2C+M">
        Michael Atalay
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bettegowda%2C+C">
        Chetan Bettegowda
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jones%2C+C">
        Craig Jones
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Sair%2C+H">
        Haris Sair
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Liao%2C+W">
        Wei-hua Liao
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zhu%2C+C">
        Chengzhang Zhu
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Zou%2C+B">
        Beiji Zou
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Yang%2C+L">
        Li Yang
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kazerooni%2C+A+F">
        Anahita Fathi Kazerooni
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Nabavizadeh%2C+A">
        Ali Nabavizadeh
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Bai%2C+H+X">
        Harrison X Bai
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Jiao%2C+Z">
        Zhicheng Jiao
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.10185v1-abstract-short" style="display: inline;">
        Deep learning models have demonstrated great potential in medical 3D imaging, but their development is limited by the expensive, large volume of annotated data required.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) addresses this by training a model on a subset of the most informative data samples without compromising performance. We compared…
        <a class="is-size-7" onclick="document.getElementById('2302.10185v1-abstract-full').style.display = 'inline'; document.getElementById('2302.10185v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.10185v1-abstract-full" style="display: none;">
        Deep learning models have demonstrated great potential in medical 3D imaging, but their development is limited by the expensive, large volume of annotated data required.
        <span class="search-hit mathjax">
         Active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        (AL) addresses this by training a model on a subset of the most informative data samples without compromising performance. We compared different AL strategies and propose a framework that minimizes the amount of data needed for state-of-the-art performance. 638 multi-institutional brain tumor MRI images were used to train a 3D U-net model and compare AL strategies. We investigated uncertainty sampling, annotation redundancy restriction, and initial dataset selection techniques. Uncertainty estimation techniques including Bayesian estimation with dropout, bootstrapping, and margins sampling were compared to random query. Strategies to avoid annotation redundancy by removing similar images within the to-be-annotated subset were considered as well. We determined the minimum amount of data necessary to achieve similar performance to the model trained on the full dataset (α = 0.1). A variance-based selection strategy using radiomics to identify the initial training dataset is also proposed. Bayesian approximation with dropout at training and testing showed similar results to that of the full data model with less than 20% of the training data (p=0.293) compared to random query achieving similar performance at 56.5% of the training data (p=0.814). Annotation redundancy restriction techniques achieved state-of-the-art performance at approximately 40%-50% of the training data. Radiomics dataset initialization had higher Dice with initial dataset sizes of 20 and 80 images, but improvements were not significant. In conclusion, we investigated various AL strategies with dropout uncertainty estimation achieving state-of-the-art performance with the least annotated data.
        <a class="is-size-7" onclick="document.getElementById('2302.10185v1-abstract-full').style.display = 'none'; document.getElementById('2302.10185v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       4 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        22 pages, 3 figures, 3 tables, 1 supplementary data document. Submitted to Medical Physics in Jan 2023
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.08991">
         arXiv:2302.08991
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.08991">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.08991">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Engineering, Finance, and Science">
         cs.CE
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Bridging scales with Machine Learning: From first principles statistical mechanics to continuum phase field computations to study order disorder transitions in LixCoO2
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Teichert%2C+G+H">
        G. H. Teichert
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Das%2C+S">
        S. Das
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Shojaei%2C+M+F">
        M. Faghih Shojaei
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Holber%2C+J">
        J. Holber
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Mueller%2C+T">
        T. Mueller
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Hung%2C+L">
        L. Hung
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gavini%2C+V">
        V. Gavini
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Garikipati%2C+K">
        K. Garikipati
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.08991v1-abstract-short" style="display: inline;">
        …representation of the free energy density and chemical potentials of this material system by coarsegraining formation energies for specific atomic configurations. We develop
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflows to train recently developed integrable deep neural networks for such high-dimensional free energy density and chemical…
        <a class="is-size-7" onclick="document.getElementById('2302.08991v1-abstract-full').style.display = 'inline'; document.getElementById('2302.08991v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.08991v1-abstract-full" style="display: none;">
        LixTMO2 (TM=Ni, Co, Mn) forms an important family of cathode materials for Li-ion batteries, whose performance is strongly governed by Li composition-dependent crystal structure and phase stability. Here, we use LixCoO2 (LCO) as a model system to benchmark a machine learning-enabled framework for bridging scales in materials physics. We focus on two scales: (a) assemblies of thousands of atoms described by density functional theory-informed statistical mechanics, and (b) continuum phase field models to study the dynamics of order-disorder transitions in LCO. Central to the scale bridging is the rigorous, quantitatively accurate, representation of the free energy density and chemical potentials of this material system by coarsegraining formation energies for specific atomic configurations. We develop
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflows to train recently developed integrable deep neural networks for such high-dimensional free energy density and chemical potential functions. The resulting, first principles-informed, machine learning-enabled, phase-field computations allow us to study LCO cathodes' phase evolution in terms of temperature, morphology, charge cycling and particle size.
        <a class="is-size-7" onclick="document.getElementById('2302.08991v1-abstract-full').style.display = 'none'; document.getElementById('2302.08991v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        46 pages, 15 figures
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.08981">
         arXiv:2302.08981
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.08981">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.08981">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Black-Box Batch
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
       for Regression
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Kirsch%2C+A">
        Andreas Kirsch
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.08981v2-abstract-short" style="display: inline;">
        Batch
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.08981v2-abstract-full').style.display = 'inline'; document.getElementById('2302.08981v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.08981v2-abstract-full" style="display: none;">
        Batch
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is a popular approach for efficiently training machine learning models on large, initially unlabelled datasets by repeatedly acquiring labels for batches of data points. However, many recent batch
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods are white-box approaches and are often limited to differentiable parametric models: they score unlabeled points using acquisition functions based on model embeddings or first- and second-order derivatives. In this paper, we propose black-box batch
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        for regression tasks as an extension of white-box approaches. Crucially, our method only relies on model predictions. This approach is compatible with a wide range of machine learning models, including regular and Bayesian deep learning models and non-differentiable models such as random forests. It is rooted in Bayesian principles and utilizes recent kernel-based approaches. This allows us to extend a wide range of existing state-of-the-art white-box batch
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        methods (BADGE, BAIT, LCMD) to black-box models. We demonstrate the effectiveness of our approach through extensive experimental evaluations on regression datasets, achieving surprisingly strong performance compared to white-box approaches for deep learning models.
        <a class="is-size-7" onclick="document.getElementById('2302.08981v2-abstract-full').style.display = 'none'; document.getElementById('2302.08981v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       7 July, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 17 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        12 pages + 11 pages appendix
       </span>
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.08893">
         arXiv:2302.08893
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.08893">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.08893">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         stat.ML
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">
         stat.ME
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1007/s10994-023-06454-2">
           10.1007/s10994-023-06454-2
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        learning
       </span>
       for data streams: a survey
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Cacciarelli%2C+D">
        Davide Cacciarelli
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Kulahci%2C+M">
        Murat Kulahci
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.08893v4-abstract-short" style="display: inline;">
        Online
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.08893v4-abstract-full').style.display = 'inline'; document.getElementById('2302.08893v4-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.08893v4-abstract-full" style="display: none;">
        Online
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        . Pool-based
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        , which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research.
        <a class="is-size-7" onclick="document.getElementById('2302.08893v4-abstract-full').style.display = 'none'; document.getElementById('2302.08893v4-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       29 November, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 17 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        Published in Machine Learning (2023)
       </span>
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Journal ref:
       </span>
       Machine Learning (2023): 1-55
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.08805">
         arXiv:2302.08805
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.08805">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.08805">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computational Physics">
         physics.comp-ph
        </span>
       </div>
       <div class="is-inline-block" style="margin-left: 0.5rem">
        <div class="tags has-addons">
         <span class="tag is-dark is-size-7">
          doi
         </span>
         <span class="tag is-light is-size-7">
          <a class="" href="https://doi.org/10.1063/5.0146905">
           10.1063/5.0146905
           <i aria-hidden="true" class="fa fa-external-link">
           </i>
          </a>
         </span>
        </div>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Deep Ensembles vs. Committees for Uncertainty Estimation in Neural-Network Force Fields: Comparison and Application to
       <span class="search-hit mathjax">
        Active
       </span>
       <span class="search-hit mathjax">
        Learning
       </span>
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Carrete%2C+J">
        Jesús Carrete
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Montes-Campos%2C+H">
        Hadrián Montes-Campos
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Wanzenb%C3%B6ck%2C+R">
        Ralf Wanzenböck
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Heid%2C+E">
        Esther Heid
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Madsen%2C+G+K+H">
        Georg K. H. Madsen
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.08805v1-abstract-short" style="display: inline;">
        …based on deep ensembles, committees and bootstrap-aggregation ensembles using data for an ionic liquid and a perovskite surface. We demonstrate an adversarial approach to
        <span class="search-hit mathjax">
         active
        </span>
        …
        <a class="is-size-7" onclick="document.getElementById('2302.08805v1-abstract-full').style.display = 'inline'; document.getElementById('2302.08805v1-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.08805v1-abstract-full" style="display: none;">
        A reliable uncertainty estimator is a key ingredient in the successful use of machine-learning force fields for predictive calculations. Important considerations are correlation with error, overhead during training and inference, and efficient workflows to systematically improve the force field. However, in the case of neural-network force fields, simple committees are often the only option considered due to their easy implementation. Here we present a generalization of the deep-ensemble design, based on multiheaded neural networks and a heteroscedastic loss, that can efficiently deal with uncertainties in both the energy and the forces. We compare uncertainty metrics based on deep ensembles, committees and bootstrap-aggregation ensembles using data for an ionic liquid and a perovskite surface. We demonstrate an adversarial approach to
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        to efficiently and progressively refine the force fields. That
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        workflow is realistically possible thanks to exceptionally fast training enabled by residual learning and a nonlinear learned optimizer.
        <a class="is-size-7" onclick="document.getElementById('2302.08805v1-abstract-full').style.display = 'none'; document.getElementById('2302.08805v1-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       17 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
     </li>
     <li class="arxiv-result">
      <div class="is-marginless">
       <p class="list-title is-inline-block">
        <a href="https://arxiv.org/abs/2302.08612">
         arXiv:2302.08612
        </a>
        <span>
         [
         <a href="https://arxiv.org/pdf/2302.08612">
          pdf
         </a>
         ,
         <a href="https://arxiv.org/format/2302.08612">
          other
         </a>
         ]
        </span>
       </p>
       <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">
         cs.LG
        </span>
        <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Methodology">
         stat.ME
        </span>
       </div>
      </div>
      <p class="title is-5 mathjax">
       Robust expected improvement for Bayesian optimization
      </p>
      <p class="authors">
       <span class="has-text-black-bis has-text-weight-semibold">
        Authors:
       </span>
       <a href="/search/?searchtype=author&amp;query=Christianson%2C+R+B">
        Ryan B. Christianson
       </a>
       ,
       <a href="/search/?searchtype=author&amp;query=Gramacy%2C+R+B">
        Robert B. Gramacy
       </a>
      </p>
      <p class="abstract mathjax">
       <span class="has-text-black-bis has-text-weight-semibold">
        Abstract
       </span>
       :
       <span class="abstract-short has-text-grey-dark mathjax" id="2302.08612v2-abstract-short" style="display: inline;">
        …programming technique in such settings involves an adversarial objective, biasing a local solver away from ``sharp'' troughs. Here we propose a surrogate modeling and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        technique called robust expected improvement (REI) that ports adversarial methodology into the BO/GP framework. After describing…
        <a class="is-size-7" onclick="document.getElementById('2302.08612v2-abstract-full').style.display = 'inline'; document.getElementById('2302.08612v2-abstract-short').style.display = 'none';" style="white-space: nowrap;">
         ▽ More
        </a>
       </span>
       <span class="abstract-full has-text-grey-dark mathjax" id="2302.08612v2-abstract-full" style="display: none;">
        Bayesian Optimization (BO) links Gaussian Process (GP) surrogates with sequential design toward optimizing expensive-to-evaluate black-box functions. Example design heuristics, or so-called acquisition functions, like expected improvement (EI), balance exploration and exploitation to furnish global solutions under stringent evaluation budgets. However, they fall short when solving for robust optima, meaning a preference for solutions in a wider domain of attraction. Robust solutions are useful when inputs are imprecisely specified, or where a series of solutions is desired. A common mathematical programming technique in such settings involves an adversarial objective, biasing a local solver away from ``sharp'' troughs. Here we propose a surrogate modeling and
        <span class="search-hit mathjax">
         active
        </span>
        <span class="search-hit mathjax">
         learning
        </span>
        technique called robust expected improvement (REI) that ports adversarial methodology into the BO/GP framework. After describing the methods, we illustrate and draw comparisons to several competitors on benchmark synthetic exercises and real problems of varying complexity.
        <a class="is-size-7" onclick="document.getElementById('2302.08612v2-abstract-full').style.display = 'none'; document.getElementById('2302.08612v2-abstract-short').style.display = 'inline';" style="white-space: nowrap;">
         △ Less
        </a>
       </span>
      </p>
      <p class="is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Submitted
       </span>
       14 August, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        v1
       </span>
       submitted 16 February, 2023;
       <span class="has-text-black-bis has-text-weight-semibold">
        originally announced
       </span>
       February 2023.
      </p>
      <p class="comments is-size-7">
       <span class="has-text-black-bis has-text-weight-semibold">
        Comments:
       </span>
       <span class="has-text-grey-dark mathjax">
        27 pages, 17 figures, 1 table
       </span>
      </p>
     </li>
    </ol>
    <nav aria-label="pagination" class="pagination is-small is-centered breathe-horizontal" role="navigation">
     <a class="pagination-previous" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=200">
      Previous
     </a>
     <a class="pagination-next" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=600">
      Next
     </a>
     <ul class="pagination-list">
      <li>
       <a aria-label="Goto page 1" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=0">
        1
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 2" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=200">
        2
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 3" class="pagination-link is-current" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=400">
        3
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 4" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=600">
        4
       </a>
      </li>
      <li>
       <a aria-current="page" aria-label="Page 5" class="pagination-link" href="/search/?query=%22active+learning%22&amp;searchtype=all&amp;source=header&amp;order=-announced_date_first&amp;size=200&amp;abstracts=show&amp;date-date_type=submitted_date&amp;start=800">
        5
       </a>
      </li>
      <li>
       <span class="pagination-ellipsis">
        …
       </span>
      </li>
     </ul>
    </nav>
    <div class="is-hidden-tablet">
     <!-- feedback for mobile only -->
     <span class="help" style="display: inline-block;">
      <a href="https://github.com/arXiv/arxiv-search/releases">
       Search v0.5.6 released 2020-02-24
      </a>
     </span>
    </div>
   </div>
  </main>
  <footer>
   <div aria-label="Secondary" class="columns is-desktop" role="navigation">
    <!-- MetaColumn 1 -->
    <div class="column">
     <div class="columns">
      <div class="column">
       <ul class="nav-spaced">
        <li>
         <a href="https://arxiv.org/about">
          About
         </a>
        </li>
        <li>
         <a href="https://arxiv.org/help">
          Help
         </a>
        </li>
       </ul>
      </div>
      <div class="column">
       <ul class="nav-spaced">
        <li>
         <svg class="icon filter-black" role="presentation" viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg">
          <title>
           contact arXiv
          </title>
          <desc>
           Click here to contact arXiv
          </desc>
          <path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z">
          </path>
         </svg>
         <a href="https://arxiv.org/help/contact">
          Contact
         </a>
        </li>
        <li>
         <svg class="icon filter-black" role="presentation" viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg">
          <title>
           subscribe to arXiv mailings
          </title>
          <desc>
           Click here to subscribe
          </desc>
          <path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z">
          </path>
         </svg>
         <a href="https://arxiv.org/help/subscribe">
          Subscribe
         </a>
        </li>
       </ul>
      </div>
     </div>
    </div>
    <!-- end MetaColumn 1 -->
    <!-- MetaColumn 2 -->
    <div class="column">
     <div class="columns">
      <div class="column">
       <ul class="nav-spaced">
        <li>
         <a href="https://arxiv.org/help/license">
          Copyright
         </a>
        </li>
        <li>
         <a href="https://arxiv.org/help/policies/privacy_policy">
          Privacy Policy
         </a>
        </li>
       </ul>
      </div>
      <div class="column sorry-app-links">
       <ul class="nav-spaced">
        <li>
         <a href="https://arxiv.org/help/web_accessibility">
          Web Accessibility Assistance
         </a>
        </li>
        <li>
         <p class="help">
          <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">
           arXiv Operational Status
           <svg class="icon filter-dark_grey" role="presentation" viewbox="0 0 256 512" xmlns="http://www.w3.org/2000/svg">
            <path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z">
            </path>
           </svg>
          </a>
          <br/>
          Get status notifications via
          <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank">
           <svg class="icon filter-black" role="presentation" viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg">
            <path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z">
            </path>
           </svg>
           email
          </a>
          or
          <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank">
           <svg class="icon filter-black" role="presentation" viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg">
            <path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z">
            </path>
           </svg>
           slack
          </a>
         </p>
        </li>
       </ul>
      </div>
     </div>
    </div>
    <!-- end MetaColumn 2 -->
   </div>
  </footer>
 </body>
</html>
